{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMKf_R3jHulN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re, string, unicodedata\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
        "from string import punctuation\n",
        "from nltk.corpus import wordnet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE8DSa_IHwif"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "msdqvEy8nR14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "l6WlhamZHzCZ",
        "outputId": "9bf5b7f9-9bf2-4252-c364-04ea1a48e611"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Ratings                                            Reviews  \\\n",
              "0      1.0  *Disclaimer: I only watched this movie as a co...   \n",
              "1      1.0  I am writing this in hopes that this gets put ...   \n",
              "2      1.0  Really, I could write a scathing review of thi...   \n",
              "3      1.0  If you saw the other previous spoof movies by ...   \n",
              "4      1.0  This movie I saw a day early for free and I st...   \n",
              "5      1.0  Honestly, what is wrong with you, Hollywood? N...   \n",
              "6      1.0  I was given a free ticket to this film; so I c...   \n",
              "7      1.0  OK, so \"Disastrous\" isn't an imaginative barb ...   \n",
              "8      1.0  Jason Friedberg and Aaron Seltzer, the way eve...   \n",
              "9      1.0  Honestly the worst movie ever made. Theatre fu...   \n",
              "\n",
              "                           Movies  \\\n",
              "0                  Disaster Movie   \n",
              "1                  Disaster Movie   \n",
              "2                  Disaster Movie   \n",
              "3                  Disaster Movie   \n",
              "4                  Disaster Movie   \n",
              "5                  Disaster Movie   \n",
              "6                  Disaster Movie   \n",
              "7                  Disaster Movie   \n",
              "8                  Disaster Movie   \n",
              "9  Justin Bieber: Never Say Never   \n",
              "\n",
              "                                            Resenhas  \n",
              "0  * Isenção de responsabilidade: eu só assisti e...  \n",
              "1  Estou escrevendo isso na esperança de que isso...  \n",
              "2  Realmente, eu poderia escrever uma crítica con...  \n",
              "3  Se você viu os outros filmes falsificados ante...  \n",
              "4  Este filme eu vi um dia cedo de graça e ainda ...  \n",
              "5  Honestamente, o que há de errado com você, Hol...  \n",
              "6  Recebi um ingresso grátis para este filme; ent...  \n",
              "7  OK, então \"Desastroso\" não é um fardo imaginat...  \n",
              "8  Jason Friedberg e Aaron Seltzer, do jeito que ...  \n",
              "9  Honestamente, o pior filme de todos os tempos....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-766bd582-2c25-4c15-b963-e2d9fcfe4464\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ratings</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Movies</th>\n",
              "      <th>Resenhas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>*Disclaimer: I only watched this movie as a co...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>* Isenção de responsabilidade: eu só assisti e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>I am writing this in hopes that this gets put ...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Estou escrevendo isso na esperança de que isso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Really, I could write a scathing review of thi...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Realmente, eu poderia escrever uma crítica con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>If you saw the other previous spoof movies by ...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Se você viu os outros filmes falsificados ante...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>This movie I saw a day early for free and I st...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Este filme eu vi um dia cedo de graça e ainda ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Honestly, what is wrong with you, Hollywood? N...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Honestamente, o que há de errado com você, Hol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>I was given a free ticket to this film; so I c...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Recebi um ingresso grátis para este filme; ent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>OK, so \"Disastrous\" isn't an imaginative barb ...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>OK, então \"Desastroso\" não é um fardo imaginat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Jason Friedberg and Aaron Seltzer, the way eve...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Jason Friedberg e Aaron Seltzer, do jeito que ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Honestly the worst movie ever made. Theatre fu...</td>\n",
              "      <td>Justin Bieber: Never Say Never</td>\n",
              "      <td>Honestamente, o pior filme de todos os tempos....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-766bd582-2c25-4c15-b963-e2d9fcfe4464')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-766bd582-2c25-4c15-b963-e2d9fcfe4464 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-766bd582-2c25-4c15-b963-e2d9fcfe4464');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31dce1f3-17d3-460b-957d-6b8a5450c408\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31dce1f3-17d3-460b-957d-6b8a5450c408')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31dce1f3-17d3-460b-957d-6b8a5450c408 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/IMDB-Dataset.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fij_2npjaLL1",
        "outputId": "a94fc578-6beb-4445-9048-53f54f3aec6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFKBO7zVH1La",
        "outputId": "4a44f344-dc30-4725-f3ec-e5f98dab5096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'no', 'doesn', 'each', 'again', \"you'll\", 'where', 'can', 'ain', \"mustn't\", 'these', 'only', 'hasn', 't', 'this', 'd', 's', 'am', 'were', 'then', 'itself', 'aren', 'we', 'those', 'under', 'too', 'off', 'ours', 'why', 'of', 'so', \"wouldn't\", 'because', 'couldn', 'wouldn', 'been', 'on', 'did', 'into', 'here', 'doing', 'could', 'the', 'at', 'who', 'isn', 'theirs', 'shan', 'didn', \"aren't\", 'myself', 'own', 'between', 'do', 'be', \"that'll\", 'its', 'out', 'have', \"isn't\", 'them', 'all', 'before', 'are', 'our', 'him', 'when', 'and', 'about', 'needn', 'nor', 'o', 'hadn', 'yourself', 'his', \"mightn't\", 'until', 'they', 'was', \"shan't\", 're', 'most', \"didn't\", \"weren't\", 'or', 'down', 'during', 'any', \"it's\", 'ma', \"you'd\", 'your', 'does', 'few', 'same', \"she's\", \"won't\", 'yours', 'further', 'she', 'he', 'there', 'such', 'shouldn', 'yourselves', 'once', \"doesn't\", 'i', \"needn't\", 'has', 'haven', 'wasn', 'against', 'having', 'shall', 'you', 've', 'weren', 'in', 'just', 'now', \"hadn't\", 'very', \"you're\", 'it', 'as', 'up', \"wasn't\", 'might', 'my', 'a', 'more', 'll', 'after', 'above', 'below', 'with', 'm', 'hers', \"you've\", \"shouldn't\", 'her', 'if', 'while', 'had', 'their', 'from', \"couldn't\", 'for', 'mightn', 'ourselves', 'himself', 'will', 'but', 'me', 'y', 'whom', 'mustn', 'other', 'which', 'over', \"haven't\", 'that', 'should', 'is', 'some', \"don't\", \"hasn't\", 'won', 'herself', 'how', 'than', 'to', 'would', 'being', 'through', 'an', 'by', 'themselves', 'don', 'both', 'what', \"should've\"}\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "new_stopwords = ['would', 'shall', 'could', 'might']\n",
        "stop_words.extend(new_stopwords)\n",
        "stop_words.remove('not')\n",
        "stop_words = set(stop_words)\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh0e3Y7XXKbq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG7JlfxzU8LA"
      },
      "outputs": [],
      "source": [
        "content = df['Reviews'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7N2xqNZU-7A"
      },
      "outputs": [],
      "source": [
        "def remove_special_char(content):\n",
        "    return re.sub('\\W+', ' ', content)\n",
        "\n",
        "def remove_url(content):\n",
        "    return re.sub(r'http\\S+', ' ' ,content)\n",
        "\n",
        "def remove_stopwords(content):\n",
        "    clean_data = []\n",
        "    for i in content.split():\n",
        "        if i.strip().lower() not in stop_words and i.strip().lower().isalpha():\n",
        "            clean_data.append(i.strip().lower())\n",
        "    return \" \".join(clean_data)\n",
        "\n",
        "def contraction_expansion(content):\n",
        "    content = re.sub(r\"won\\'t\", 'would not', content)\n",
        "    content = re.sub(r\"can\\'t\", 'could not', content)\n",
        "    content = re.sub(r\"don\\'t\", \"do not\", content)\n",
        "    content = re.sub(r\"shouldn\\'t\", \"should not\", content)\n",
        "    content = re.sub(r\"needn\\'t\", \"need not\", content)\n",
        "    content = re.sub(r\"hasn\\'t\", \"has not\", content)\n",
        "    content = re.sub(r\"haven\\'t\", \"have not\", content)\n",
        "    content = re.sub(r\"weren\\'t\", \"were not\", content)\n",
        "    content = re.sub(r\"mightn\\'t\", \"might not\", content)\n",
        "    content = re.sub(r\"didn\\'t\", \"did not\", content)\n",
        "    content = re.sub(r\"n\\'t\", \" not\", content)\n",
        "    return content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "A45hGnEvVBAA",
        "outputId": "2717c1fd-6332-4010-f917-19f9b139c481"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'disclaimer watched movie conditional agreement see films free not caught dead giving hard earned money idiots well explain depth film write shortest review ever not see movie far stupidest lamest lazy unbelievably unfunny movie ever seen total disaster since hatred movie others like extends far beyond one viewing think go bit not know people movie besides carmen electra vanessa minnillo kim kardashian not matter horrible though think point editing flat horrible possibly blatant continuity errors make crapfast even crappier thought know films not supposed serious come film making someone gets minor facial cut next shot someone gets cut sword blood least cut though since narnia films get away give disaster movie pass jokes thoughtless mindless physical gags obviously take popular movies last year late well including best picture nominees know saddest thing stupid movies not care much money make many cameos sorry ass excuses films taking away jobs actors writers directors truly deserve attention lionsgate thought better taste ashamed making kind crap jason friedberg aaron seltzer burn hell guys contributing decline western civilization correction cause downfall western civilization'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def data_cleaning(content):\n",
        "    content = contraction_expansion(content)\n",
        "    content = remove_special_char(content)\n",
        "    content = remove_url(content)\n",
        "    content = remove_stopwords(content)\n",
        "    return content\n",
        "data_cleaning(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k0tmDfmMVFg6",
        "outputId": "ed9c9ad5-bf24-4cb4-ffc0-168b96bc8687"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Ratings  \\\n",
              "0      1.0   \n",
              "1      1.0   \n",
              "2      1.0   \n",
              "3      1.0   \n",
              "4      1.0   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Reviews  \\\n",
              "0  *Disclaimer: I only watched this movie as a conditional agreement. And I see films for free. I wouldn't be caught dead giving my hard earned money to these idiots.Well, to explain the depth of this 'film', I could write my shortest review, ever. Don't see this movie. It is by far the stupidest, lamest, most lazy, and unbelievably UNFUNNY movie I have ever seen. It is a total disaster. But since my hatred for this movie, and the others like it, extends far beyond one viewing, I think I'll go on for a bit.I don't know any of the people in the movie besides Carmen Electra, Vanessa Minnillo, and Kim Kardashian, but it doesn't matter. They're all horrible, though I think that was the point. The editing is flat out horrible, and possibly blatant continuity errors make this crapfast even crappier than I thought it would be. Now I know that these films are not supposed to be serious at all, but come on, it's film-making 101 that if someone gets a minor facial cut, it should be there in the...   \n",
              "1  I am writing this in hopes that this gets put over the previous review of this \"film\". How anyone can find this slop entertaining is completely beyond me. First of all a spoof film entitled \"Disaster Movie\", should indeed be a spoof on disaster films. Now I have seen 1 (yes count them, 1) disaster film being spoofed, that being \"Twister\". How does Juno, Iron Man, Batman, The Hulk, Alvin and the Chipmunks, Amy Winehouse, or Hancock register as Disaster films? Selzterwater and Failburg once again have shown that they lack any sort of writing skill and humor. Having unfortunately been tortured with Date Movie and Epic Movie I know exactly what to expect from these two...no plot, no jokes just bad references and cheaply remade scenes from other films. Someone should have informed them that satire is more than just copy and paste from one film to another, though I shouldn't say that because some of these actually just seem to be taken from trailers.There is nothing clever or witty or re...   \n",
              "2  Really, I could write a scathing review of this turd sandwich, but instead, I'm just going to be making a few observations and points I've deduced.There's just no point in watching these movies anymore. Does any reader out there remember Scary Movie? Remember how it was original with a few comedic elements to it? There was slapstick, some funny lines, it was a pretty forgettable comedy, but it was worth the price of admission. Well, That was the last time this premise was funny. STOP MAKING THESE MOVIES. PLEASE.I could call for a boycott of these pieces of monkey sh*t, but we all know there's going to be a line up of pre pubescent annoying little buggers, spouting crappy one liners like, \"THIS IS SPARTA!\" and, \"IM RICK JAMES BITCH\" so these movies will continue to make some form of monetary gain, considering the production value of this movie looks like it cost about 10 cents to make.Don't see this movie. Don't spend any money on it. Go home, rent Airplane, laugh your ass off, and ...   \n",
              "3  If you saw the other previous spoof movies by these two horrible gentlemen, then you should know that this already will be bad. I'll tell you the truth, if you want to watch it as a brainless person (ironically meant for the stereotypical teenagers, which I am not) then you will laugh at it a bit. But if you judge it, even a little, the movie automatically fails. Why? Never ask that when it comes to these two men.Remember the good old Hollywood days whenever making a movie was about showing people a type of art, and also a story that kept you on the edge of your seat? Well whenever word hit that making films earned you loads of cash, then all these greedy people came in the picture and its quite pathetic. These two are no exception. We still have movie artists (most notably the genius that is Christopher Nolan). But these two guys just...well I've been writing so big words, let me put it in simple terms for these guys...These guys suck, they are not artists, but instead money cravi...   \n",
              "4                                                                                 This movie I saw a day early for free and I still feel like I got ripped off. It is totally brain dead. Burping, kicking in the groin and boobs all over the place. Lame. What is wrong with society, that films like this even get made? The parodies were all horrendous, and un-funny. The plot was lackluster at best and the acting was shallow, transparent and really quite unnecessary.Anyone see \"Idiocracy\"? Remember the movie that won all the academy awards in the future? Well this is that movie. I have not seen a more rancid crappy film. \"Date Movie\" was okay, The Scary movies at least had decent plots, but this, this makes \"spoofs\" (if I can be so nice to call it that) for this year 0 for 3, with \"Meet the Spartans\" and \"Superhero Movie\" all falling flat.Well I've wasted even more of my life typing about this sack of cow dung. So all in all, don't see this movie, unless of course your IQ is below 80.Thanks, R   \n",
              "\n",
              "           Movies  \\\n",
              "0  Disaster Movie   \n",
              "1  Disaster Movie   \n",
              "2  Disaster Movie   \n",
              "3  Disaster Movie   \n",
              "4  Disaster Movie   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Resenhas  \\\n",
              "0  * Isenção de responsabilidade: eu só assisti esse filme como um acordo condicional. E eu vejo filmes de graça. Eu não seria pego morto dando meu dinheiro suado a esses idiotas. Bem, para explicar a profundidade desse 'filme', eu poderia escrever minha crítica mais curta de todos os tempos. Não vê este filme. É de longe o filme mais estúpido, lamenta, preguiçoso e inacreditavelmente UNFUNNY que eu já vi. É um desastre total. Mas como o meu ódio por este filme e por outros, se estende muito além de uma exibição, acho que vou continuar um pouco. Não conheço nenhuma das pessoas do filme além de Carmen Electra, Vanessa Minnillo, e Kim Kardashian, mas isso não importa. Eles são todos horríveis, embora eu ache que esse seja o ponto. A edição é horrível e, possivelmente, erros de continuidade flagrantes tornam essa porcaria ainda mais horrível do que eu pensava. Agora eu sei que esses filmes não devem ser sérios, mas vamos lá, é o cinema 101 que se alguém fizer um pequeno corte facial, ele...   \n",
              "1  Estou escrevendo isso na esperança de que isso seja colocado sobre a revisão anterior deste \"filme\". Como alguém pode achar divertido esse desleixo está completamente além de mim. Antes de mais nada, um filme de paródia intitulado \"Filme de desastre\" deveria ser, de fato, uma paródia de filmes de desastre. Agora eu já vi 1 (sim, conte-os, 1) filme de desastre sendo falsificado, sendo \"Twister\". Como Juno, Homem de Ferro, Batman, O Hulk, Alvin e os Esquilos, Amy Winehouse ou Hancock se registram como filmes de Desastre? Selzterwater e Failburg mostraram mais uma vez que não possuem nenhum tipo de habilidade e humor de escrita. Infelizmente, tendo sido torturado com Date Movie e Epic Movie, sei exatamente o que esperar desses dois ... nenhum enredo, nenhuma piada, apenas más referências e cenas refeitas de outros filmes. Alguém deveria ter informado a eles que a sátira é mais do que apenas copiar e colar de um filme para outro, embora eu não deva dizer isso porque alguns deles realme...   \n",
              "2  Realmente, eu poderia escrever uma crítica contundente sobre esse sanduíche de cocô, mas, em vez disso, vou fazer algumas observações e pontos que deduzi. Não há mais sentido assistir a esses filmes. Algum leitor por aí se lembra do filme de terror? Lembra como era original, com alguns elementos cômicos? Havia palhaçada, algumas frases engraçadas, era uma comédia bastante esquecível, mas valia o preço da entrada. Bem, essa foi a última vez que essa premissa foi engraçada. PARE DE FAZER ESTES FILMES. POR FAVOR, eu poderia pedir um boicote a esses pedaços de macaco, mas todos sabemos que haverá uma fila de buggers irritantes e pré-pubescentes, jorrando uns forros ruins como: \"ISTO É SPARTA!\" e \"IM RICK JAMES BITCH\", para que esses filmes continuem gerando algum ganho monetário, considerando que o valor de produção deste filme parece custar cerca de 10 centavos de dólar. Não gaste dinheiro com isso. Vá para casa, alugue a Airplane, ria e julgue silenciosamente as pessoas que estão fal...   \n",
              "3  Se você viu os outros filmes falsificados anteriores por esses dois senhores horríveis, deve saber que isso já será ruim. Vou lhe dizer a verdade, se você quiser vê-lo como uma pessoa sem cérebro (ironicamente para os adolescentes estereotipados, o que eu não sou), então você rirá um pouco. Mas se você julgar, mesmo que um pouco, o filme falha automaticamente. Por quê? Nunca pergunte isso quando se trata desses dois homens. Lembre-se dos bons e velhos tempos de Hollywood, sempre que fazer um filme era mostrar às pessoas um tipo de arte e também uma história que o mantinha na ponta do seu assento? Bem, sempre que a notícia de que fazer filmes ganhava muito dinheiro, então todas essas pessoas gananciosas apareciam na imagem e é bastante patético. Esses dois não são exceção. Ainda temos artistas de filmes (principalmente o gênio Christopher Nolan). Mas esses dois caras simplesmente ... bem, eu tenho escrito palavras tão grandes, deixe-me colocar em termos simples para esses caras ... ...   \n",
              "4                                 Este filme eu vi um dia cedo de graça e ainda sinto que fui enganado. É totalmente morte cerebral. Arrotando, chutando a virilha e os peitos por todo o lugar. Coxo. O que há de errado com a sociedade, que filmes como esse são feitos? As paródias eram todas horrendas e pouco engraçadas. O enredo foi sem brilho, na melhor das hipóteses, e a atuação foi superficial, transparente e realmente bastante desnecessária. Alguém vê \"Idiocracia\"? Lembra do filme que ganhou todos os prêmios da academia no futuro? Bem, este é esse filme. Eu não vi um filme de baixa qualidade mais rançoso. \"Date Movie\" foi bom, The Scary Movies pelo menos teve enredos decentes, mas isso faz \"spoofs\" (se é que posso dizer assim) para este ano 0 para 3, com \"Meet the Spartans\" e \"Filme de super-heróis\" todos caindo. Bem, eu perdi ainda mais da minha vida digitando sobre esse saco de esterco de vaca. Então, apesar de tudo, não assista a este filme, a menos que o seu QI seja inferior a 80.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Reviews_clean  \n",
              "0  disclaimer watched movie conditional agreement see films free not caught dead giving hard earned money idiots well explain depth film write shortest review ever not see movie far stupidest lamest lazy unbelievably unfunny movie ever seen total disaster since hatred movie others like extends far beyond one viewing think go bit not know people movie besides carmen electra vanessa minnillo kim kardashian not matter horrible though think point editing flat horrible possibly blatant continuity errors make crapfast even crappier thought know films not supposed serious come film making someone gets minor facial cut next shot someone gets cut sword blood least cut though since narnia films get away give disaster movie pass jokes thoughtless mindless physical gags obviously take popular movies last year late well including best picture nominees know saddest thing stupid movies not care much money make many cameos sorry ass excuses films taking away jobs actors writers directors truly deserv...  \n",
              "1                                                               writing hopes gets put previous review film anyone find slop entertaining completely beyond first spoof film entitled disaster movie indeed spoof disaster films seen yes count disaster film spoofed twister juno iron man batman hulk alvin chipmunks amy winehouse hancock register disaster films selzterwater failburg shown lack sort writing skill humor unfortunately tortured date movie epic movie know exactly expect two plot jokes bad references cheaply remade scenes films someone informed satire copy paste one film another though not say actually seem taken trailers nothing clever witty remotely smart way two write not believe people still pay see travesties insult audience though enjoy films doubt smart enough realize rating unfortunately not number low enough yes includes negatives rate deserves top worst films time right date movie epic faliure mean movie meet spartans rather forced hour manos hands fate marathon watch slop  \n",
              "2                                                                                                                                                                                                                                                                                                                                                really write scathing review turd sandwich instead going making observations points deduced point watching movies anymore reader remember scary movie remember original comedic elements slapstick funny lines pretty forgettable comedy worth price admission well last time premise funny stop making movies please call boycott pieces monkey sh know going line pre pubescent annoying little buggers spouting crappy one liners like sparta im rick james bitch movies continue make form monetary gain considering production value movie looks like cost cents make not see movie not spend money go home rent airplane laugh ass silently judge people talking movie monday favor  \n",
              "3  saw previous spoof movies two horrible gentlemen know already bad tell truth want watch brainless person ironically meant stereotypical teenagers not laugh bit judge even little movie automatically fails never ask comes two men remember good old hollywood days whenever making movie showing people type art also story kept edge seat well whenever word hit making films earned loads cash greedy people came picture quite pathetic two exception still movie artists notably genius christopher nolan two guys well writing big words let put simple terms guys guys suck not artists instead money craving whores latest movie proves even movie fails easily mind blowing mean nothing funny trailer people usually put best stuff like idiots sometimes knew going bad made bet friends not good idea write movie reviews paper tell everyone whats good whats bad friends flipped review well warning least not even called movie nothing artistic original jokes sorry references made throughout pretty much random ...  \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                    movie saw day early free still feel like got ripped totally brain dead burping kicking groin boobs place lame wrong society films like even get made parodies horrendous un funny plot lackluster best acting shallow transparent really quite unnecessary anyone see idiocracy remember movie academy awards future well movie not seen rancid crappy film date movie okay scary movies least decent plots makes spoofs nice call year meet spartans superhero movie falling flat well wasted even life typing sack cow dung not see movie unless course iq thanks r  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-720dbdf5-a4da-4120-a701-bafe95dd5ae3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ratings</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Movies</th>\n",
              "      <th>Resenhas</th>\n",
              "      <th>Reviews_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>*Disclaimer: I only watched this movie as a conditional agreement. And I see films for free. I wouldn't be caught dead giving my hard earned money to these idiots.Well, to explain the depth of this 'film', I could write my shortest review, ever. Don't see this movie. It is by far the stupidest, lamest, most lazy, and unbelievably UNFUNNY movie I have ever seen. It is a total disaster. But since my hatred for this movie, and the others like it, extends far beyond one viewing, I think I'll go on for a bit.I don't know any of the people in the movie besides Carmen Electra, Vanessa Minnillo, and Kim Kardashian, but it doesn't matter. They're all horrible, though I think that was the point. The editing is flat out horrible, and possibly blatant continuity errors make this crapfast even crappier than I thought it would be. Now I know that these films are not supposed to be serious at all, but come on, it's film-making 101 that if someone gets a minor facial cut, it should be there in the...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>* Isenção de responsabilidade: eu só assisti esse filme como um acordo condicional. E eu vejo filmes de graça. Eu não seria pego morto dando meu dinheiro suado a esses idiotas. Bem, para explicar a profundidade desse 'filme', eu poderia escrever minha crítica mais curta de todos os tempos. Não vê este filme. É de longe o filme mais estúpido, lamenta, preguiçoso e inacreditavelmente UNFUNNY que eu já vi. É um desastre total. Mas como o meu ódio por este filme e por outros, se estende muito além de uma exibição, acho que vou continuar um pouco. Não conheço nenhuma das pessoas do filme além de Carmen Electra, Vanessa Minnillo, e Kim Kardashian, mas isso não importa. Eles são todos horríveis, embora eu ache que esse seja o ponto. A edição é horrível e, possivelmente, erros de continuidade flagrantes tornam essa porcaria ainda mais horrível do que eu pensava. Agora eu sei que esses filmes não devem ser sérios, mas vamos lá, é o cinema 101 que se alguém fizer um pequeno corte facial, ele...</td>\n",
              "      <td>disclaimer watched movie conditional agreement see films free not caught dead giving hard earned money idiots well explain depth film write shortest review ever not see movie far stupidest lamest lazy unbelievably unfunny movie ever seen total disaster since hatred movie others like extends far beyond one viewing think go bit not know people movie besides carmen electra vanessa minnillo kim kardashian not matter horrible though think point editing flat horrible possibly blatant continuity errors make crapfast even crappier thought know films not supposed serious come film making someone gets minor facial cut next shot someone gets cut sword blood least cut though since narnia films get away give disaster movie pass jokes thoughtless mindless physical gags obviously take popular movies last year late well including best picture nominees know saddest thing stupid movies not care much money make many cameos sorry ass excuses films taking away jobs actors writers directors truly deserv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>I am writing this in hopes that this gets put over the previous review of this \"film\". How anyone can find this slop entertaining is completely beyond me. First of all a spoof film entitled \"Disaster Movie\", should indeed be a spoof on disaster films. Now I have seen 1 (yes count them, 1) disaster film being spoofed, that being \"Twister\". How does Juno, Iron Man, Batman, The Hulk, Alvin and the Chipmunks, Amy Winehouse, or Hancock register as Disaster films? Selzterwater and Failburg once again have shown that they lack any sort of writing skill and humor. Having unfortunately been tortured with Date Movie and Epic Movie I know exactly what to expect from these two...no plot, no jokes just bad references and cheaply remade scenes from other films. Someone should have informed them that satire is more than just copy and paste from one film to another, though I shouldn't say that because some of these actually just seem to be taken from trailers.There is nothing clever or witty or re...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Estou escrevendo isso na esperança de que isso seja colocado sobre a revisão anterior deste \"filme\". Como alguém pode achar divertido esse desleixo está completamente além de mim. Antes de mais nada, um filme de paródia intitulado \"Filme de desastre\" deveria ser, de fato, uma paródia de filmes de desastre. Agora eu já vi 1 (sim, conte-os, 1) filme de desastre sendo falsificado, sendo \"Twister\". Como Juno, Homem de Ferro, Batman, O Hulk, Alvin e os Esquilos, Amy Winehouse ou Hancock se registram como filmes de Desastre? Selzterwater e Failburg mostraram mais uma vez que não possuem nenhum tipo de habilidade e humor de escrita. Infelizmente, tendo sido torturado com Date Movie e Epic Movie, sei exatamente o que esperar desses dois ... nenhum enredo, nenhuma piada, apenas más referências e cenas refeitas de outros filmes. Alguém deveria ter informado a eles que a sátira é mais do que apenas copiar e colar de um filme para outro, embora eu não deva dizer isso porque alguns deles realme...</td>\n",
              "      <td>writing hopes gets put previous review film anyone find slop entertaining completely beyond first spoof film entitled disaster movie indeed spoof disaster films seen yes count disaster film spoofed twister juno iron man batman hulk alvin chipmunks amy winehouse hancock register disaster films selzterwater failburg shown lack sort writing skill humor unfortunately tortured date movie epic movie know exactly expect two plot jokes bad references cheaply remade scenes films someone informed satire copy paste one film another though not say actually seem taken trailers nothing clever witty remotely smart way two write not believe people still pay see travesties insult audience though enjoy films doubt smart enough realize rating unfortunately not number low enough yes includes negatives rate deserves top worst films time right date movie epic faliure mean movie meet spartans rather forced hour manos hands fate marathon watch slop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Really, I could write a scathing review of this turd sandwich, but instead, I'm just going to be making a few observations and points I've deduced.There's just no point in watching these movies anymore. Does any reader out there remember Scary Movie? Remember how it was original with a few comedic elements to it? There was slapstick, some funny lines, it was a pretty forgettable comedy, but it was worth the price of admission. Well, That was the last time this premise was funny. STOP MAKING THESE MOVIES. PLEASE.I could call for a boycott of these pieces of monkey sh*t, but we all know there's going to be a line up of pre pubescent annoying little buggers, spouting crappy one liners like, \"THIS IS SPARTA!\" and, \"IM RICK JAMES BITCH\" so these movies will continue to make some form of monetary gain, considering the production value of this movie looks like it cost about 10 cents to make.Don't see this movie. Don't spend any money on it. Go home, rent Airplane, laugh your ass off, and ...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Realmente, eu poderia escrever uma crítica contundente sobre esse sanduíche de cocô, mas, em vez disso, vou fazer algumas observações e pontos que deduzi. Não há mais sentido assistir a esses filmes. Algum leitor por aí se lembra do filme de terror? Lembra como era original, com alguns elementos cômicos? Havia palhaçada, algumas frases engraçadas, era uma comédia bastante esquecível, mas valia o preço da entrada. Bem, essa foi a última vez que essa premissa foi engraçada. PARE DE FAZER ESTES FILMES. POR FAVOR, eu poderia pedir um boicote a esses pedaços de macaco, mas todos sabemos que haverá uma fila de buggers irritantes e pré-pubescentes, jorrando uns forros ruins como: \"ISTO É SPARTA!\" e \"IM RICK JAMES BITCH\", para que esses filmes continuem gerando algum ganho monetário, considerando que o valor de produção deste filme parece custar cerca de 10 centavos de dólar. Não gaste dinheiro com isso. Vá para casa, alugue a Airplane, ria e julgue silenciosamente as pessoas que estão fal...</td>\n",
              "      <td>really write scathing review turd sandwich instead going making observations points deduced point watching movies anymore reader remember scary movie remember original comedic elements slapstick funny lines pretty forgettable comedy worth price admission well last time premise funny stop making movies please call boycott pieces monkey sh know going line pre pubescent annoying little buggers spouting crappy one liners like sparta im rick james bitch movies continue make form monetary gain considering production value movie looks like cost cents make not see movie not spend money go home rent airplane laugh ass silently judge people talking movie monday favor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>If you saw the other previous spoof movies by these two horrible gentlemen, then you should know that this already will be bad. I'll tell you the truth, if you want to watch it as a brainless person (ironically meant for the stereotypical teenagers, which I am not) then you will laugh at it a bit. But if you judge it, even a little, the movie automatically fails. Why? Never ask that when it comes to these two men.Remember the good old Hollywood days whenever making a movie was about showing people a type of art, and also a story that kept you on the edge of your seat? Well whenever word hit that making films earned you loads of cash, then all these greedy people came in the picture and its quite pathetic. These two are no exception. We still have movie artists (most notably the genius that is Christopher Nolan). But these two guys just...well I've been writing so big words, let me put it in simple terms for these guys...These guys suck, they are not artists, but instead money cravi...</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Se você viu os outros filmes falsificados anteriores por esses dois senhores horríveis, deve saber que isso já será ruim. Vou lhe dizer a verdade, se você quiser vê-lo como uma pessoa sem cérebro (ironicamente para os adolescentes estereotipados, o que eu não sou), então você rirá um pouco. Mas se você julgar, mesmo que um pouco, o filme falha automaticamente. Por quê? Nunca pergunte isso quando se trata desses dois homens. Lembre-se dos bons e velhos tempos de Hollywood, sempre que fazer um filme era mostrar às pessoas um tipo de arte e também uma história que o mantinha na ponta do seu assento? Bem, sempre que a notícia de que fazer filmes ganhava muito dinheiro, então todas essas pessoas gananciosas apareciam na imagem e é bastante patético. Esses dois não são exceção. Ainda temos artistas de filmes (principalmente o gênio Christopher Nolan). Mas esses dois caras simplesmente ... bem, eu tenho escrito palavras tão grandes, deixe-me colocar em termos simples para esses caras ... ...</td>\n",
              "      <td>saw previous spoof movies two horrible gentlemen know already bad tell truth want watch brainless person ironically meant stereotypical teenagers not laugh bit judge even little movie automatically fails never ask comes two men remember good old hollywood days whenever making movie showing people type art also story kept edge seat well whenever word hit making films earned loads cash greedy people came picture quite pathetic two exception still movie artists notably genius christopher nolan two guys well writing big words let put simple terms guys guys suck not artists instead money craving whores latest movie proves even movie fails easily mind blowing mean nothing funny trailer people usually put best stuff like idiots sometimes knew going bad made bet friends not good idea write movie reviews paper tell everyone whats good whats bad friends flipped review well warning least not even called movie nothing artistic original jokes sorry references made throughout pretty much random ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>This movie I saw a day early for free and I still feel like I got ripped off. It is totally brain dead. Burping, kicking in the groin and boobs all over the place. Lame. What is wrong with society, that films like this even get made? The parodies were all horrendous, and un-funny. The plot was lackluster at best and the acting was shallow, transparent and really quite unnecessary.Anyone see \"Idiocracy\"? Remember the movie that won all the academy awards in the future? Well this is that movie. I have not seen a more rancid crappy film. \"Date Movie\" was okay, The Scary movies at least had decent plots, but this, this makes \"spoofs\" (if I can be so nice to call it that) for this year 0 for 3, with \"Meet the Spartans\" and \"Superhero Movie\" all falling flat.Well I've wasted even more of my life typing about this sack of cow dung. So all in all, don't see this movie, unless of course your IQ is below 80.Thanks, R</td>\n",
              "      <td>Disaster Movie</td>\n",
              "      <td>Este filme eu vi um dia cedo de graça e ainda sinto que fui enganado. É totalmente morte cerebral. Arrotando, chutando a virilha e os peitos por todo o lugar. Coxo. O que há de errado com a sociedade, que filmes como esse são feitos? As paródias eram todas horrendas e pouco engraçadas. O enredo foi sem brilho, na melhor das hipóteses, e a atuação foi superficial, transparente e realmente bastante desnecessária. Alguém vê \"Idiocracia\"? Lembra do filme que ganhou todos os prêmios da academia no futuro? Bem, este é esse filme. Eu não vi um filme de baixa qualidade mais rançoso. \"Date Movie\" foi bom, The Scary Movies pelo menos teve enredos decentes, mas isso faz \"spoofs\" (se é que posso dizer assim) para este ano 0 para 3, com \"Meet the Spartans\" e \"Filme de super-heróis\" todos caindo. Bem, eu perdi ainda mais da minha vida digitando sobre esse saco de esterco de vaca. Então, apesar de tudo, não assista a este filme, a menos que o seu QI seja inferior a 80.</td>\n",
              "      <td>movie saw day early free still feel like got ripped totally brain dead burping kicking groin boobs place lame wrong society films like even get made parodies horrendous un funny plot lackluster best acting shallow transparent really quite unnecessary anyone see idiocracy remember movie academy awards future well movie not seen rancid crappy film date movie okay scary movies least decent plots makes spoofs nice call year meet spartans superhero movie falling flat well wasted even life typing sack cow dung not see movie unless course iq thanks r</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-720dbdf5-a4da-4120-a701-bafe95dd5ae3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-720dbdf5-a4da-4120-a701-bafe95dd5ae3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-720dbdf5-a4da-4120-a701-bafe95dd5ae3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dc5e76fb-a5bf-43b1-af89-e0658f566642\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc5e76fb-a5bf-43b1-af89-e0658f566642')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dc5e76fb-a5bf-43b1-af89-e0658f566642 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "pd.options.display.max_colwidth = 1000\n",
        "df['Reviews_clean'] = df['Reviews'].apply(data_cleaning)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLoab3IsVHic",
        "outputId": "aef13656-e736-45f7-e2a2-87853edb1b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "0    60000\n",
            "1    60000\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    60000\n",
              "1    60000\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Mapping rating data to Binary label 1 (+ve) if rating >=7 and 0 (-ve) if rating <=4 and 2 (neutral) if rating = 5 or 6\n",
        "df['Label'] = df['Ratings'].apply(lambda x: '1' if x >= 7 else ('0' if x<=4 else '2'))\n",
        "#Removing\n",
        "df=df[df.Label<'2']\n",
        "data=df[['Reviews_clean','Reviews','Ratings','Label']]\n",
        "print(data['Label'].value_counts())\n",
        "df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMPl7amnVJuk"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from prettytable import PrettyTable\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpK3B4RHVKwl"
      },
      "outputs": [],
      "source": [
        "class LemmaTokenizer(object):\n",
        "    def __init_(self):\n",
        "        self.wordnetlemma = WordNetLemmatizer()\n",
        "    def __call__(self, reviews):\n",
        "        return [self.wordnetlemma.lemmatize(word) for word in word_tokenize(reviews)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQCE6fTNVNXV"
      },
      "outputs": [],
      "source": [
        "class LemmaTokenizer(object):\n",
        "    def __init__(self):\n",
        "        self.wordnetlemma = WordNetLemmatizer()\n",
        "    def __call__(self, reviews):\n",
        "        return [self.wordnetlemma.lemmatize(word) for word in word_tokenize(reviews)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm8hO8mNVPWm"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(data, test_size=0.3, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuBMH4bOarNq",
        "outputId": "f56e5c2c-aee6-49da-db9b-c25b5c3887eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwicCWlWVSuH"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(analyzer='word', tokenizer = LemmaTokenizer(), ngram_range=(1, 3), min_df=10, max_features=2500)\n",
        "X_train_df = tfidf.fit_transform(train['Reviews_clean']).toarray()\n",
        "X_test_df  = tfidf.transform(test['Reviews_clean']).toarray()\n",
        "\n",
        "\n",
        "y_train = train['Label']\n",
        "y_test  = test['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z-0nQl4VT0O",
        "outputId": "5ee703b0-13ea-418e-e15d-17176954a5f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 1 :\n",
            "\t# Unigrams :\n",
            "\t. blow\n",
            "\t. climax\n",
            "\t. na\n",
            "\t. forever\n",
            "\t. category\n",
            "\t. behind\n",
            "\t. decides\n",
            "\t. e\n",
            "\t. pick\n",
            "\t. content\n",
            "\t. roger\n",
            "\t. came\n",
            "\t. round\n",
            "\t. dying\n",
            "\t. notice\n",
            "\t. reach\n",
            "\t. hurt\n",
            "\t. risk\n",
            "\t. television\n",
            "\t. search\n",
            "\t. fighter\n",
            "\t. likely\n",
            "\t. consider\n",
            "\t. speech\n",
            "\t. lady\n",
            "\t. twice\n",
            "\t. presence\n",
            "\t. murder\n",
            "\t. process\n",
            "\t. witness\n",
            "\t. suspect\n",
            "\t. gag\n",
            "\t. dvd\n",
            "\t. angel\n",
            "\t. technical\n",
            "\t. former\n",
            "\t. police\n",
            "\t. opposite\n",
            "\t. formula\n",
            "\t. khan\n",
            "\t. impossible\n",
            "\t. outside\n",
            "\t. order\n",
            "\t. known\n",
            "\t. queen\n",
            "\t. display\n",
            "\t. president\n",
            "\t. leaving\n",
            "\t. santa\n",
            "\t. third\n",
            "\t. jaw\n",
            "\t. doctor\n",
            "\t. plus\n",
            "\t. pair\n",
            "\t. existence\n",
            "\t. difficult\n",
            "\t. manner\n",
            "\t. japanese\n",
            "\t. worked\n",
            "\t. voice\n",
            "\t. campy\n",
            "\t. vampire\n",
            "\t. main\n",
            "\t. opening\n",
            "\t. doubt\n",
            "\t. damn\n",
            "\t. introduced\n",
            "\t. major\n",
            "\t. soldier\n",
            "\t. working\n",
            "\t. aware\n",
            "\t. face\n",
            "\t. jackie\n",
            "\t. dr\n",
            "\t. candy\n",
            "\t. later\n",
            "\t. drawn\n",
            "\t. hall\n",
            "\t. wan\n",
            "\t. ups\n",
            "\t. therefore\n",
            "\t. box\n",
            "\t. girlfriend\n",
            "\t. sport\n",
            "\t. entry\n",
            "\t. however\n",
            "\t. appealing\n",
            "\t. bone\n",
            "\t. designed\n",
            "\t. teenage\n",
            "\t. sheer\n",
            "\t. bollywood\n",
            "\t. number\n",
            "\t. prove\n",
            "\t. released\n",
            "\t. blood\n",
            "\t. jump\n",
            "\t. army\n",
            "\t. sword\n",
            "\t. regular\n",
            "\t. push\n",
            "\t. gangster\n",
            "\t. filmmaker\n",
            "\t. despite\n",
            "\t. knew\n",
            "\t. various\n",
            "\t. singer\n",
            "\t. extremely\n",
            "\t. v\n",
            "\t. developed\n",
            "\t. public\n",
            "\t. insane\n",
            "\t. ring\n",
            "\t. wish\n",
            "\t. table\n",
            "\t. wolf\n",
            "\t. crude\n",
            "\t. protagonist\n",
            "\t. teacher\n",
            "\t. famous\n",
            "\t. core\n",
            "\t. acted\n",
            "\t. accept\n",
            "\t. playing\n",
            "\t. bird\n",
            "\t. board\n",
            "\t. eric\n",
            "\t. chick\n",
            "\t. wake\n",
            "\t. leading\n",
            "\t. clue\n",
            "\t. food\n",
            "\t. naturally\n",
            "\t. evil\n",
            "\t. g\n",
            "\t. party\n",
            "\t. hotel\n",
            "\t. realized\n",
            "\t. skin\n",
            "\t. threat\n",
            "\t. suggest\n",
            "\t. common\n",
            "\t. excited\n",
            "\t. curious\n",
            "\t. expression\n",
            "\t. pop\n",
            "\t. thus\n",
            "\t. cop\n",
            "\t. frame\n",
            "\t. meanwhile\n",
            "\t. mental\n",
            "\t. forest\n",
            "\t. capable\n",
            "\t. page\n",
            "\t. singing\n",
            "\t. context\n",
            "\t. fame\n",
            "\t. russian\n",
            "\t. deadly\n",
            "\t. bar\n",
            "\t. offer\n",
            "\t. included\n",
            "\t. somewhat\n",
            "\t. realize\n",
            "\t. jr\n",
            "\t. fate\n",
            "\t. roll\n",
            "\t. particularly\n",
            "\t. leader\n",
            "\t. field\n",
            "\t. k\n",
            "\t. everybody\n",
            "\t. mentioned\n",
            "\t. immediately\n",
            "\t. dirty\n",
            "\t. match\n",
            "\t. whose\n",
            "\t. weapon\n",
            "\t. adding\n",
            "\t. going\n",
            "\t. driver\n",
            "\t. skill\n",
            "\t. conclusion\n",
            "\t. onto\n",
            "\t. willing\n",
            "\t. south\n",
            "\t. early\n",
            "\t. recall\n",
            "\t. scenario\n",
            "\t. matter\n",
            "\t. heard\n",
            "\t. goofy\n",
            "\t. black\n",
            "\t. shock\n",
            "\t. doll\n",
            "\t. ii\n",
            "\t. fly\n",
            "\t. base\n",
            "\t. door\n",
            "\t. spider\n",
            "\t. arm\n",
            "\t. fred\n",
            "\t. know\n",
            "\t. jungle\n",
            "\t. creator\n",
            "\t. close\n",
            "\t. player\n",
            "\t. animal\n",
            "\t. provide\n",
            "\t. followed\n",
            "\t. need\n",
            "\t. mindless\n",
            "\t. hunter\n",
            "\t. lead\n",
            "\t. late\n",
            "\t. track\n",
            "\t. franchise\n",
            "\t. loses\n",
            "\t. away\n",
            "\t. whilst\n",
            "\t. ball\n",
            "\t. connection\n",
            "\t. praise\n",
            "\t. fighting\n",
            "\t. create\n",
            "\t. raise\n",
            "\t. named\n",
            "\t. drug\n",
            "\t. limited\n",
            "\t. test\n",
            "\t. stage\n",
            "\t. spoof\n",
            "\t. richard\n",
            "\t. instance\n",
            "\t. two\n",
            "\t. superior\n",
            "\t. rich\n",
            "\t. structure\n",
            "\t. lose\n",
            "\t. casting\n",
            "\t. christian\n",
            "\t. mid\n",
            "\t. dance\n",
            "\t. changed\n",
            "\t. mass\n",
            "\t. cross\n",
            "\t. add\n",
            "\t. activity\n",
            "\t. martial\n",
            "\t. happen\n",
            "\t. hunt\n",
            "\t. cant\n",
            "\t. six\n",
            "\t. finished\n",
            "\t. loose\n",
            "\t. plan\n",
            "\t. folk\n",
            "\t. behavior\n",
            "\t. shown\n",
            "\t. overly\n",
            "\t. say\n",
            "\t. related\n",
            "\t. sky\n",
            "\t. p\n",
            "\t. mountain\n",
            "\t. industry\n",
            "\t. fight\n",
            "\t. trouble\n",
            "\t. anti\n",
            "\t. respect\n",
            "\t. band\n",
            "\t. finish\n",
            "\t. group\n",
            "\t. n\n",
            "\t. wall\n",
            "\t. la\n",
            "\t. considering\n",
            "\t. nightmare\n",
            "\t. anyway\n",
            "\t. paris\n",
            "\t. dad\n",
            "\t. massive\n",
            "\t. standing\n",
            "\t. nasty\n",
            "\t. kind\n",
            "\t. italian\n",
            "\t. mad\n",
            "\t. regardless\n",
            "\t. ahead\n",
            "\t. burn\n",
            "\t. german\n",
            "\t. remake\n",
            "\t. blue\n",
            "\t. forward\n",
            "\t. escape\n",
            "\t. bought\n",
            "\t. station\n",
            "\t. carry\n",
            "\t. site\n",
            "\t. remember\n",
            "\t. pacing\n",
            "\t. longer\n",
            "\t. sequence\n",
            "\t. pack\n",
            "\t. note\n",
            "\t. set\n",
            "\t. much\n",
            "\t. held\n",
            "\t. hill\n",
            "\t. credit\n",
            "\t. target\n",
            "\t. want\n",
            "\t. glass\n",
            "\t. silent\n",
            "\t. race\n",
            "\t. indian\n",
            "\t. supernatural\n",
            "\t. compared\n",
            "\t. strange\n",
            "\t. background\n",
            "\t. business\n",
            "\t. plane\n",
            "\t. ordinary\n",
            "\t. ask\n",
            "\t. hear\n",
            "\t. self\n",
            "\t. involving\n",
            "\t. mine\n",
            "\t. stop\n",
            "\t. meant\n",
            "\t. shocking\n",
            "\t. van\n",
            "\t. brazil\n",
            "\t. reading\n",
            "\t. passed\n",
            "\t. particular\n",
            "\t. buy\n",
            "\t. missed\n",
            "\t. predator\n",
            "\t. watched\n",
            "\t. extreme\n",
            "\t. town\n",
            "\t. fi\n",
            "\t. lie\n",
            "\t. information\n",
            "\t. stephen\n",
            "\t. upon\n",
            "\t. internet\n",
            "\t. decision\n",
            "\t. version\n",
            "\t. male\n",
            "\t. sci\n",
            "\t. highlight\n",
            "\t. explosion\n",
            "\t. stuff\n",
            "\t. soon\n",
            "\t. treated\n",
            "\t. earlier\n",
            "\t. married\n",
            "\t. root\n",
            "\t. putting\n",
            "\t. death\n",
            "\t. equally\n",
            "\t. college\n",
            "\t. terror\n",
            "\t. bizarre\n",
            "\t. reveal\n",
            "\t. mention\n",
            "\t. collection\n",
            "\t. sexual\n",
            "\t. revenge\n",
            "\t. boyfriend\n",
            "\t. perhaps\n",
            "\t. directed\n",
            "\t. help\n",
            "\t. led\n",
            "\t. pretty\n",
            "\t. flesh\n",
            "\t. reaction\n",
            "\t. government\n",
            "\t. towards\n",
            "\t. beat\n",
            "\t. sight\n",
            "\t. ticket\n",
            "\t. rarely\n",
            "\t. studio\n",
            "\t. became\n",
            "\t. break\n",
            "\t. com\n",
            "\t. flick\n",
            "\t. vote\n",
            "\t. british\n",
            "\t. mysterious\n",
            "\t. subject\n",
            "\t. moon\n",
            "\t. three\n",
            "\t. involves\n",
            "\t. anyone\n",
            "\t. darkness\n",
            "\t. charles\n",
            "\t. gross\n",
            "\t. considered\n",
            "\t. texas\n",
            "\t. majority\n",
            "\t. high\n",
            "\t. french\n",
            "\t. angle\n",
            "\t. west\n",
            "\t. psycho\n",
            "\t. century\n",
            "\t. latter\n",
            "\t. snow\n",
            "\t. animation\n",
            "\t. saying\n",
            "\t. long\n",
            "\t. area\n",
            "\t. affair\n",
            "\t. heroine\n",
            "\t. clear\n",
            "\t. scream\n",
            "\t. continue\n",
            "\t. rise\n",
            "\t. normally\n",
            "\t. told\n",
            "\t. ready\n",
            "\t. far\n",
            "\t. account\n",
            "\t. becomes\n",
            "\t. loss\n",
            "\t. chinese\n",
            "\t. fellow\n",
            "\t. sick\n",
            "\t. l\n",
            "\t. honest\n",
            "\t. cult\n",
            "\t. middle\n",
            "\t. gang\n",
            "\t. kelly\n",
            "\t. place\n",
            "\t. felt\n",
            "\t. level\n",
            "\t. personality\n",
            "\t. green\n",
            "\t. back\n",
            "\t. criminal\n",
            "\t. crew\n",
            "\t. intelligence\n",
            "\t. occasionally\n",
            "\t. factor\n",
            "\t. term\n",
            "\t. state\n",
            "\t. movement\n",
            "\t. learn\n",
            "\t. damme\n",
            "\t. force\n",
            "\t. drive\n",
            "\t. leaf\n",
            "\t. detective\n",
            "\t. watch\n",
            "\t. grab\n",
            "\t. fire\n",
            "\t. hot\n",
            "\t. home\n",
            "\t. artistic\n",
            "\t. central\n",
            "\t. legend\n",
            "\t. decade\n",
            "\t. come\n",
            "\t. etc\n",
            "\t. ice\n",
            "\t. record\n",
            "\t. mike\n",
            "\t. attack\n",
            "\t. aside\n",
            "\t. seemingly\n",
            "\t. cartoon\n",
            "\t. worthy\n",
            "\t. amount\n",
            "\t. every\n",
            "\t. bank\n",
            "\t. length\n",
            "\t. teen\n",
            "\t. hide\n",
            "\t. afraid\n",
            "\t. gary\n",
            "\t. remains\n",
            "\t. tony\n",
            "\t. taste\n",
            "\t. depth\n",
            "\t. successful\n",
            "\t. demon\n",
            "\t. news\n",
            "\t. built\n",
            "\t. mystery\n",
            "\t. intended\n",
            "\t. foot\n",
            "\t. wit\n",
            "\t. department\n",
            "\t. artist\n",
            "\t. gave\n",
            "\t. danger\n",
            "\t. everything\n",
            "\t. screenwriter\n",
            "\t. dragon\n",
            "\t. asked\n",
            "\t. interview\n",
            "\t. water\n",
            "\t. ruin\n",
            "\t. grand\n",
            "\t. indeed\n",
            "\t. location\n",
            "\t. extra\n",
            "\t. punch\n",
            "\t. actress\n",
            "\t. slightly\n",
            "\t. brian\n",
            "\t. getting\n",
            "\t. floor\n",
            "\t. move\n",
            "\t. military\n",
            "\t. body\n",
            "\t. relatively\n",
            "\t. jean\n",
            "\t. conversation\n",
            "\t. leave\n",
            "\t. hospital\n",
            "\t. visit\n",
            "\t. bear\n",
            "\t. telling\n",
            "\t. english\n",
            "\t. ghost\n",
            "\t. feature\n",
            "\t. parody\n",
            "\t. begin\n",
            "\t. bet\n",
            "\t. trust\n",
            "\t. curse\n",
            "\t. latest\n",
            "\t. fault\n",
            "\t. scare\n",
            "\t. granted\n",
            "\t. though\n",
            "\t. eating\n",
            "\t. small\n",
            "\t. forgotten\n",
            "\t. spoiler\n",
            "\t. paranormal\n",
            "\t. fill\n",
            "\t. cameron\n",
            "\t. spy\n",
            "\t. charlie\n",
            "\t. convincing\n",
            "\t. million\n",
            "\t. across\n",
            "\t. survive\n",
            "\t. serial\n",
            "\t. thats\n",
            "\t. street\n",
            "\t. general\n",
            "\t. ultimately\n",
            "\t. regret\n",
            "\t. park\n",
            "\t. pull\n",
            "\t. friday\n",
            "\t. gone\n",
            "\t. danny\n",
            "\t. went\n",
            "\t. gay\n",
            "\t. regard\n",
            "\t. delivery\n",
            "\t. brief\n",
            "\t. warrior\n",
            "\t. including\n",
            "\t. source\n",
            "\t. featuring\n",
            "\t. able\n",
            "\t. billy\n",
            "\t. safe\n",
            "\t. looking\n",
            "\t. created\n",
            "\t. inside\n",
            "\t. sister\n",
            "\t. revealed\n",
            "\t. mr\n",
            "\t. absolutely\n",
            "\t. disappointed\n",
            "\t. rescue\n",
            "\t. research\n",
            "\t. claim\n",
            "\t. goal\n",
            "\t. allowed\n",
            "\t. near\n",
            "\t. travel\n",
            "\t. ability\n",
            "\t. image\n",
            "\t. answer\n",
            "\t. driving\n",
            "\t. co\n",
            "\t. picture\n",
            "\t. private\n",
            "\t. motion\n",
            "\t. meeting\n",
            "\t. cat\n",
            "\t. us\n",
            "\t. white\n",
            "\t. veteran\n",
            "\t. weekend\n",
            "\t. wind\n",
            "\t. difference\n",
            "\t. intention\n",
            "\t. decide\n",
            "\t. speaking\n",
            "\t. patrick\n",
            "\t. period\n",
            "\t. village\n",
            "\t. car\n",
            "\t. buddy\n",
            "\t. cause\n",
            "\t. jessica\n",
            "\t. nail\n",
            "\t. trip\n",
            "\t. toy\n",
            "\t. helped\n",
            "\t. put\n",
            "\t. rush\n",
            "\t. drop\n",
            "\t. teenager\n",
            "\t. movie\n",
            "\t. got\n",
            "\t. inspired\n",
            "\t. control\n",
            "\t. opportunity\n",
            "\t. necessary\n",
            "\t. anderson\n",
            "\t. walk\n",
            "\t. princess\n",
            "\t. lucky\n",
            "\t. lived\n",
            "\t. church\n",
            "\t. pain\n",
            "\t. segment\n",
            "\t. scene\n",
            "\t. hated\n",
            "\t. available\n",
            "\t. baby\n",
            "\t. community\n",
            "\t. x\n",
            "\t. follow\n",
            "\t. ray\n",
            "\t. boy\n",
            "\t. professor\n",
            "\t. narrative\n",
            "\t. jackson\n",
            "\t. thankfully\n",
            "\t. odd\n",
            "\t. room\n",
            "\t. constantly\n",
            "\t. old\n",
            "\t. slowly\n",
            "\t. entirely\n",
            "\t. fish\n",
            "\t. gore\n",
            "\t. mirror\n",
            "\t. science\n",
            "\t. tragedy\n",
            "\t. multiple\n",
            "\t. magic\n",
            "\t. massacre\n",
            "\t. franco\n",
            "\t. said\n",
            "\t. gun\n",
            "\t. secret\n",
            "\t. without\n",
            "\t. desert\n",
            "\t. deserve\n",
            "\t. american\n",
            "\t. showed\n",
            "\t. four\n",
            "\t. thousand\n",
            "\t. support\n",
            "\t. storyline\n",
            "\t. waiting\n",
            "\t. dare\n",
            "\t. draw\n",
            "\t. sequel\n",
            "\t. purpose\n",
            "\t. figure\n",
            "\t. soul\n",
            "\t. market\n",
            "\t. exactly\n",
            "\t. rule\n",
            "\t. men\n",
            "\t. william\n",
            "\t. turning\n",
            "\t. promise\n",
            "\t. alan\n",
            "\t. heavily\n",
            "\t. blair\n",
            "\t. flow\n",
            "\t. merely\n",
            "\t. viewer\n",
            "\t. includes\n",
            "\t. mostly\n",
            "\t. month\n",
            "\t. sexy\n",
            "\t. use\n",
            "\t. lord\n",
            "\t. ended\n",
            "\t. amusing\n",
            "\t. london\n",
            "\t. agree\n",
            "\t. office\n",
            "\t. cameo\n",
            "\t. corny\n",
            "\t. living\n",
            "\t. fairy\n",
            "\t. fox\n",
            "\t. partner\n",
            "\t. introduction\n",
            "\t. trailer\n",
            "\t. within\n",
            "\t. trek\n",
            "\t. mom\n",
            "\t. recently\n",
            "\t. law\n",
            "\t. lee\n",
            "\t. mile\n",
            "\t. flash\n",
            "\t. time\n",
            "\t. planet\n",
            "\t. red\n",
            "\t. really\n",
            "\t. belief\n",
            "\t. music\n",
            "\t. met\n",
            "\t. ending\n",
            "\t. end\n",
            "\t. device\n",
            "\t. taken\n",
            "\t. lesson\n",
            "\t. nearly\n",
            "\t. following\n",
            "\t. pie\n",
            "\t. showing\n",
            "\t. taking\n",
            "\t. encounter\n",
            "\t. daughter\n",
            "\t. jake\n",
            "\t. range\n",
            "\t. follows\n",
            "\t. crash\n",
            "\t. edward\n",
            "\t. hundred\n",
            "\t. bloody\n",
            "\t. christopher\n",
            "\t. count\n",
            "\t. allen\n",
            "\t. cold\n",
            "\t. admit\n",
            "\t. load\n",
            "\t. picked\n",
            "\t. gold\n",
            "\t. wedding\n",
            "\t. added\n",
            "\t. heck\n",
            "\t. gon\n",
            "\t. slapstick\n",
            "\t. commentary\n",
            "\t. villain\n",
            "\t. giving\n",
            "\t. progress\n",
            "\t. miss\n",
            "\t. cry\n",
            "\t. mainly\n",
            "\t. memory\n",
            "\t. way\n",
            "\t. handle\n",
            "\t. color\n",
            "\t. career\n",
            "\t. country\n",
            "\t. hidden\n",
            "\t. imagination\n",
            "\t. jones\n",
            "\t. mark\n",
            "\t. likable\n",
            "\t. twenty\n",
            "\t. given\n",
            "\t. presented\n",
            "\t. technique\n",
            "\t. frightening\n",
            "\t. concept\n",
            "\t. final\n",
            "\t. pulled\n",
            "\t. charm\n",
            "\t. design\n",
            "\t. die\n",
            "\t. innocent\n",
            "\t. falling\n",
            "\t. trick\n",
            "\t. destroy\n",
            "\t. hero\n",
            "\t. hand\n",
            "\t. wife\n",
            "\t. clearly\n",
            "\t. release\n",
            "\t. among\n",
            "\t. dog\n",
            "\t. born\n",
            "\t. computer\n",
            "\t. mother\n",
            "\t. couple\n",
            "\t. holiday\n",
            "\t. unknown\n",
            "\t. hey\n",
            "\t. list\n",
            "\t. focused\n",
            "\t. generally\n",
            "\t. angry\n",
            "\t. bed\n",
            "\t. cage\n",
            "\t. company\n",
            "\t. eat\n",
            "\t. original\n",
            "\t. stunt\n",
            "\t. alive\n",
            "\t. system\n",
            "\t. pay\n",
            "\t. bill\n",
            "\t. part\n",
            "\t. quickly\n",
            "\t. beginning\n",
            "\t. bright\n",
            "\t. bullet\n",
            "\t. deserved\n",
            "\t. written\n",
            "\t. island\n",
            "\t. whole\n",
            "\t. deliver\n",
            "\t. fact\n",
            "\t. relief\n",
            "\t. meaning\n",
            "\t. robin\n",
            "\t. seen\n",
            "\t. eight\n",
            "\t. constant\n",
            "\t. taylor\n",
            "\t. front\n",
            "\t. twilight\n",
            "\t. model\n",
            "\t. exception\n",
            "\t. satire\n",
            "\t. costume\n",
            "\t. using\n",
            "\t. stranger\n",
            "\t. responsible\n",
            "\t. sell\n",
            "\t. interesting\n",
            "\t. whether\n",
            "\t. song\n",
            "\t. grow\n",
            "\t. creating\n",
            "\t. interested\n",
            "\t. form\n",
            "\t. price\n",
            "\t. kid\n",
            "\t. check\n",
            "\t. shocked\n",
            "\t. proved\n",
            "\t. big\n",
            "\t. character\n",
            "\t. aspect\n",
            "\t. missing\n",
            "\t. return\n",
            "\t. stone\n",
            "\t. wait\n",
            "\t. enemy\n",
            "\t. forget\n",
            "\t. vehicle\n",
            "\t. tend\n",
            "\t. mask\n",
            "\t. rushed\n",
            "\t. probably\n",
            "\t. house\n",
            "\t. week\n",
            "\t. cinematic\n",
            "\t. willis\n",
            "\t. spirit\n",
            "\t. let\n",
            "\t. musical\n",
            "\t. russell\n",
            "\t. exist\n",
            "\t. bruce\n",
            "\t. western\n",
            "\t. sure\n",
            "\t. another\n",
            "\t. paying\n",
            "\t. degree\n",
            "\t. rob\n",
            "\t. grown\n",
            "\t. higher\n",
            "\t. discover\n",
            "\t. johnson\n",
            "\t. desire\n",
            "\t. america\n",
            "\t. direction\n",
            "\t. previous\n",
            "\t. luck\n",
            "\t. tree\n",
            "\t. murphy\n",
            "\t. several\n",
            "\t. george\n",
            "\t. eddie\n",
            "\t. sarah\n",
            "\t. tension\n",
            "\t. explain\n",
            "\t. boat\n",
            "\t. knowledge\n",
            "\t. morgan\n",
            "\t. storytelling\n",
            "\t. husband\n",
            "\t. find\n",
            "\t. sheriff\n",
            "\t. center\n",
            "\t. dangerous\n",
            "\t. night\n",
            "\t. scale\n",
            "\t. flashback\n",
            "\t. question\n",
            "\t. basic\n",
            "\t. blade\n",
            "\t. success\n",
            "\t. creature\n",
            "\t. loud\n",
            "\t. train\n",
            "\t. bomb\n",
            "\t. theatre\n",
            "\t. marriage\n",
            "\t. identity\n",
            "\t. similar\n",
            "\t. obviously\n",
            "\t. ton\n",
            "\t. hopefully\n",
            "\t. hope\n",
            "\t. next\n",
            "\t. chase\n",
            "\t. left\n",
            "\t. died\n",
            "\t. line\n",
            "\t. build\n",
            "\t. bos\n",
            "\t. julia\n",
            "\t. bob\n",
            "\t. path\n",
            "\t. screenplay\n",
            "\t. till\n",
            "\t. camp\n",
            "\t. rated\n",
            "\t. focus\n",
            "\t. special\n",
            "\t. snake\n",
            "\t. entertain\n",
            "\t. mary\n",
            "\t. screen\n",
            "\t. typical\n",
            "\t. since\n",
            "\t. witch\n",
            "\t. truck\n",
            "\t. conflict\n",
            "\t. normal\n",
            "\t. directing\n",
            "\t. robert\n",
            "\t. surface\n",
            "\t. eye\n",
            "\t. j\n",
            "\t. used\n",
            "\t. christmas\n",
            "\t. meet\n",
            "\t. straight\n",
            "\t. master\n",
            "\t. choice\n",
            "\t. commercial\n",
            "\t. captain\n",
            "\t. documentary\n",
            "\t. believe\n",
            "\t. mean\n",
            "\t. clean\n",
            "\t. wear\n",
            "\t. proper\n",
            "\t. study\n",
            "\t. rock\n",
            "\t. stand\n",
            "\t. disney\n",
            "\t. moved\n",
            "\t. beach\n",
            "\t. hollywood\n",
            "\t. impact\n",
            "\t. sean\n",
            "\t. store\n",
            "\t. physical\n",
            "\t. creative\n",
            "\t. case\n",
            "\t. max\n",
            "\t. average\n",
            "\t. direct\n",
            "\t. le\n",
            "\t. drink\n",
            "\t. stay\n",
            "\t. victim\n",
            "\t. friend\n",
            "\t. impression\n",
            "\t. winning\n",
            "\t. seem\n",
            "\t. wild\n",
            "\t. crowd\n",
            "\t. johnny\n",
            "\t. bag\n",
            "\t. animated\n",
            "\t. low\n",
            "\t. ship\n",
            "\t. show\n",
            "\t. historical\n",
            "\t. mission\n",
            "\t. gory\n",
            "\t. non\n",
            "\t. speak\n",
            "\t. jamie\n",
            "\t. rating\n",
            "\t. mix\n",
            "\t. peter\n",
            "\t. read\n",
            "\t. king\n",
            "\t. jim\n",
            "\t. dozen\n",
            "\t. exact\n",
            "\t. window\n",
            "\t. produced\n",
            "\t. david\n",
            "\t. wanting\n",
            "\t. kept\n",
            "\t. dude\n",
            "\t. suit\n",
            "\t. feeling\n",
            "\t. hit\n",
            "\t. course\n",
            "\t. happening\n",
            "\t. explained\n",
            "\t. technology\n",
            "\t. bigger\n",
            "\t. dislike\n",
            "\t. step\n",
            "\t. caught\n",
            "\t. repeat\n",
            "\t. passion\n",
            "\t. beast\n",
            "\t. dramatic\n",
            "\t. scared\n",
            "\t. de\n",
            "\t. younger\n",
            "\t. event\n",
            "\t. vision\n",
            "\t. r\n",
            "\t. alright\n",
            "\t. art\n",
            "\t. apparent\n",
            "\t. soft\n",
            "\t. filmed\n",
            "\t. go\n",
            "\t. almost\n",
            "\t. era\n",
            "\t. stuck\n",
            "\t. understanding\n",
            "\t. crime\n",
            "\t. ten\n",
            "\t. apart\n",
            "\t. originality\n",
            "\t. past\n",
            "\t. grace\n",
            "\t. pg\n",
            "\t. manage\n",
            "\t. type\n",
            "\t. essentially\n",
            "\t. certain\n",
            "\t. mouth\n",
            "\t. wrote\n",
            "\t. hold\n",
            "\t. intriguing\n",
            "\t. talking\n",
            "\t. hard\n",
            "\t. fair\n",
            "\t. standard\n",
            "\t. anymore\n",
            "\t. super\n",
            "\t. attitude\n",
            "\t. lower\n",
            "\t. gratuitous\n",
            "\t. key\n",
            "\t. struggle\n",
            "\t. totally\n",
            "\t. joe\n",
            "\t. work\n",
            "\t. done\n",
            "\t. slow\n",
            "\t. biggest\n",
            "\t. jennifer\n",
            "\t. short\n",
            "\t. call\n",
            "\t. anna\n",
            "\t. incredibly\n",
            "\t. material\n",
            "\t. imdb\n",
            "\t. spielberg\n",
            "\t. mixed\n",
            "\t. appropriate\n",
            "\t. winner\n",
            "\t. exploitation\n",
            "\t. silly\n",
            "\t. share\n",
            "\t. suspense\n",
            "\t. child\n",
            "\t. wide\n",
            "\t. star\n",
            "\t. turned\n",
            "\t. dead\n",
            "\t. honestly\n",
            "\t. entire\n",
            "\t. stick\n",
            "\t. contains\n",
            "\t. nazi\n",
            "\t. current\n",
            "\t. experiment\n",
            "\t. anybody\n",
            "\t. five\n",
            "\t. golden\n",
            "\t. andrew\n",
            "\t. girl\n",
            "\t. start\n",
            "\t. cable\n",
            "\t. breaking\n",
            "\t. bring\n",
            "\t. jane\n",
            "\t. genuine\n",
            "\t. received\n",
            "\t. desperate\n",
            "\t. shooting\n",
            "\t. full\n",
            "\t. often\n",
            "\t. father\n",
            "\t. sum\n",
            "\t. comment\n",
            "\t. tough\n",
            "\t. pure\n",
            "\t. take\n",
            "\t. gut\n",
            "\t. attractive\n",
            "\t. guy\n",
            "\t. appeared\n",
            "\t. quiet\n",
            "\t. creepy\n",
            "\t. funnier\n",
            "\t. medium\n",
            "\t. tim\n",
            "\t. reviewer\n",
            "\t. haunted\n",
            "\t. imagine\n",
            "\t. sex\n",
            "\t. makeup\n",
            "\t. first\n",
            "\t. older\n",
            "\t. spot\n",
            "\t. filled\n",
            "\t. like\n",
            "\t. iron\n",
            "\t. catch\n",
            "\t. history\n",
            "\t. arnold\n",
            "\t. williams\n",
            "\t. thrown\n",
            "\t. serious\n",
            "\t. lost\n",
            "\t. individual\n",
            "\t. fat\n",
            "\t. expected\n",
            "\t. c\n",
            "\t. suddenly\n",
            "\t. robot\n",
            "\t. setting\n",
            "\t. motivation\n",
            "\t. michael\n",
            "\t. nick\n",
            "\t. werewolf\n",
            "\t. talk\n",
            "\t. simply\n",
            "\t. killing\n",
            "\t. absurd\n",
            "\t. as\n",
            "\t. free\n",
            "\t. reference\n",
            "\t. rental\n",
            "\t. weird\n",
            "\t. thrill\n",
            "\t. brother\n",
            "\t. manages\n",
            "\t. par\n",
            "\t. audience\n",
            "\t. pleasure\n",
            "\t. network\n",
            "\t. tight\n",
            "\t. drag\n",
            "\t. advice\n",
            "\t. rather\n",
            "\t. ed\n",
            "\t. sit\n",
            "\t. usual\n",
            "\t. value\n",
            "\t. kevin\n",
            "\t. novel\n",
            "\t. yet\n",
            "\t. must\n",
            "\t. fast\n",
            "\t. rented\n",
            "\t. already\n",
            "\t. tired\n",
            "\t. surprising\n",
            "\t. f\n",
            "\t. recent\n",
            "\t. humanity\n",
            "\t. wondering\n",
            "\t. minor\n",
            "\t. sake\n",
            "\t. female\n",
            "\t. get\n",
            "\t. parent\n",
            "\t. around\n",
            "\t. lake\n",
            "\t. dollar\n",
            "\t. fully\n",
            "\t. woman\n",
            "\t. steve\n",
            "\t. alex\n",
            "\t. approach\n",
            "\t. easily\n",
            "\t. real\n",
            "\t. never\n",
            "\t. adaptation\n",
            "\t. amy\n",
            "\t. smith\n",
            "\t. netflix\n",
            "\t. humorous\n",
            "\t. howard\n",
            "\t. combination\n",
            "\t. yeah\n",
            "\t. local\n",
            "\t. welcome\n",
            "\t. thinking\n",
            "\t. timing\n",
            "\t. jack\n",
            "\t. team\n",
            "\t. thank\n",
            "\t. liner\n",
            "\t. finale\n",
            "\t. b\n",
            "\t. universe\n",
            "\t. fiction\n",
            "\t. scott\n",
            "\t. filming\n",
            "\t. memorable\n",
            "\t. killer\n",
            "\t. coming\n",
            "\t. example\n",
            "\t. can\n",
            "\t. found\n",
            "\t. point\n",
            "\t. right\n",
            "\t. describe\n",
            "\t. haunting\n",
            "\t. become\n",
            "\t. crazy\n",
            "\t. daniel\n",
            "\t. managed\n",
            "\t. clothes\n",
            "\t. possible\n",
            "\t. sitting\n",
            "\t. downright\n",
            "\t. phone\n",
            "\t. blonde\n",
            "\t. interest\n",
            "\t. earth\n",
            "\t. matthew\n",
            "\t. seagal\n",
            "\t. viewing\n",
            "\t. homage\n",
            "\t. based\n",
            "\t. addition\n",
            "\t. finally\n",
            "\t. feel\n",
            "\t. head\n",
            "\t. horror\n",
            "\t. thomas\n",
            "\t. justice\n",
            "\t. issue\n",
            "\t. disturbing\n",
            "\t. installment\n",
            "\t. becoming\n",
            "\t. hair\n",
            "\t. last\n",
            "\t. childhood\n",
            "\t. enough\n",
            "\t. knowing\n",
            "\t. cinema\n",
            "\t. kate\n",
            "\t. interaction\n",
            "\t. sign\n",
            "\t. poster\n",
            "\t. visuals\n",
            "\t. result\n",
            "\t. genuinely\n",
            "\t. giant\n",
            "\t. steal\n",
            "\t. york\n",
            "\t. piece\n",
            "\t. city\n",
            "\t. humour\n",
            "\t. judge\n",
            "\t. creates\n",
            "\t. walked\n",
            "\t. director\n",
            "\t. live\n",
            "\t. miller\n",
            "\t. stereotype\n",
            "\t. school\n",
            "\t. shoot\n",
            "\t. reminds\n",
            "\t. young\n",
            "\t. debut\n",
            "\t. present\n",
            "\t. side\n",
            "\t. possibly\n",
            "\t. accurate\n",
            "\t. knight\n",
            "\t. understand\n",
            "\t. emotionally\n",
            "\t. decided\n",
            "\t. fine\n",
            "\t. martin\n",
            "\t. appears\n",
            "\t. absolute\n",
            "\t. mainstream\n",
            "\t. familiar\n",
            "\t. compelling\n",
            "\t. moving\n",
            "\t. guessing\n",
            "\t. lover\n",
            "\t. logic\n",
            "\t. superman\n",
            "\t. delivered\n",
            "\t. captured\n",
            "\t. portrayed\n",
            "\t. rocky\n",
            "\t. visually\n",
            "\t. man\n",
            "\t. growing\n",
            "\t. son\n",
            "\t. run\n",
            "\t. naked\n",
            "\t. laugh\n",
            "\t. better\n",
            "\t. light\n",
            "\t. element\n",
            "\t. along\n",
            "\t. power\n",
            "\t. little\n",
            "\t. visual\n",
            "\t. seriously\n",
            "\t. day\n",
            "\t. maker\n",
            "\t. fit\n",
            "\t. involved\n",
            "\t. deal\n",
            "\t. environment\n",
            "\t. happened\n",
            "\t. stereotypical\n",
            "\t. spoil\n",
            "\t. graphic\n",
            "\t. dry\n",
            "\t. reality\n",
            "\t. produce\n",
            "\t. tone\n",
            "\t. dealing\n",
            "\t. moore\n",
            "\t. deep\n",
            "\t. trilogy\n",
            "\t. kick\n",
            "\t. actual\n",
            "\t. frankly\n",
            "\t. sam\n",
            "\t. saved\n",
            "\t. prof\n",
            "\t. hell\n",
            "\t. challenge\n",
            "\t. fall\n",
            "\t. matt\n",
            "\t. moral\n",
            "\t. faith\n",
            "\t. social\n",
            "\t. throw\n",
            "\t. together\n",
            "\t. confused\n",
            "\t. mood\n",
            "\t. give\n",
            "\t. language\n",
            "\t. product\n",
            "\t. hank\n",
            "\t. independent\n",
            "\t. sometimes\n",
            "\t. reminded\n",
            "\t. generation\n",
            "\t. word\n",
            "\t. frank\n",
            "\t. situation\n",
            "\t. thanks\n",
            "\t. adam\n",
            "\t. james\n",
            "\t. political\n",
            "\t. society\n",
            "\t. space\n",
            "\t. alien\n",
            "\t. somewhere\n",
            "\t. sort\n",
            "\t. rest\n",
            "\t. mind\n",
            "\t. cute\n",
            "\t. running\n",
            "\t. harry\n",
            "\t. accent\n",
            "\t. soundtrack\n",
            "\t. wood\n",
            "\t. laughter\n",
            "\t. dream\n",
            "\t. keeping\n",
            "\t. hearted\n",
            "\t. open\n",
            "\t. wrong\n",
            "\t. certainly\n",
            "\t. paul\n",
            "\t. making\n",
            "\t. compare\n",
            "\t. ben\n",
            "\t. academy\n",
            "\t. beyond\n",
            "\t. attention\n",
            "\t. exciting\n",
            "\t. wanted\n",
            "\t. grew\n",
            "\t. youtube\n",
            "\t. single\n",
            "\t. people\n",
            "\t. chance\n",
            "\t. started\n",
            "\t. seven\n",
            "\t. assume\n",
            "\t. cut\n",
            "\t. battle\n",
            "\t. clichés\n",
            "\t. sleep\n",
            "\t. cox\n",
            "\t. smile\n",
            "\t. budget\n",
            "\t. ignore\n",
            "\t. continues\n",
            "\t. buck\n",
            "\t. walking\n",
            "\t. preview\n",
            "\t. stallone\n",
            "\t. quirky\n",
            "\t. change\n",
            "\t. date\n",
            "\t. year\n",
            "\t. wilson\n",
            "\t. shot\n",
            "\t. violent\n",
            "\t. hole\n",
            "\t. warning\n",
            "\t. worth\n",
            "\t. awkward\n",
            "\t. allows\n",
            "\t. whatever\n",
            "\t. fantasy\n",
            "\t. cool\n",
            "\t. substance\n",
            "\t. expect\n",
            "\t. appear\n",
            "\t. realism\n",
            "\t. atmosphere\n",
            "\t. make\n",
            "\t. jason\n",
            "\t. award\n",
            "\t. others\n",
            "\t. psychological\n",
            "\t. happens\n",
            "\t. listen\n",
            "\t. ugly\n",
            "\t. somehow\n",
            "\t. fail\n",
            "\t. unrealistic\n",
            "\t. blockbuster\n",
            "\t. story\n",
            "\t. sense\n",
            "\t. god\n",
            "\t. culture\n",
            "\t. anywhere\n",
            "\t. execution\n",
            "\t. zombie\n",
            "\t. hate\n",
            "\t. fear\n",
            "\t. pace\n",
            "\t. actually\n",
            "\t. view\n",
            "\t. dinosaur\n",
            "\t. effect\n",
            "\t. kill\n",
            "\t. maybe\n",
            "\t. saving\n",
            "\t. bringing\n",
            "\t. tom\n",
            "\t. chris\n",
            "\t. brain\n",
            "\t. nudity\n",
            "\t. comedic\n",
            "\t. important\n",
            "\t. killed\n",
            "\t. indie\n",
            "\t. noise\n",
            "\t. enjoying\n",
            "\t. cheesy\n",
            "\t. epic\n",
            "\t. problem\n",
            "\t. otherwise\n",
            "\t. score\n",
            "\t. intelligent\n",
            "\t. copy\n",
            "\t. nobody\n",
            "\t. called\n",
            "\t. engaging\n",
            "\t. sad\n",
            "\t. seeing\n",
            "\t. clever\n",
            "\t. funny\n",
            "\t. obvious\n",
            "\t. easy\n",
            "\t. somebody\n",
            "\t. stopped\n",
            "\t. play\n",
            "\t. confusing\n",
            "\t. truth\n",
            "\t. mistake\n",
            "\t. act\n",
            "\t. write\n",
            "\t. flaw\n",
            "\t. unusual\n",
            "\t. monster\n",
            "\t. cgi\n",
            "\t. truly\n",
            "\t. series\n",
            "\t. beauty\n",
            "\t. explanation\n",
            "\t. stock\n",
            "\t. favor\n",
            "\t. lighting\n",
            "\t. sat\n",
            "\t. seemed\n",
            "\t. quality\n",
            "\t. john\n",
            "\t. ryan\n",
            "\t. spend\n",
            "\t. edited\n",
            "\t. thin\n",
            "\t. continuity\n",
            "\t. watching\n",
            "\t. quite\n",
            "\t. suppose\n",
            "\t. driven\n",
            "\t. brought\n",
            "\t. tale\n",
            "\t. superhero\n",
            "\t. impressive\n",
            "\t. festival\n",
            "\t. capture\n",
            "\t. fell\n",
            "\t. unnecessary\n",
            "\t. throughout\n",
            "\t. contrived\n",
            "\t. natural\n",
            "\t. strength\n",
            "\t. dimensional\n",
            "\t. pas\n",
            "\t. literally\n",
            "\t. idiot\n",
            "\t. looked\n",
            "\t. actor\n",
            "\t. rent\n",
            "\t. although\n",
            "\t. laughed\n",
            "\t. marvel\n",
            "\t. theater\n",
            "\t. empty\n",
            "\t. moment\n",
            "\t. genre\n",
            "\t. loving\n",
            "\t. expecting\n",
            "\t. torture\n",
            "\t. provides\n",
            "\t. hardly\n",
            "\t. positive\n",
            "\t. dialog\n",
            "\t. sub\n",
            "\t. summer\n",
            "\t. wonder\n",
            "\t. paper\n",
            "\t. nature\n",
            "\t. genius\n",
            "\t. screaming\n",
            "\t. joy\n",
            "\t. top\n",
            "\t. theme\n",
            "\t. cast\n",
            "\t. sandler\n",
            "\t. portrayal\n",
            "\t. deeper\n",
            "\t. tense\n",
            "\t. lovely\n",
            "\t. care\n",
            "\t. criticism\n",
            "\t. personal\n",
            "\t. lacking\n",
            "\t. talent\n",
            "\t. human\n",
            "\t. footage\n",
            "\t. win\n",
            "\t. brutal\n",
            "\t. smart\n",
            "\t. cinematography\n",
            "\t. popcorn\n",
            "\t. wearing\n",
            "\t. cruise\n",
            "\t. expectation\n",
            "\t. chemistry\n",
            "\t. modern\n",
            "\t. something\n",
            "\t. tv\n",
            "\t. cliché\n",
            "\t. breath\n",
            "\t. unbelievable\n",
            "\t. future\n",
            "\t. bottom\n",
            "\t. emotion\n",
            "\t. entertainment\n",
            "\t. saw\n",
            "\t. yes\n",
            "\t. seems\n",
            "\t. thrilling\n",
            "\t. witty\n",
            "\t. perspective\n",
            "\t. forced\n",
            "\t. thing\n",
            "\t. student\n",
            "\t. thought\n",
            "\t. disgusting\n",
            "\t. still\n",
            "\t. suspenseful\n",
            "\t. relate\n",
            "\t. min\n",
            "\t. balance\n",
            "\t. may\n",
            "\t. hoping\n",
            "\t. completely\n",
            "\t. okay\n",
            "\t. scientist\n",
            "\t. shallow\n",
            "\t. adult\n",
            "\t. game\n",
            "\t. basically\n",
            "\t. writer\n",
            "\t. name\n",
            "\t. drunk\n",
            "\t. drama\n",
            "\t. personally\n",
            "\t. review\n",
            "\t. channel\n",
            "\t. batman\n",
            "\t. many\n",
            "\t. violence\n",
            "\t. message\n",
            "\t. romance\n",
            "\t. paid\n",
            "\t. made\n",
            "\t. utterly\n",
            "\t. sound\n",
            "\t. style\n",
            "\t. promising\n",
            "\t. touch\n",
            "\t. tear\n",
            "\t. blah\n",
            "\t. fascinating\n",
            "\t. jon\n",
            "\t. age\n",
            "\t. new\n",
            "\t. laughing\n",
            "\t. experience\n",
            "\t. cash\n",
            "\t. stupidity\n",
            "\t. detail\n",
            "\t. clichéd\n",
            "\t. effort\n",
            "\t. neither\n",
            "\t. think\n",
            "\t. writing\n",
            "\t. failure\n",
            "\t. generic\n",
            "\t. pleasant\n",
            "\t. played\n",
            "\t. terribly\n",
            "\t. gorgeous\n",
            "\t. either\n",
            "\t. treat\n",
            "\t. paint\n",
            "\t. satisfying\n",
            "\t. halfway\n",
            "\t. turkey\n",
            "\t. project\n",
            "\t. simple\n",
            "\t. title\n",
            "\t. premise\n",
            "\t. joke\n",
            "\t. watchable\n",
            "\t. spent\n",
            "\t. rip\n",
            "\t. war\n",
            "\t. supporting\n",
            "\t. disappoint\n",
            "\t. sucked\n",
            "\t. effective\n",
            "\t. editing\n",
            "\t. book\n",
            "\t. ok\n",
            "\t. rare\n",
            "\t. ruined\n",
            "\t. bit\n",
            "\t. keep\n",
            "\t. blame\n",
            "\t. u\n",
            "\t. surprisingly\n",
            "\t. decent\n",
            "\t. charming\n",
            "\t. film\n",
            "\t. overall\n",
            "\t. friendship\n",
            "\t. video\n",
            "\t. nowhere\n",
            "\t. twist\n",
            "\t. thoroughly\n",
            "\t. believable\n",
            "\t. unlike\n",
            "\t. producer\n",
            "\t. except\n",
            "\t. shark\n",
            "\t. production\n",
            "\t. everyone\n",
            "\t. shine\n",
            "\t. cover\n",
            "\t. bored\n",
            "\t. gem\n",
            "\t. cringe\n",
            "\t. complex\n",
            "\t. appreciate\n",
            "\t. nicely\n",
            "\t. dark\n",
            "\t. not\n",
            "\t. try\n",
            "\t. romantic\n",
            "\t. surprise\n",
            "\t. happy\n",
            "\t. sweet\n",
            "\t. camera\n",
            "\t. deserves\n",
            "\t. please\n",
            "\t. favourite\n",
            "\t. someone\n",
            "\t. comic\n",
            "\t. reason\n",
            "\t. supposedly\n",
            "\t. look\n",
            "\t. else\n",
            "\t. spectacular\n",
            "\t. unexpected\n",
            "\t. half\n",
            "\t. brings\n",
            "\t. entertained\n",
            "\t. porn\n",
            "\t. lazy\n",
            "\t. trying\n",
            "\t. recommended\n",
            "\t. plenty\n",
            "\t. masterpiece\n",
            "\t. bunch\n",
            "\t. complaint\n",
            "\t. thriller\n",
            "\t. relationship\n",
            "\t. funniest\n",
            "\t. season\n",
            "\t. plain\n",
            "\t. oh\n",
            "\t. subtle\n",
            "\t. nice\n",
            "\t. especially\n",
            "\t. asylum\n",
            "\t. today\n",
            "\t. grade\n",
            "\t. ever\n",
            "\t. fresh\n",
            "\t. syfy\n",
            "\t. glad\n",
            "\t. fake\n",
            "\t. life\n",
            "\t. paced\n",
            "\t. potential\n",
            "\t. adventure\n",
            "\t. total\n",
            "\t. impressed\n",
            "\t. horribly\n",
            "\t. crappy\n",
            "\t. bond\n",
            "\t. utter\n",
            "\t. predictable\n",
            "\t. opinion\n",
            "\t. plot\n",
            "\t. lot\n",
            "\t. comedy\n",
            "\t. wonderfully\n",
            "\t. shame\n",
            "\t. guess\n",
            "\t. nonsense\n",
            "\t. insult\n",
            "\t. idea\n",
            "\t. ride\n",
            "\t. journey\n",
            "\t. emotional\n",
            "\t. strong\n",
            "\t. world\n",
            "\t. bother\n",
            "\t. irritating\n",
            "\t. dialogue\n",
            "\t. greatest\n",
            "\t. fan\n",
            "\t. notch\n",
            "\t. brilliantly\n",
            "\t. humor\n",
            "\t. disaster\n",
            "\t. anything\n",
            "\t. hour\n",
            "\t. incredible\n",
            "\t. classic\n",
            "\t. cost\n",
            "\t. painfully\n",
            "\t. good\n",
            "\t. random\n",
            "\t. recommend\n",
            "\t. complete\n",
            "\t. realistic\n",
            "\t. true\n",
            "\t. screening\n",
            "\t. disappointment\n",
            "\t. none\n",
            "\t. dumb\n",
            "\t. packed\n",
            "\t. tedious\n",
            "\t. always\n",
            "\t. apparently\n",
            "\t. lack\n",
            "\t. touching\n",
            "\t. also\n",
            "\t. negative\n",
            "\t. powerful\n",
            "\t. embarrassing\n",
            "\t. remotely\n",
            "\t. stunning\n",
            "\t. role\n",
            "\t. weak\n",
            "\t. tried\n",
            "\t. failed\n",
            "\t. forgettable\n",
            "\t. episode\n",
            "\t. pile\n",
            "\t. barely\n",
            "\t. oscar\n",
            "\t. amateur\n",
            "\t. whatsoever\n",
            "\t. disappointing\n",
            "\t. excuse\n",
            "\t. delivers\n",
            "\t. trash\n",
            "\t. terrific\n",
            "\t. sorry\n",
            "\t. skip\n",
            "\t. wooden\n",
            "\t. unique\n",
            "\t. see\n",
            "\t. heart\n",
            "\t. instead\n",
            "\t. supposed\n",
            "\t. sadly\n",
            "\t. intense\n",
            "\t. amateurish\n",
            "\t. underrated\n",
            "\t. dreadful\n",
            "\t. least\n",
            "\t. suck\n",
            "\t. edge\n",
            "\t. mediocre\n",
            "\t. seat\n",
            "\t. zero\n",
            "\t. unless\n",
            "\t. painful\n",
            "\t. atrocious\n",
            "\t. different\n",
            "\t. outstanding\n",
            "\t. beautifully\n",
            "\t. perfectly\n",
            "\t. entertaining\n",
            "\t. solid\n",
            "\t. bland\n",
            "\t. highly\n",
            "\t. rubbish\n",
            "\t. ridiculous\n",
            "\t. flat\n",
            "\t. refreshing\n",
            "\t. job\n",
            "\t. attempt\n",
            "\t. family\n",
            "\t. performance\n",
            "\t. pointless\n",
            "\t. surprised\n",
            "\t. pleasantly\n",
            "\t. beautiful\n",
            "\t. save\n",
            "\t. laughable\n",
            "\t. unfunny\n",
            "\t. favorite\n",
            "\t. acting\n",
            "\t. unfortunately\n",
            "\t. annoying\n",
            "\t. enjoyable\n",
            "\t. hilarious\n",
            "\t. fails\n",
            "\t. pathetic\n",
            "\t. dull\n",
            "\t. cheap\n",
            "\t. redeeming\n",
            "\t. enjoy\n",
            "\t. critic\n",
            "\t. badly\n",
            "\t. liked\n",
            "\t. lame\n",
            "\t. brilliant\n",
            "\t. well\n",
            "\t. action\n",
            "\t. crap\n",
            "\t. mess\n",
            "\t. stupid\n",
            "\t. wonderful\n",
            "\t. avoid\n",
            "\t. even\n",
            "\t. best\n",
            "\t. superb\n",
            "\t. fantastic\n",
            "\t. definitely\n",
            "\t. garbage\n",
            "\t. script\n",
            "\t. awesome\n",
            "\t. wasted\n",
            "\t. minute\n",
            "\t. money\n",
            "\t. love\n",
            "\t. poorly\n",
            "\t. fun\n",
            "\t. amazing\n",
            "\t. nothing\n",
            "\t. horrible\n",
            "\t. perfect\n",
            "\t. excellent\n",
            "\t. enjoyed\n",
            "\t. worse\n",
            "\t. poor\n",
            "\t. loved\n",
            "\t. boring\n",
            "\t. terrible\n",
            "\t. awful\n",
            "\t. waste\n",
            "\t. bad\n",
            "\t. worst\n",
            "\t. great\n",
            "\t# Bigrams :\n",
            "\t. show not\n",
            "\t. film seen\n",
            "\t. original film\n",
            "\t. not see\n",
            "\t. come back\n",
            "\t. movie get\n",
            "\t. something not\n",
            "\t. scene movie\n",
            "\t. screen time\n",
            "\t. not exactly\n",
            "\t. movie make\n",
            "\t. part film\n",
            "\t. even not\n",
            "\t. horror movie\n",
            "\t. watching film\n",
            "\t. character development\n",
            "\t. best part\n",
            "\t. year ago\n",
            "\t. many time\n",
            "\t. good enough\n",
            "\t. want see\n",
            "\t. movie not\n",
            "\t. say not\n",
            "\t. not need\n",
            "\t. end film\n",
            "\t. never seen\n",
            "\t. thing not\n",
            "\t. video game\n",
            "\t. title brazil\n",
            "\t. not movie\n",
            "\t. not mind\n",
            "\t. one time\n",
            "\t. make film\n",
            "\t. budget film\n",
            "\t. first movie\n",
            "\t. fight scene\n",
            "\t. not give\n",
            "\t. not great\n",
            "\t. tv series\n",
            "\t. way not\n",
            "\t. like not\n",
            "\t. every scene\n",
            "\t. good bad\n",
            "\t. not say\n",
            "\t. say movie\n",
            "\t. put together\n",
            "\t. character movie\n",
            "\t. made film\n",
            "\t. die hard\n",
            "\t. well not\n",
            "\t. bad guy\n",
            "\t. year later\n",
            "\t. one thing\n",
            "\t. movie like\n",
            "\t. plot line\n",
            "\t. plot twist\n",
            "\t. know not\n",
            "\t. found footage\n",
            "\t. movie actually\n",
            "\t. main character\n",
            "\t. definitely not\n",
            "\t. second half\n",
            "\t. watch not\n",
            "\t. one film\n",
            "\t. not film\n",
            "\t. looking forward\n",
            "\t. movie time\n",
            "\t. much like\n",
            "\t. every time\n",
            "\t. movie people\n",
            "\t. film like\n",
            "\t. martial art\n",
            "\t. certainly not\n",
            "\t. not think\n",
            "\t. make good\n",
            "\t. movie movie\n",
            "\t. film even\n",
            "\t. sci fi\n",
            "\t. movie first\n",
            "\t. take place\n",
            "\t. not mean\n",
            "\t. story not\n",
            "\t. not feel\n",
            "\t. watch movie\n",
            "\t. throughout movie\n",
            "\t. end not\n",
            "\t. watch film\n",
            "\t. movie still\n",
            "\t. film not\n",
            "\t. people like\n",
            "\t. go back\n",
            "\t. van damme\n",
            "\t. comedy not\n",
            "\t. end movie\n",
            "\t. though not\n",
            "\t. movie never\n",
            "\t. bad thing\n",
            "\t. however not\n",
            "\t. time movie\n",
            "\t. good not\n",
            "\t. movie one\n",
            "\t. film making\n",
            "\t. film make\n",
            "\t. one not\n",
            "\t. not find\n",
            "\t. tv show\n",
            "\t. entire film\n",
            "\t. want watch\n",
            "\t. not sure\n",
            "\t. one movie\n",
            "\t. rest cast\n",
            "\t. horror flick\n",
            "\t. first two\n",
            "\t. everyone else\n",
            "\t. good guy\n",
            "\t. get see\n",
            "\t. first film\n",
            "\t. probably not\n",
            "\t. like one\n",
            "\t. not mention\n",
            "\t. story line\n",
            "\t. visual effect\n",
            "\t. watched movie\n",
            "\t. not come\n",
            "\t. first half\n",
            "\t. type movie\n",
            "\t. like film\n",
            "\t. movie pretty\n",
            "\t. kind movie\n",
            "\t. movie go\n",
            "\t. film really\n",
            "\t. big fan\n",
            "\t. not go\n",
            "\t. not going\n",
            "\t. good one\n",
            "\t. seen movie\n",
            "\t. also not\n",
            "\t. one one\n",
            "\t. every single\n",
            "\t. part movie\n",
            "\t. serial killer\n",
            "\t. scene not\n",
            "\t. give film\n",
            "\t. first one\n",
            "\t. film made\n",
            "\t. zombie movie\n",
            "\t. give movie\n",
            "\t. movie take\n",
            "\t. not get\n",
            "\t. star trek\n",
            "\t. movie start\n",
            "\t. film one\n",
            "\t. movie seen\n",
            "\t. gon na\n",
            "\t. worth watching\n",
            "\t. one day\n",
            "\t. made movie\n",
            "\t. film film\n",
            "\t. budget movie\n",
            "\t. wan na\n",
            "\t. seen film\n",
            "\t. film maker\n",
            "\t. running time\n",
            "\t. best friend\n",
            "\t. give u\n",
            "\t. time not\n",
            "\t. not know\n",
            "\t. take seriously\n",
            "\t. seem like\n",
            "\t. effect not\n",
            "\t. watching movie\n",
            "\t. great actor\n",
            "\t. feel like\n",
            "\t. review movie\n",
            "\t. box office\n",
            "\t. read book\n",
            "\t. not look\n",
            "\t. movie made\n",
            "\t. best thing\n",
            "\t. writer director\n",
            "\t. action scene\n",
            "\t. tell story\n",
            "\t. not want\n",
            "\t. not quite\n",
            "\t. star war\n",
            "\t. one two\n",
            "\t. year old\n",
            "\t. get better\n",
            "\t. not not\n",
            "\t. action sequence\n",
            "\t. movie really\n",
            "\t. not understand\n",
            "\t. funny not\n",
            "\t. better film\n",
            "\t. good actor\n",
            "\t. quite good\n",
            "\t. science fiction\n",
            "\t. scary movie\n",
            "\t. not take\n",
            "\t. film much\n",
            "\t. come across\n",
            "\t. movie watch\n",
            "\t. last year\n",
            "\t. movie also\n",
            "\t. fall love\n",
            "\t. not bad\n",
            "\t. plot not\n",
            "\t. never really\n",
            "\t. not many\n",
            "\t. high school\n",
            "\t. see not\n",
            "\t. not expect\n",
            "\t. although not\n",
            "\t. two hour\n",
            "\t. whole film\n",
            "\t. really like\n",
            "\t. throughout film\n",
            "\t. much better\n",
            "\t. movie think\n",
            "\t. not seem\n",
            "\t. sex scene\n",
            "\t. go watch\n",
            "\t. movie see\n",
            "\t. plot hole\n",
            "\t. one scene\n",
            "\t. something like\n",
            "\t. still not\n",
            "\t. last minute\n",
            "\t. can not\n",
            "\t. along way\n",
            "\t. make movie\n",
            "\t. movie even\n",
            "\t. one point\n",
            "\t. make laugh\n",
            "\t. film also\n",
            "\t. movie much\n",
            "\t. good film\n",
            "\t. like movie\n",
            "\t. even though\n",
            "\t. one liner\n",
            "\t. film ever\n",
            "\t. yet another\n",
            "\t. production value\n",
            "\t. character not\n",
            "\t. anything else\n",
            "\t. camera work\n",
            "\t. new york\n",
            "\t. pretty much\n",
            "\t. special effect\n",
            "\t. ever made\n",
            "\t. first place\n",
            "\t. not expecting\n",
            "\t. film good\n",
            "\t. real life\n",
            "\t. never get\n",
            "\t. not seen\n",
            "\t. not really\n",
            "\t. little bit\n",
            "\t. horror film\n",
            "\t. not always\n",
            "\t. movie year\n",
            "\t. beginning end\n",
            "\t. not let\n",
            "\t. making movie\n",
            "\t. good acting\n",
            "\t. b movie\n",
            "\t. start finish\n",
            "\t. good story\n",
            "\t. movie well\n",
            "\t. not help\n",
            "\t. think movie\n",
            "\t. low budget\n",
            "\t. better movie\n",
            "\t. actor not\n",
            "\t. felt like\n",
            "\t. whole movie\n",
            "\t. half hour\n",
            "\t. good movie\n",
            "\t. thought movie\n",
            "\t. first time\n",
            "\t. everything else\n",
            "\t. not one\n",
            "\t. get back\n",
            "\t. really really\n",
            "\t. film well\n",
            "\t. thing movie\n",
            "\t. recommend movie\n",
            "\t. horror fan\n",
            "\t. saw movie\n",
            "\t. entire movie\n",
            "\t. must say\n",
            "\t. not scary\n",
            "\t. long time\n",
            "\t. love story\n",
            "\t. supporting cast\n",
            "\t. comic book\n",
            "\t. one better\n",
            "\t. seemed like\n",
            "\t. something else\n",
            "\t. pretty good\n",
            "\t. big screen\n",
            "\t. last night\n",
            "\t. well made\n",
            "\t. people not\n",
            "\t. not believe\n",
            "\t. like watching\n",
            "\t. see film\n",
            "\t. lot people\n",
            "\t. not anything\n",
            "\t. minute movie\n",
            "\t. seems like\n",
            "\t. not care\n",
            "\t. not much\n",
            "\t. acting not\n",
            "\t. bad good\n",
            "\t. simply not\n",
            "\t. laugh loud\n",
            "\t. movie good\n",
            "\t. really not\n",
            "\t. work well\n",
            "\t. many people\n",
            "\t. sound like\n",
            "\t. nothing else\n",
            "\t. action film\n",
            "\t. romantic comedy\n",
            "\t. good thing\n",
            "\t. movie definitely\n",
            "\t. acting good\n",
            "\t. looked like\n",
            "\t. please not\n",
            "\t. enjoy movie\n",
            "\t. fun watch\n",
            "\t. good idea\n",
            "\t. movie lot\n",
            "\t. action movie\n",
            "\t. not bother\n",
            "\t. not best\n",
            "\t. good job\n",
            "\t. whole thing\n",
            "\t. even better\n",
            "\t. first minute\n",
            "\t. not like\n",
            "\t. see movie\n",
            "\t. one favorite\n",
            "\t. lot fun\n",
            "\t. movie ever\n",
            "\t. good time\n",
            "\t. great film\n",
            "\t. worth watch\n",
            "\t. not watch\n",
            "\t. not enough\n",
            "\t. really liked\n",
            "\t. film great\n",
            "\t. make sense\n",
            "\t. bad film\n",
            "\t. not work\n",
            "\t. not wait\n",
            "\t. may not\n",
            "\t. ever seen\n",
            "\t. best film\n",
            "\t. top notch\n",
            "\t. fun movie\n",
            "\t. really good\n",
            "\t. not good\n",
            "\t. not make\n",
            "\t. love movie\n",
            "\t. bad not\n",
            "\t. well written\n",
            "\t. bad bad\n",
            "\t. not disappointed\n",
            "\t. bad review\n",
            "\t. not recommend\n",
            "\t. negative review\n",
            "\t. movie bad\n",
            "\t. edge seat\n",
            "\t. worst film\n",
            "\t. enjoyed movie\n",
            "\t. pleasantly surprised\n",
            "\t. movie great\n",
            "\t. even worse\n",
            "\t. highly recommend\n",
            "\t. well done\n",
            "\t. not funny\n",
            "\t. acting bad\n",
            "\t. go see\n",
            "\t. great movie\n",
            "\t. must see\n",
            "\t. look like\n",
            "\t. great job\n",
            "\t. really bad\n",
            "\t. best movie\n",
            "\t. really enjoyed\n",
            "\t. not worth\n",
            "\t. bad movie\n",
            "\t. bad acting\n",
            "\t. one worst\n",
            "\t. one best\n",
            "\t. not waste\n",
            "\t. worst movie\n",
            "\t. not even\n",
            "\t. waste time\n",
            "\t# Trigrams :\n",
            "\t. movie ever made\n",
            "\t. movie ever seen\n",
            "\t. not waste time\n",
            "\t. worst movie ever\n",
            "2. 0 :\n",
            "\t# Unigrams :\n",
            "\t. blow\n",
            "\t. climax\n",
            "\t. na\n",
            "\t. forever\n",
            "\t. category\n",
            "\t. behind\n",
            "\t. decides\n",
            "\t. e\n",
            "\t. pick\n",
            "\t. content\n",
            "\t. roger\n",
            "\t. came\n",
            "\t. round\n",
            "\t. dying\n",
            "\t. notice\n",
            "\t. reach\n",
            "\t. hurt\n",
            "\t. risk\n",
            "\t. television\n",
            "\t. search\n",
            "\t. fighter\n",
            "\t. likely\n",
            "\t. consider\n",
            "\t. speech\n",
            "\t. lady\n",
            "\t. twice\n",
            "\t. presence\n",
            "\t. murder\n",
            "\t. process\n",
            "\t. witness\n",
            "\t. suspect\n",
            "\t. gag\n",
            "\t. dvd\n",
            "\t. angel\n",
            "\t. technical\n",
            "\t. former\n",
            "\t. police\n",
            "\t. opposite\n",
            "\t. formula\n",
            "\t. khan\n",
            "\t. impossible\n",
            "\t. outside\n",
            "\t. order\n",
            "\t. known\n",
            "\t. queen\n",
            "\t. display\n",
            "\t. president\n",
            "\t. leaving\n",
            "\t. santa\n",
            "\t. third\n",
            "\t. jaw\n",
            "\t. doctor\n",
            "\t. plus\n",
            "\t. pair\n",
            "\t. existence\n",
            "\t. difficult\n",
            "\t. manner\n",
            "\t. japanese\n",
            "\t. worked\n",
            "\t. voice\n",
            "\t. campy\n",
            "\t. vampire\n",
            "\t. main\n",
            "\t. opening\n",
            "\t. doubt\n",
            "\t. damn\n",
            "\t. introduced\n",
            "\t. major\n",
            "\t. soldier\n",
            "\t. working\n",
            "\t. aware\n",
            "\t. face\n",
            "\t. jackie\n",
            "\t. dr\n",
            "\t. candy\n",
            "\t. later\n",
            "\t. drawn\n",
            "\t. hall\n",
            "\t. wan\n",
            "\t. ups\n",
            "\t. therefore\n",
            "\t. box\n",
            "\t. girlfriend\n",
            "\t. sport\n",
            "\t. entry\n",
            "\t. however\n",
            "\t. appealing\n",
            "\t. bone\n",
            "\t. designed\n",
            "\t. teenage\n",
            "\t. sheer\n",
            "\t. bollywood\n",
            "\t. number\n",
            "\t. prove\n",
            "\t. released\n",
            "\t. blood\n",
            "\t. jump\n",
            "\t. army\n",
            "\t. sword\n",
            "\t. regular\n",
            "\t. push\n",
            "\t. gangster\n",
            "\t. filmmaker\n",
            "\t. despite\n",
            "\t. knew\n",
            "\t. various\n",
            "\t. singer\n",
            "\t. extremely\n",
            "\t. v\n",
            "\t. developed\n",
            "\t. public\n",
            "\t. insane\n",
            "\t. ring\n",
            "\t. wish\n",
            "\t. table\n",
            "\t. wolf\n",
            "\t. crude\n",
            "\t. protagonist\n",
            "\t. teacher\n",
            "\t. famous\n",
            "\t. core\n",
            "\t. acted\n",
            "\t. accept\n",
            "\t. playing\n",
            "\t. bird\n",
            "\t. board\n",
            "\t. eric\n",
            "\t. chick\n",
            "\t. wake\n",
            "\t. leading\n",
            "\t. clue\n",
            "\t. food\n",
            "\t. naturally\n",
            "\t. evil\n",
            "\t. g\n",
            "\t. party\n",
            "\t. hotel\n",
            "\t. realized\n",
            "\t. skin\n",
            "\t. threat\n",
            "\t. suggest\n",
            "\t. common\n",
            "\t. excited\n",
            "\t. curious\n",
            "\t. expression\n",
            "\t. pop\n",
            "\t. thus\n",
            "\t. cop\n",
            "\t. frame\n",
            "\t. meanwhile\n",
            "\t. mental\n",
            "\t. forest\n",
            "\t. capable\n",
            "\t. page\n",
            "\t. singing\n",
            "\t. context\n",
            "\t. fame\n",
            "\t. russian\n",
            "\t. deadly\n",
            "\t. bar\n",
            "\t. offer\n",
            "\t. included\n",
            "\t. somewhat\n",
            "\t. realize\n",
            "\t. jr\n",
            "\t. fate\n",
            "\t. roll\n",
            "\t. particularly\n",
            "\t. leader\n",
            "\t. field\n",
            "\t. k\n",
            "\t. everybody\n",
            "\t. mentioned\n",
            "\t. immediately\n",
            "\t. dirty\n",
            "\t. match\n",
            "\t. whose\n",
            "\t. weapon\n",
            "\t. adding\n",
            "\t. going\n",
            "\t. driver\n",
            "\t. skill\n",
            "\t. conclusion\n",
            "\t. onto\n",
            "\t. willing\n",
            "\t. south\n",
            "\t. early\n",
            "\t. recall\n",
            "\t. scenario\n",
            "\t. matter\n",
            "\t. heard\n",
            "\t. goofy\n",
            "\t. black\n",
            "\t. shock\n",
            "\t. doll\n",
            "\t. ii\n",
            "\t. fly\n",
            "\t. base\n",
            "\t. door\n",
            "\t. spider\n",
            "\t. arm\n",
            "\t. fred\n",
            "\t. know\n",
            "\t. jungle\n",
            "\t. creator\n",
            "\t. close\n",
            "\t. player\n",
            "\t. animal\n",
            "\t. provide\n",
            "\t. followed\n",
            "\t. need\n",
            "\t. mindless\n",
            "\t. hunter\n",
            "\t. lead\n",
            "\t. late\n",
            "\t. track\n",
            "\t. franchise\n",
            "\t. loses\n",
            "\t. away\n",
            "\t. whilst\n",
            "\t. ball\n",
            "\t. connection\n",
            "\t. praise\n",
            "\t. fighting\n",
            "\t. create\n",
            "\t. raise\n",
            "\t. named\n",
            "\t. drug\n",
            "\t. limited\n",
            "\t. test\n",
            "\t. stage\n",
            "\t. spoof\n",
            "\t. richard\n",
            "\t. instance\n",
            "\t. two\n",
            "\t. superior\n",
            "\t. rich\n",
            "\t. structure\n",
            "\t. lose\n",
            "\t. casting\n",
            "\t. christian\n",
            "\t. mid\n",
            "\t. dance\n",
            "\t. changed\n",
            "\t. mass\n",
            "\t. cross\n",
            "\t. add\n",
            "\t. activity\n",
            "\t. martial\n",
            "\t. happen\n",
            "\t. hunt\n",
            "\t. cant\n",
            "\t. six\n",
            "\t. finished\n",
            "\t. loose\n",
            "\t. plan\n",
            "\t. folk\n",
            "\t. behavior\n",
            "\t. shown\n",
            "\t. overly\n",
            "\t. say\n",
            "\t. related\n",
            "\t. sky\n",
            "\t. p\n",
            "\t. mountain\n",
            "\t. industry\n",
            "\t. fight\n",
            "\t. trouble\n",
            "\t. anti\n",
            "\t. respect\n",
            "\t. band\n",
            "\t. finish\n",
            "\t. group\n",
            "\t. n\n",
            "\t. wall\n",
            "\t. la\n",
            "\t. considering\n",
            "\t. nightmare\n",
            "\t. anyway\n",
            "\t. paris\n",
            "\t. dad\n",
            "\t. massive\n",
            "\t. standing\n",
            "\t. nasty\n",
            "\t. kind\n",
            "\t. italian\n",
            "\t. mad\n",
            "\t. regardless\n",
            "\t. ahead\n",
            "\t. burn\n",
            "\t. german\n",
            "\t. remake\n",
            "\t. blue\n",
            "\t. forward\n",
            "\t. escape\n",
            "\t. bought\n",
            "\t. station\n",
            "\t. carry\n",
            "\t. site\n",
            "\t. remember\n",
            "\t. pacing\n",
            "\t. longer\n",
            "\t. sequence\n",
            "\t. pack\n",
            "\t. note\n",
            "\t. set\n",
            "\t. much\n",
            "\t. held\n",
            "\t. hill\n",
            "\t. credit\n",
            "\t. target\n",
            "\t. want\n",
            "\t. glass\n",
            "\t. silent\n",
            "\t. race\n",
            "\t. indian\n",
            "\t. supernatural\n",
            "\t. compared\n",
            "\t. strange\n",
            "\t. background\n",
            "\t. business\n",
            "\t. plane\n",
            "\t. ordinary\n",
            "\t. ask\n",
            "\t. hear\n",
            "\t. self\n",
            "\t. involving\n",
            "\t. mine\n",
            "\t. stop\n",
            "\t. meant\n",
            "\t. shocking\n",
            "\t. van\n",
            "\t. brazil\n",
            "\t. reading\n",
            "\t. passed\n",
            "\t. particular\n",
            "\t. buy\n",
            "\t. missed\n",
            "\t. predator\n",
            "\t. watched\n",
            "\t. extreme\n",
            "\t. town\n",
            "\t. fi\n",
            "\t. lie\n",
            "\t. information\n",
            "\t. stephen\n",
            "\t. upon\n",
            "\t. internet\n",
            "\t. decision\n",
            "\t. version\n",
            "\t. male\n",
            "\t. sci\n",
            "\t. highlight\n",
            "\t. explosion\n",
            "\t. stuff\n",
            "\t. soon\n",
            "\t. treated\n",
            "\t. earlier\n",
            "\t. married\n",
            "\t. root\n",
            "\t. putting\n",
            "\t. death\n",
            "\t. equally\n",
            "\t. college\n",
            "\t. terror\n",
            "\t. bizarre\n",
            "\t. reveal\n",
            "\t. mention\n",
            "\t. collection\n",
            "\t. sexual\n",
            "\t. revenge\n",
            "\t. boyfriend\n",
            "\t. perhaps\n",
            "\t. directed\n",
            "\t. help\n",
            "\t. led\n",
            "\t. pretty\n",
            "\t. flesh\n",
            "\t. reaction\n",
            "\t. government\n",
            "\t. towards\n",
            "\t. beat\n",
            "\t. sight\n",
            "\t. ticket\n",
            "\t. rarely\n",
            "\t. studio\n",
            "\t. became\n",
            "\t. break\n",
            "\t. com\n",
            "\t. flick\n",
            "\t. vote\n",
            "\t. british\n",
            "\t. mysterious\n",
            "\t. subject\n",
            "\t. moon\n",
            "\t. three\n",
            "\t. involves\n",
            "\t. anyone\n",
            "\t. darkness\n",
            "\t. charles\n",
            "\t. gross\n",
            "\t. considered\n",
            "\t. texas\n",
            "\t. majority\n",
            "\t. high\n",
            "\t. french\n",
            "\t. angle\n",
            "\t. west\n",
            "\t. psycho\n",
            "\t. century\n",
            "\t. latter\n",
            "\t. snow\n",
            "\t. animation\n",
            "\t. saying\n",
            "\t. long\n",
            "\t. area\n",
            "\t. affair\n",
            "\t. heroine\n",
            "\t. clear\n",
            "\t. scream\n",
            "\t. continue\n",
            "\t. rise\n",
            "\t. normally\n",
            "\t. told\n",
            "\t. ready\n",
            "\t. far\n",
            "\t. account\n",
            "\t. becomes\n",
            "\t. loss\n",
            "\t. chinese\n",
            "\t. fellow\n",
            "\t. sick\n",
            "\t. l\n",
            "\t. honest\n",
            "\t. cult\n",
            "\t. middle\n",
            "\t. gang\n",
            "\t. kelly\n",
            "\t. place\n",
            "\t. felt\n",
            "\t. level\n",
            "\t. personality\n",
            "\t. green\n",
            "\t. back\n",
            "\t. criminal\n",
            "\t. crew\n",
            "\t. intelligence\n",
            "\t. occasionally\n",
            "\t. factor\n",
            "\t. term\n",
            "\t. state\n",
            "\t. movement\n",
            "\t. learn\n",
            "\t. damme\n",
            "\t. force\n",
            "\t. drive\n",
            "\t. leaf\n",
            "\t. detective\n",
            "\t. watch\n",
            "\t. grab\n",
            "\t. fire\n",
            "\t. hot\n",
            "\t. home\n",
            "\t. artistic\n",
            "\t. central\n",
            "\t. legend\n",
            "\t. decade\n",
            "\t. come\n",
            "\t. etc\n",
            "\t. ice\n",
            "\t. record\n",
            "\t. mike\n",
            "\t. attack\n",
            "\t. aside\n",
            "\t. seemingly\n",
            "\t. cartoon\n",
            "\t. worthy\n",
            "\t. amount\n",
            "\t. every\n",
            "\t. bank\n",
            "\t. length\n",
            "\t. teen\n",
            "\t. hide\n",
            "\t. afraid\n",
            "\t. gary\n",
            "\t. remains\n",
            "\t. tony\n",
            "\t. taste\n",
            "\t. depth\n",
            "\t. successful\n",
            "\t. demon\n",
            "\t. news\n",
            "\t. built\n",
            "\t. mystery\n",
            "\t. intended\n",
            "\t. foot\n",
            "\t. wit\n",
            "\t. department\n",
            "\t. artist\n",
            "\t. gave\n",
            "\t. danger\n",
            "\t. everything\n",
            "\t. screenwriter\n",
            "\t. dragon\n",
            "\t. asked\n",
            "\t. interview\n",
            "\t. water\n",
            "\t. ruin\n",
            "\t. grand\n",
            "\t. indeed\n",
            "\t. location\n",
            "\t. extra\n",
            "\t. punch\n",
            "\t. actress\n",
            "\t. slightly\n",
            "\t. brian\n",
            "\t. getting\n",
            "\t. floor\n",
            "\t. move\n",
            "\t. military\n",
            "\t. body\n",
            "\t. relatively\n",
            "\t. jean\n",
            "\t. conversation\n",
            "\t. leave\n",
            "\t. hospital\n",
            "\t. visit\n",
            "\t. bear\n",
            "\t. telling\n",
            "\t. english\n",
            "\t. ghost\n",
            "\t. feature\n",
            "\t. parody\n",
            "\t. begin\n",
            "\t. bet\n",
            "\t. trust\n",
            "\t. curse\n",
            "\t. latest\n",
            "\t. fault\n",
            "\t. scare\n",
            "\t. granted\n",
            "\t. though\n",
            "\t. eating\n",
            "\t. small\n",
            "\t. forgotten\n",
            "\t. spoiler\n",
            "\t. paranormal\n",
            "\t. fill\n",
            "\t. cameron\n",
            "\t. spy\n",
            "\t. charlie\n",
            "\t. convincing\n",
            "\t. million\n",
            "\t. across\n",
            "\t. survive\n",
            "\t. serial\n",
            "\t. thats\n",
            "\t. street\n",
            "\t. general\n",
            "\t. ultimately\n",
            "\t. regret\n",
            "\t. park\n",
            "\t. pull\n",
            "\t. friday\n",
            "\t. gone\n",
            "\t. danny\n",
            "\t. went\n",
            "\t. gay\n",
            "\t. regard\n",
            "\t. delivery\n",
            "\t. brief\n",
            "\t. warrior\n",
            "\t. including\n",
            "\t. source\n",
            "\t. featuring\n",
            "\t. able\n",
            "\t. billy\n",
            "\t. safe\n",
            "\t. looking\n",
            "\t. created\n",
            "\t. inside\n",
            "\t. sister\n",
            "\t. revealed\n",
            "\t. mr\n",
            "\t. absolutely\n",
            "\t. disappointed\n",
            "\t. rescue\n",
            "\t. research\n",
            "\t. claim\n",
            "\t. goal\n",
            "\t. allowed\n",
            "\t. near\n",
            "\t. travel\n",
            "\t. ability\n",
            "\t. image\n",
            "\t. answer\n",
            "\t. driving\n",
            "\t. co\n",
            "\t. picture\n",
            "\t. private\n",
            "\t. motion\n",
            "\t. meeting\n",
            "\t. cat\n",
            "\t. us\n",
            "\t. white\n",
            "\t. veteran\n",
            "\t. weekend\n",
            "\t. wind\n",
            "\t. difference\n",
            "\t. intention\n",
            "\t. decide\n",
            "\t. speaking\n",
            "\t. patrick\n",
            "\t. period\n",
            "\t. village\n",
            "\t. car\n",
            "\t. buddy\n",
            "\t. cause\n",
            "\t. jessica\n",
            "\t. nail\n",
            "\t. trip\n",
            "\t. toy\n",
            "\t. helped\n",
            "\t. put\n",
            "\t. rush\n",
            "\t. drop\n",
            "\t. teenager\n",
            "\t. movie\n",
            "\t. got\n",
            "\t. inspired\n",
            "\t. control\n",
            "\t. opportunity\n",
            "\t. necessary\n",
            "\t. anderson\n",
            "\t. walk\n",
            "\t. princess\n",
            "\t. lucky\n",
            "\t. lived\n",
            "\t. church\n",
            "\t. pain\n",
            "\t. segment\n",
            "\t. scene\n",
            "\t. hated\n",
            "\t. available\n",
            "\t. baby\n",
            "\t. community\n",
            "\t. x\n",
            "\t. follow\n",
            "\t. ray\n",
            "\t. boy\n",
            "\t. professor\n",
            "\t. narrative\n",
            "\t. jackson\n",
            "\t. thankfully\n",
            "\t. odd\n",
            "\t. room\n",
            "\t. constantly\n",
            "\t. old\n",
            "\t. slowly\n",
            "\t. entirely\n",
            "\t. fish\n",
            "\t. gore\n",
            "\t. mirror\n",
            "\t. science\n",
            "\t. tragedy\n",
            "\t. multiple\n",
            "\t. magic\n",
            "\t. massacre\n",
            "\t. franco\n",
            "\t. said\n",
            "\t. gun\n",
            "\t. secret\n",
            "\t. without\n",
            "\t. desert\n",
            "\t. deserve\n",
            "\t. american\n",
            "\t. showed\n",
            "\t. four\n",
            "\t. thousand\n",
            "\t. support\n",
            "\t. storyline\n",
            "\t. waiting\n",
            "\t. dare\n",
            "\t. draw\n",
            "\t. sequel\n",
            "\t. purpose\n",
            "\t. figure\n",
            "\t. soul\n",
            "\t. market\n",
            "\t. exactly\n",
            "\t. rule\n",
            "\t. men\n",
            "\t. william\n",
            "\t. turning\n",
            "\t. promise\n",
            "\t. alan\n",
            "\t. heavily\n",
            "\t. blair\n",
            "\t. flow\n",
            "\t. merely\n",
            "\t. viewer\n",
            "\t. includes\n",
            "\t. mostly\n",
            "\t. month\n",
            "\t. sexy\n",
            "\t. use\n",
            "\t. lord\n",
            "\t. ended\n",
            "\t. amusing\n",
            "\t. london\n",
            "\t. agree\n",
            "\t. office\n",
            "\t. cameo\n",
            "\t. corny\n",
            "\t. living\n",
            "\t. fairy\n",
            "\t. fox\n",
            "\t. partner\n",
            "\t. introduction\n",
            "\t. trailer\n",
            "\t. within\n",
            "\t. trek\n",
            "\t. mom\n",
            "\t. recently\n",
            "\t. law\n",
            "\t. lee\n",
            "\t. mile\n",
            "\t. flash\n",
            "\t. time\n",
            "\t. planet\n",
            "\t. red\n",
            "\t. really\n",
            "\t. belief\n",
            "\t. music\n",
            "\t. met\n",
            "\t. ending\n",
            "\t. end\n",
            "\t. device\n",
            "\t. taken\n",
            "\t. lesson\n",
            "\t. nearly\n",
            "\t. following\n",
            "\t. pie\n",
            "\t. showing\n",
            "\t. taking\n",
            "\t. encounter\n",
            "\t. daughter\n",
            "\t. jake\n",
            "\t. range\n",
            "\t. follows\n",
            "\t. crash\n",
            "\t. edward\n",
            "\t. hundred\n",
            "\t. bloody\n",
            "\t. christopher\n",
            "\t. count\n",
            "\t. allen\n",
            "\t. cold\n",
            "\t. admit\n",
            "\t. load\n",
            "\t. picked\n",
            "\t. gold\n",
            "\t. wedding\n",
            "\t. added\n",
            "\t. heck\n",
            "\t. gon\n",
            "\t. slapstick\n",
            "\t. commentary\n",
            "\t. villain\n",
            "\t. giving\n",
            "\t. progress\n",
            "\t. miss\n",
            "\t. cry\n",
            "\t. mainly\n",
            "\t. memory\n",
            "\t. way\n",
            "\t. handle\n",
            "\t. color\n",
            "\t. career\n",
            "\t. country\n",
            "\t. hidden\n",
            "\t. imagination\n",
            "\t. jones\n",
            "\t. mark\n",
            "\t. likable\n",
            "\t. twenty\n",
            "\t. given\n",
            "\t. presented\n",
            "\t. technique\n",
            "\t. frightening\n",
            "\t. concept\n",
            "\t. final\n",
            "\t. pulled\n",
            "\t. charm\n",
            "\t. design\n",
            "\t. die\n",
            "\t. innocent\n",
            "\t. falling\n",
            "\t. trick\n",
            "\t. destroy\n",
            "\t. hero\n",
            "\t. hand\n",
            "\t. wife\n",
            "\t. clearly\n",
            "\t. release\n",
            "\t. among\n",
            "\t. dog\n",
            "\t. born\n",
            "\t. computer\n",
            "\t. mother\n",
            "\t. couple\n",
            "\t. holiday\n",
            "\t. unknown\n",
            "\t. hey\n",
            "\t. list\n",
            "\t. focused\n",
            "\t. generally\n",
            "\t. angry\n",
            "\t. bed\n",
            "\t. cage\n",
            "\t. company\n",
            "\t. eat\n",
            "\t. original\n",
            "\t. stunt\n",
            "\t. alive\n",
            "\t. system\n",
            "\t. pay\n",
            "\t. bill\n",
            "\t. part\n",
            "\t. quickly\n",
            "\t. beginning\n",
            "\t. bright\n",
            "\t. bullet\n",
            "\t. deserved\n",
            "\t. written\n",
            "\t. island\n",
            "\t. whole\n",
            "\t. deliver\n",
            "\t. fact\n",
            "\t. relief\n",
            "\t. meaning\n",
            "\t. robin\n",
            "\t. seen\n",
            "\t. eight\n",
            "\t. constant\n",
            "\t. taylor\n",
            "\t. front\n",
            "\t. twilight\n",
            "\t. model\n",
            "\t. exception\n",
            "\t. satire\n",
            "\t. costume\n",
            "\t. using\n",
            "\t. stranger\n",
            "\t. responsible\n",
            "\t. sell\n",
            "\t. interesting\n",
            "\t. whether\n",
            "\t. song\n",
            "\t. grow\n",
            "\t. creating\n",
            "\t. interested\n",
            "\t. form\n",
            "\t. price\n",
            "\t. kid\n",
            "\t. check\n",
            "\t. shocked\n",
            "\t. proved\n",
            "\t. big\n",
            "\t. character\n",
            "\t. aspect\n",
            "\t. missing\n",
            "\t. return\n",
            "\t. stone\n",
            "\t. wait\n",
            "\t. enemy\n",
            "\t. forget\n",
            "\t. vehicle\n",
            "\t. tend\n",
            "\t. mask\n",
            "\t. rushed\n",
            "\t. probably\n",
            "\t. house\n",
            "\t. week\n",
            "\t. cinematic\n",
            "\t. willis\n",
            "\t. spirit\n",
            "\t. let\n",
            "\t. musical\n",
            "\t. russell\n",
            "\t. exist\n",
            "\t. bruce\n",
            "\t. western\n",
            "\t. sure\n",
            "\t. another\n",
            "\t. paying\n",
            "\t. degree\n",
            "\t. rob\n",
            "\t. grown\n",
            "\t. higher\n",
            "\t. discover\n",
            "\t. johnson\n",
            "\t. desire\n",
            "\t. america\n",
            "\t. direction\n",
            "\t. previous\n",
            "\t. luck\n",
            "\t. tree\n",
            "\t. murphy\n",
            "\t. several\n",
            "\t. george\n",
            "\t. eddie\n",
            "\t. sarah\n",
            "\t. tension\n",
            "\t. explain\n",
            "\t. boat\n",
            "\t. knowledge\n",
            "\t. morgan\n",
            "\t. storytelling\n",
            "\t. husband\n",
            "\t. find\n",
            "\t. sheriff\n",
            "\t. center\n",
            "\t. dangerous\n",
            "\t. night\n",
            "\t. scale\n",
            "\t. flashback\n",
            "\t. question\n",
            "\t. basic\n",
            "\t. blade\n",
            "\t. success\n",
            "\t. creature\n",
            "\t. loud\n",
            "\t. train\n",
            "\t. bomb\n",
            "\t. theatre\n",
            "\t. marriage\n",
            "\t. identity\n",
            "\t. similar\n",
            "\t. obviously\n",
            "\t. ton\n",
            "\t. hopefully\n",
            "\t. hope\n",
            "\t. next\n",
            "\t. chase\n",
            "\t. left\n",
            "\t. died\n",
            "\t. line\n",
            "\t. build\n",
            "\t. bos\n",
            "\t. julia\n",
            "\t. bob\n",
            "\t. path\n",
            "\t. screenplay\n",
            "\t. till\n",
            "\t. camp\n",
            "\t. rated\n",
            "\t. focus\n",
            "\t. special\n",
            "\t. snake\n",
            "\t. entertain\n",
            "\t. mary\n",
            "\t. screen\n",
            "\t. typical\n",
            "\t. since\n",
            "\t. witch\n",
            "\t. truck\n",
            "\t. conflict\n",
            "\t. normal\n",
            "\t. directing\n",
            "\t. robert\n",
            "\t. surface\n",
            "\t. eye\n",
            "\t. j\n",
            "\t. used\n",
            "\t. christmas\n",
            "\t. meet\n",
            "\t. straight\n",
            "\t. master\n",
            "\t. choice\n",
            "\t. commercial\n",
            "\t. captain\n",
            "\t. documentary\n",
            "\t. believe\n",
            "\t. mean\n",
            "\t. clean\n",
            "\t. wear\n",
            "\t. proper\n",
            "\t. study\n",
            "\t. rock\n",
            "\t. stand\n",
            "\t. disney\n",
            "\t. moved\n",
            "\t. beach\n",
            "\t. hollywood\n",
            "\t. impact\n",
            "\t. sean\n",
            "\t. store\n",
            "\t. physical\n",
            "\t. creative\n",
            "\t. case\n",
            "\t. max\n",
            "\t. average\n",
            "\t. direct\n",
            "\t. le\n",
            "\t. drink\n",
            "\t. stay\n",
            "\t. victim\n",
            "\t. friend\n",
            "\t. impression\n",
            "\t. winning\n",
            "\t. seem\n",
            "\t. wild\n",
            "\t. crowd\n",
            "\t. johnny\n",
            "\t. bag\n",
            "\t. animated\n",
            "\t. low\n",
            "\t. ship\n",
            "\t. show\n",
            "\t. historical\n",
            "\t. mission\n",
            "\t. gory\n",
            "\t. non\n",
            "\t. speak\n",
            "\t. jamie\n",
            "\t. rating\n",
            "\t. mix\n",
            "\t. peter\n",
            "\t. read\n",
            "\t. king\n",
            "\t. jim\n",
            "\t. dozen\n",
            "\t. exact\n",
            "\t. window\n",
            "\t. produced\n",
            "\t. david\n",
            "\t. wanting\n",
            "\t. kept\n",
            "\t. dude\n",
            "\t. suit\n",
            "\t. feeling\n",
            "\t. hit\n",
            "\t. course\n",
            "\t. happening\n",
            "\t. explained\n",
            "\t. technology\n",
            "\t. bigger\n",
            "\t. dislike\n",
            "\t. step\n",
            "\t. caught\n",
            "\t. repeat\n",
            "\t. passion\n",
            "\t. beast\n",
            "\t. dramatic\n",
            "\t. scared\n",
            "\t. de\n",
            "\t. younger\n",
            "\t. event\n",
            "\t. vision\n",
            "\t. r\n",
            "\t. alright\n",
            "\t. art\n",
            "\t. apparent\n",
            "\t. soft\n",
            "\t. filmed\n",
            "\t. go\n",
            "\t. almost\n",
            "\t. era\n",
            "\t. stuck\n",
            "\t. understanding\n",
            "\t. crime\n",
            "\t. ten\n",
            "\t. apart\n",
            "\t. originality\n",
            "\t. past\n",
            "\t. grace\n",
            "\t. pg\n",
            "\t. manage\n",
            "\t. type\n",
            "\t. essentially\n",
            "\t. certain\n",
            "\t. mouth\n",
            "\t. wrote\n",
            "\t. hold\n",
            "\t. intriguing\n",
            "\t. talking\n",
            "\t. hard\n",
            "\t. fair\n",
            "\t. standard\n",
            "\t. anymore\n",
            "\t. super\n",
            "\t. attitude\n",
            "\t. lower\n",
            "\t. gratuitous\n",
            "\t. key\n",
            "\t. struggle\n",
            "\t. totally\n",
            "\t. joe\n",
            "\t. work\n",
            "\t. done\n",
            "\t. slow\n",
            "\t. biggest\n",
            "\t. jennifer\n",
            "\t. short\n",
            "\t. call\n",
            "\t. anna\n",
            "\t. incredibly\n",
            "\t. material\n",
            "\t. imdb\n",
            "\t. spielberg\n",
            "\t. mixed\n",
            "\t. appropriate\n",
            "\t. winner\n",
            "\t. exploitation\n",
            "\t. silly\n",
            "\t. share\n",
            "\t. suspense\n",
            "\t. child\n",
            "\t. wide\n",
            "\t. star\n",
            "\t. turned\n",
            "\t. dead\n",
            "\t. honestly\n",
            "\t. entire\n",
            "\t. stick\n",
            "\t. contains\n",
            "\t. nazi\n",
            "\t. current\n",
            "\t. experiment\n",
            "\t. anybody\n",
            "\t. five\n",
            "\t. golden\n",
            "\t. andrew\n",
            "\t. girl\n",
            "\t. start\n",
            "\t. cable\n",
            "\t. breaking\n",
            "\t. bring\n",
            "\t. jane\n",
            "\t. genuine\n",
            "\t. received\n",
            "\t. desperate\n",
            "\t. shooting\n",
            "\t. full\n",
            "\t. often\n",
            "\t. father\n",
            "\t. sum\n",
            "\t. comment\n",
            "\t. tough\n",
            "\t. pure\n",
            "\t. take\n",
            "\t. gut\n",
            "\t. attractive\n",
            "\t. guy\n",
            "\t. appeared\n",
            "\t. quiet\n",
            "\t. creepy\n",
            "\t. funnier\n",
            "\t. medium\n",
            "\t. tim\n",
            "\t. reviewer\n",
            "\t. haunted\n",
            "\t. imagine\n",
            "\t. sex\n",
            "\t. makeup\n",
            "\t. first\n",
            "\t. older\n",
            "\t. spot\n",
            "\t. filled\n",
            "\t. like\n",
            "\t. iron\n",
            "\t. catch\n",
            "\t. history\n",
            "\t. arnold\n",
            "\t. williams\n",
            "\t. thrown\n",
            "\t. serious\n",
            "\t. lost\n",
            "\t. individual\n",
            "\t. fat\n",
            "\t. expected\n",
            "\t. c\n",
            "\t. suddenly\n",
            "\t. robot\n",
            "\t. setting\n",
            "\t. motivation\n",
            "\t. michael\n",
            "\t. nick\n",
            "\t. werewolf\n",
            "\t. talk\n",
            "\t. simply\n",
            "\t. killing\n",
            "\t. absurd\n",
            "\t. as\n",
            "\t. free\n",
            "\t. reference\n",
            "\t. rental\n",
            "\t. weird\n",
            "\t. thrill\n",
            "\t. brother\n",
            "\t. manages\n",
            "\t. par\n",
            "\t. audience\n",
            "\t. pleasure\n",
            "\t. network\n",
            "\t. tight\n",
            "\t. drag\n",
            "\t. advice\n",
            "\t. rather\n",
            "\t. ed\n",
            "\t. sit\n",
            "\t. usual\n",
            "\t. value\n",
            "\t. kevin\n",
            "\t. novel\n",
            "\t. yet\n",
            "\t. must\n",
            "\t. fast\n",
            "\t. rented\n",
            "\t. already\n",
            "\t. tired\n",
            "\t. surprising\n",
            "\t. f\n",
            "\t. recent\n",
            "\t. humanity\n",
            "\t. wondering\n",
            "\t. minor\n",
            "\t. sake\n",
            "\t. female\n",
            "\t. get\n",
            "\t. parent\n",
            "\t. around\n",
            "\t. lake\n",
            "\t. dollar\n",
            "\t. fully\n",
            "\t. woman\n",
            "\t. steve\n",
            "\t. alex\n",
            "\t. approach\n",
            "\t. easily\n",
            "\t. real\n",
            "\t. never\n",
            "\t. adaptation\n",
            "\t. amy\n",
            "\t. smith\n",
            "\t. netflix\n",
            "\t. humorous\n",
            "\t. howard\n",
            "\t. combination\n",
            "\t. yeah\n",
            "\t. local\n",
            "\t. welcome\n",
            "\t. thinking\n",
            "\t. timing\n",
            "\t. jack\n",
            "\t. team\n",
            "\t. thank\n",
            "\t. liner\n",
            "\t. finale\n",
            "\t. b\n",
            "\t. universe\n",
            "\t. fiction\n",
            "\t. scott\n",
            "\t. filming\n",
            "\t. memorable\n",
            "\t. killer\n",
            "\t. coming\n",
            "\t. example\n",
            "\t. can\n",
            "\t. found\n",
            "\t. point\n",
            "\t. right\n",
            "\t. describe\n",
            "\t. haunting\n",
            "\t. become\n",
            "\t. crazy\n",
            "\t. daniel\n",
            "\t. managed\n",
            "\t. clothes\n",
            "\t. possible\n",
            "\t. sitting\n",
            "\t. downright\n",
            "\t. phone\n",
            "\t. blonde\n",
            "\t. interest\n",
            "\t. earth\n",
            "\t. matthew\n",
            "\t. seagal\n",
            "\t. viewing\n",
            "\t. homage\n",
            "\t. based\n",
            "\t. addition\n",
            "\t. finally\n",
            "\t. feel\n",
            "\t. head\n",
            "\t. horror\n",
            "\t. thomas\n",
            "\t. justice\n",
            "\t. issue\n",
            "\t. disturbing\n",
            "\t. installment\n",
            "\t. becoming\n",
            "\t. hair\n",
            "\t. last\n",
            "\t. childhood\n",
            "\t. enough\n",
            "\t. knowing\n",
            "\t. cinema\n",
            "\t. kate\n",
            "\t. interaction\n",
            "\t. sign\n",
            "\t. poster\n",
            "\t. visuals\n",
            "\t. result\n",
            "\t. genuinely\n",
            "\t. giant\n",
            "\t. steal\n",
            "\t. york\n",
            "\t. piece\n",
            "\t. city\n",
            "\t. humour\n",
            "\t. judge\n",
            "\t. creates\n",
            "\t. walked\n",
            "\t. director\n",
            "\t. live\n",
            "\t. miller\n",
            "\t. stereotype\n",
            "\t. school\n",
            "\t. shoot\n",
            "\t. reminds\n",
            "\t. young\n",
            "\t. debut\n",
            "\t. present\n",
            "\t. side\n",
            "\t. possibly\n",
            "\t. accurate\n",
            "\t. knight\n",
            "\t. understand\n",
            "\t. emotionally\n",
            "\t. decided\n",
            "\t. fine\n",
            "\t. martin\n",
            "\t. appears\n",
            "\t. absolute\n",
            "\t. mainstream\n",
            "\t. familiar\n",
            "\t. compelling\n",
            "\t. moving\n",
            "\t. guessing\n",
            "\t. lover\n",
            "\t. logic\n",
            "\t. superman\n",
            "\t. delivered\n",
            "\t. captured\n",
            "\t. portrayed\n",
            "\t. rocky\n",
            "\t. visually\n",
            "\t. man\n",
            "\t. growing\n",
            "\t. son\n",
            "\t. run\n",
            "\t. naked\n",
            "\t. laugh\n",
            "\t. better\n",
            "\t. light\n",
            "\t. element\n",
            "\t. along\n",
            "\t. power\n",
            "\t. little\n",
            "\t. visual\n",
            "\t. seriously\n",
            "\t. day\n",
            "\t. maker\n",
            "\t. fit\n",
            "\t. involved\n",
            "\t. deal\n",
            "\t. environment\n",
            "\t. happened\n",
            "\t. stereotypical\n",
            "\t. spoil\n",
            "\t. graphic\n",
            "\t. dry\n",
            "\t. reality\n",
            "\t. produce\n",
            "\t. tone\n",
            "\t. dealing\n",
            "\t. moore\n",
            "\t. deep\n",
            "\t. trilogy\n",
            "\t. kick\n",
            "\t. actual\n",
            "\t. frankly\n",
            "\t. sam\n",
            "\t. saved\n",
            "\t. prof\n",
            "\t. hell\n",
            "\t. challenge\n",
            "\t. fall\n",
            "\t. matt\n",
            "\t. moral\n",
            "\t. faith\n",
            "\t. social\n",
            "\t. throw\n",
            "\t. together\n",
            "\t. confused\n",
            "\t. mood\n",
            "\t. give\n",
            "\t. language\n",
            "\t. product\n",
            "\t. hank\n",
            "\t. independent\n",
            "\t. sometimes\n",
            "\t. reminded\n",
            "\t. generation\n",
            "\t. word\n",
            "\t. frank\n",
            "\t. situation\n",
            "\t. thanks\n",
            "\t. adam\n",
            "\t. james\n",
            "\t. political\n",
            "\t. society\n",
            "\t. space\n",
            "\t. alien\n",
            "\t. somewhere\n",
            "\t. sort\n",
            "\t. rest\n",
            "\t. mind\n",
            "\t. cute\n",
            "\t. running\n",
            "\t. harry\n",
            "\t. accent\n",
            "\t. soundtrack\n",
            "\t. wood\n",
            "\t. laughter\n",
            "\t. dream\n",
            "\t. keeping\n",
            "\t. hearted\n",
            "\t. open\n",
            "\t. wrong\n",
            "\t. certainly\n",
            "\t. paul\n",
            "\t. making\n",
            "\t. compare\n",
            "\t. ben\n",
            "\t. academy\n",
            "\t. beyond\n",
            "\t. attention\n",
            "\t. exciting\n",
            "\t. wanted\n",
            "\t. grew\n",
            "\t. youtube\n",
            "\t. single\n",
            "\t. people\n",
            "\t. chance\n",
            "\t. started\n",
            "\t. seven\n",
            "\t. assume\n",
            "\t. cut\n",
            "\t. battle\n",
            "\t. clichés\n",
            "\t. sleep\n",
            "\t. cox\n",
            "\t. smile\n",
            "\t. budget\n",
            "\t. ignore\n",
            "\t. continues\n",
            "\t. buck\n",
            "\t. walking\n",
            "\t. preview\n",
            "\t. stallone\n",
            "\t. quirky\n",
            "\t. change\n",
            "\t. date\n",
            "\t. year\n",
            "\t. wilson\n",
            "\t. shot\n",
            "\t. violent\n",
            "\t. hole\n",
            "\t. warning\n",
            "\t. worth\n",
            "\t. awkward\n",
            "\t. allows\n",
            "\t. whatever\n",
            "\t. fantasy\n",
            "\t. cool\n",
            "\t. substance\n",
            "\t. expect\n",
            "\t. appear\n",
            "\t. realism\n",
            "\t. atmosphere\n",
            "\t. make\n",
            "\t. jason\n",
            "\t. award\n",
            "\t. others\n",
            "\t. psychological\n",
            "\t. happens\n",
            "\t. listen\n",
            "\t. ugly\n",
            "\t. somehow\n",
            "\t. fail\n",
            "\t. unrealistic\n",
            "\t. blockbuster\n",
            "\t. story\n",
            "\t. sense\n",
            "\t. god\n",
            "\t. culture\n",
            "\t. anywhere\n",
            "\t. execution\n",
            "\t. zombie\n",
            "\t. hate\n",
            "\t. fear\n",
            "\t. pace\n",
            "\t. actually\n",
            "\t. view\n",
            "\t. dinosaur\n",
            "\t. effect\n",
            "\t. kill\n",
            "\t. maybe\n",
            "\t. saving\n",
            "\t. bringing\n",
            "\t. tom\n",
            "\t. chris\n",
            "\t. brain\n",
            "\t. nudity\n",
            "\t. comedic\n",
            "\t. important\n",
            "\t. killed\n",
            "\t. indie\n",
            "\t. noise\n",
            "\t. enjoying\n",
            "\t. cheesy\n",
            "\t. epic\n",
            "\t. problem\n",
            "\t. otherwise\n",
            "\t. score\n",
            "\t. intelligent\n",
            "\t. copy\n",
            "\t. nobody\n",
            "\t. called\n",
            "\t. engaging\n",
            "\t. sad\n",
            "\t. seeing\n",
            "\t. clever\n",
            "\t. funny\n",
            "\t. obvious\n",
            "\t. easy\n",
            "\t. somebody\n",
            "\t. stopped\n",
            "\t. play\n",
            "\t. confusing\n",
            "\t. truth\n",
            "\t. mistake\n",
            "\t. act\n",
            "\t. write\n",
            "\t. flaw\n",
            "\t. unusual\n",
            "\t. monster\n",
            "\t. cgi\n",
            "\t. truly\n",
            "\t. series\n",
            "\t. beauty\n",
            "\t. explanation\n",
            "\t. stock\n",
            "\t. favor\n",
            "\t. lighting\n",
            "\t. sat\n",
            "\t. seemed\n",
            "\t. quality\n",
            "\t. john\n",
            "\t. ryan\n",
            "\t. spend\n",
            "\t. edited\n",
            "\t. thin\n",
            "\t. continuity\n",
            "\t. watching\n",
            "\t. quite\n",
            "\t. suppose\n",
            "\t. driven\n",
            "\t. brought\n",
            "\t. tale\n",
            "\t. superhero\n",
            "\t. impressive\n",
            "\t. festival\n",
            "\t. capture\n",
            "\t. fell\n",
            "\t. unnecessary\n",
            "\t. throughout\n",
            "\t. contrived\n",
            "\t. natural\n",
            "\t. strength\n",
            "\t. dimensional\n",
            "\t. pas\n",
            "\t. literally\n",
            "\t. idiot\n",
            "\t. looked\n",
            "\t. actor\n",
            "\t. rent\n",
            "\t. although\n",
            "\t. laughed\n",
            "\t. marvel\n",
            "\t. theater\n",
            "\t. empty\n",
            "\t. moment\n",
            "\t. genre\n",
            "\t. loving\n",
            "\t. expecting\n",
            "\t. torture\n",
            "\t. provides\n",
            "\t. hardly\n",
            "\t. positive\n",
            "\t. dialog\n",
            "\t. sub\n",
            "\t. summer\n",
            "\t. wonder\n",
            "\t. paper\n",
            "\t. nature\n",
            "\t. genius\n",
            "\t. screaming\n",
            "\t. joy\n",
            "\t. top\n",
            "\t. theme\n",
            "\t. cast\n",
            "\t. sandler\n",
            "\t. portrayal\n",
            "\t. deeper\n",
            "\t. tense\n",
            "\t. lovely\n",
            "\t. care\n",
            "\t. criticism\n",
            "\t. personal\n",
            "\t. lacking\n",
            "\t. talent\n",
            "\t. human\n",
            "\t. footage\n",
            "\t. win\n",
            "\t. brutal\n",
            "\t. smart\n",
            "\t. cinematography\n",
            "\t. popcorn\n",
            "\t. wearing\n",
            "\t. cruise\n",
            "\t. expectation\n",
            "\t. chemistry\n",
            "\t. modern\n",
            "\t. something\n",
            "\t. tv\n",
            "\t. cliché\n",
            "\t. breath\n",
            "\t. unbelievable\n",
            "\t. future\n",
            "\t. bottom\n",
            "\t. emotion\n",
            "\t. entertainment\n",
            "\t. saw\n",
            "\t. yes\n",
            "\t. seems\n",
            "\t. thrilling\n",
            "\t. witty\n",
            "\t. perspective\n",
            "\t. forced\n",
            "\t. thing\n",
            "\t. student\n",
            "\t. thought\n",
            "\t. disgusting\n",
            "\t. still\n",
            "\t. suspenseful\n",
            "\t. relate\n",
            "\t. min\n",
            "\t. balance\n",
            "\t. may\n",
            "\t. hoping\n",
            "\t. completely\n",
            "\t. okay\n",
            "\t. scientist\n",
            "\t. shallow\n",
            "\t. adult\n",
            "\t. game\n",
            "\t. basically\n",
            "\t. writer\n",
            "\t. name\n",
            "\t. drunk\n",
            "\t. drama\n",
            "\t. personally\n",
            "\t. review\n",
            "\t. channel\n",
            "\t. batman\n",
            "\t. many\n",
            "\t. violence\n",
            "\t. message\n",
            "\t. romance\n",
            "\t. paid\n",
            "\t. made\n",
            "\t. utterly\n",
            "\t. sound\n",
            "\t. style\n",
            "\t. promising\n",
            "\t. touch\n",
            "\t. tear\n",
            "\t. blah\n",
            "\t. fascinating\n",
            "\t. jon\n",
            "\t. age\n",
            "\t. new\n",
            "\t. laughing\n",
            "\t. experience\n",
            "\t. cash\n",
            "\t. stupidity\n",
            "\t. detail\n",
            "\t. clichéd\n",
            "\t. effort\n",
            "\t. neither\n",
            "\t. think\n",
            "\t. writing\n",
            "\t. failure\n",
            "\t. generic\n",
            "\t. pleasant\n",
            "\t. played\n",
            "\t. terribly\n",
            "\t. gorgeous\n",
            "\t. either\n",
            "\t. treat\n",
            "\t. paint\n",
            "\t. satisfying\n",
            "\t. halfway\n",
            "\t. turkey\n",
            "\t. project\n",
            "\t. simple\n",
            "\t. title\n",
            "\t. premise\n",
            "\t. joke\n",
            "\t. watchable\n",
            "\t. spent\n",
            "\t. rip\n",
            "\t. war\n",
            "\t. supporting\n",
            "\t. disappoint\n",
            "\t. sucked\n",
            "\t. effective\n",
            "\t. editing\n",
            "\t. book\n",
            "\t. ok\n",
            "\t. rare\n",
            "\t. ruined\n",
            "\t. bit\n",
            "\t. keep\n",
            "\t. blame\n",
            "\t. u\n",
            "\t. surprisingly\n",
            "\t. decent\n",
            "\t. charming\n",
            "\t. film\n",
            "\t. overall\n",
            "\t. friendship\n",
            "\t. video\n",
            "\t. nowhere\n",
            "\t. twist\n",
            "\t. thoroughly\n",
            "\t. believable\n",
            "\t. unlike\n",
            "\t. producer\n",
            "\t. except\n",
            "\t. shark\n",
            "\t. production\n",
            "\t. everyone\n",
            "\t. shine\n",
            "\t. cover\n",
            "\t. bored\n",
            "\t. gem\n",
            "\t. cringe\n",
            "\t. complex\n",
            "\t. appreciate\n",
            "\t. nicely\n",
            "\t. dark\n",
            "\t. not\n",
            "\t. try\n",
            "\t. romantic\n",
            "\t. surprise\n",
            "\t. happy\n",
            "\t. sweet\n",
            "\t. camera\n",
            "\t. deserves\n",
            "\t. please\n",
            "\t. favourite\n",
            "\t. someone\n",
            "\t. comic\n",
            "\t. reason\n",
            "\t. supposedly\n",
            "\t. look\n",
            "\t. else\n",
            "\t. spectacular\n",
            "\t. unexpected\n",
            "\t. half\n",
            "\t. brings\n",
            "\t. entertained\n",
            "\t. porn\n",
            "\t. lazy\n",
            "\t. trying\n",
            "\t. recommended\n",
            "\t. plenty\n",
            "\t. masterpiece\n",
            "\t. bunch\n",
            "\t. complaint\n",
            "\t. thriller\n",
            "\t. relationship\n",
            "\t. funniest\n",
            "\t. season\n",
            "\t. plain\n",
            "\t. oh\n",
            "\t. subtle\n",
            "\t. nice\n",
            "\t. especially\n",
            "\t. asylum\n",
            "\t. today\n",
            "\t. grade\n",
            "\t. ever\n",
            "\t. fresh\n",
            "\t. syfy\n",
            "\t. glad\n",
            "\t. fake\n",
            "\t. life\n",
            "\t. paced\n",
            "\t. potential\n",
            "\t. adventure\n",
            "\t. total\n",
            "\t. impressed\n",
            "\t. horribly\n",
            "\t. crappy\n",
            "\t. bond\n",
            "\t. utter\n",
            "\t. predictable\n",
            "\t. opinion\n",
            "\t. plot\n",
            "\t. lot\n",
            "\t. comedy\n",
            "\t. wonderfully\n",
            "\t. shame\n",
            "\t. guess\n",
            "\t. nonsense\n",
            "\t. insult\n",
            "\t. idea\n",
            "\t. ride\n",
            "\t. journey\n",
            "\t. emotional\n",
            "\t. strong\n",
            "\t. world\n",
            "\t. bother\n",
            "\t. irritating\n",
            "\t. dialogue\n",
            "\t. greatest\n",
            "\t. fan\n",
            "\t. notch\n",
            "\t. brilliantly\n",
            "\t. humor\n",
            "\t. disaster\n",
            "\t. anything\n",
            "\t. hour\n",
            "\t. incredible\n",
            "\t. classic\n",
            "\t. cost\n",
            "\t. painfully\n",
            "\t. good\n",
            "\t. random\n",
            "\t. recommend\n",
            "\t. complete\n",
            "\t. realistic\n",
            "\t. true\n",
            "\t. screening\n",
            "\t. disappointment\n",
            "\t. none\n",
            "\t. dumb\n",
            "\t. packed\n",
            "\t. tedious\n",
            "\t. always\n",
            "\t. apparently\n",
            "\t. lack\n",
            "\t. touching\n",
            "\t. also\n",
            "\t. negative\n",
            "\t. powerful\n",
            "\t. embarrassing\n",
            "\t. remotely\n",
            "\t. stunning\n",
            "\t. role\n",
            "\t. weak\n",
            "\t. tried\n",
            "\t. failed\n",
            "\t. forgettable\n",
            "\t. episode\n",
            "\t. pile\n",
            "\t. barely\n",
            "\t. oscar\n",
            "\t. amateur\n",
            "\t. whatsoever\n",
            "\t. disappointing\n",
            "\t. excuse\n",
            "\t. delivers\n",
            "\t. trash\n",
            "\t. terrific\n",
            "\t. sorry\n",
            "\t. skip\n",
            "\t. wooden\n",
            "\t. unique\n",
            "\t. see\n",
            "\t. heart\n",
            "\t. instead\n",
            "\t. supposed\n",
            "\t. sadly\n",
            "\t. intense\n",
            "\t. amateurish\n",
            "\t. underrated\n",
            "\t. dreadful\n",
            "\t. least\n",
            "\t. suck\n",
            "\t. edge\n",
            "\t. mediocre\n",
            "\t. seat\n",
            "\t. zero\n",
            "\t. unless\n",
            "\t. painful\n",
            "\t. atrocious\n",
            "\t. different\n",
            "\t. outstanding\n",
            "\t. beautifully\n",
            "\t. perfectly\n",
            "\t. entertaining\n",
            "\t. solid\n",
            "\t. bland\n",
            "\t. highly\n",
            "\t. rubbish\n",
            "\t. ridiculous\n",
            "\t. flat\n",
            "\t. refreshing\n",
            "\t. job\n",
            "\t. attempt\n",
            "\t. family\n",
            "\t. performance\n",
            "\t. pointless\n",
            "\t. surprised\n",
            "\t. pleasantly\n",
            "\t. beautiful\n",
            "\t. save\n",
            "\t. laughable\n",
            "\t. unfunny\n",
            "\t. favorite\n",
            "\t. acting\n",
            "\t. unfortunately\n",
            "\t. annoying\n",
            "\t. enjoyable\n",
            "\t. hilarious\n",
            "\t. fails\n",
            "\t. pathetic\n",
            "\t. dull\n",
            "\t. cheap\n",
            "\t. redeeming\n",
            "\t. enjoy\n",
            "\t. critic\n",
            "\t. badly\n",
            "\t. liked\n",
            "\t. lame\n",
            "\t. brilliant\n",
            "\t. well\n",
            "\t. action\n",
            "\t. crap\n",
            "\t. mess\n",
            "\t. stupid\n",
            "\t. wonderful\n",
            "\t. avoid\n",
            "\t. even\n",
            "\t. best\n",
            "\t. superb\n",
            "\t. fantastic\n",
            "\t. definitely\n",
            "\t. garbage\n",
            "\t. script\n",
            "\t. awesome\n",
            "\t. wasted\n",
            "\t. minute\n",
            "\t. money\n",
            "\t. love\n",
            "\t. poorly\n",
            "\t. fun\n",
            "\t. amazing\n",
            "\t. nothing\n",
            "\t. horrible\n",
            "\t. perfect\n",
            "\t. excellent\n",
            "\t. enjoyed\n",
            "\t. worse\n",
            "\t. poor\n",
            "\t. loved\n",
            "\t. boring\n",
            "\t. terrible\n",
            "\t. awful\n",
            "\t. waste\n",
            "\t. bad\n",
            "\t. worst\n",
            "\t. great\n",
            "\t# Bigrams :\n",
            "\t. show not\n",
            "\t. film seen\n",
            "\t. original film\n",
            "\t. not see\n",
            "\t. come back\n",
            "\t. movie get\n",
            "\t. something not\n",
            "\t. scene movie\n",
            "\t. screen time\n",
            "\t. not exactly\n",
            "\t. movie make\n",
            "\t. part film\n",
            "\t. even not\n",
            "\t. horror movie\n",
            "\t. watching film\n",
            "\t. character development\n",
            "\t. best part\n",
            "\t. year ago\n",
            "\t. many time\n",
            "\t. good enough\n",
            "\t. want see\n",
            "\t. movie not\n",
            "\t. say not\n",
            "\t. not need\n",
            "\t. end film\n",
            "\t. never seen\n",
            "\t. thing not\n",
            "\t. video game\n",
            "\t. title brazil\n",
            "\t. not movie\n",
            "\t. not mind\n",
            "\t. one time\n",
            "\t. make film\n",
            "\t. budget film\n",
            "\t. first movie\n",
            "\t. fight scene\n",
            "\t. not give\n",
            "\t. not great\n",
            "\t. tv series\n",
            "\t. way not\n",
            "\t. like not\n",
            "\t. every scene\n",
            "\t. good bad\n",
            "\t. not say\n",
            "\t. say movie\n",
            "\t. put together\n",
            "\t. character movie\n",
            "\t. made film\n",
            "\t. die hard\n",
            "\t. well not\n",
            "\t. bad guy\n",
            "\t. year later\n",
            "\t. one thing\n",
            "\t. movie like\n",
            "\t. plot line\n",
            "\t. plot twist\n",
            "\t. know not\n",
            "\t. found footage\n",
            "\t. movie actually\n",
            "\t. main character\n",
            "\t. definitely not\n",
            "\t. second half\n",
            "\t. watch not\n",
            "\t. one film\n",
            "\t. not film\n",
            "\t. looking forward\n",
            "\t. movie time\n",
            "\t. much like\n",
            "\t. every time\n",
            "\t. movie people\n",
            "\t. film like\n",
            "\t. martial art\n",
            "\t. certainly not\n",
            "\t. not think\n",
            "\t. make good\n",
            "\t. movie movie\n",
            "\t. film even\n",
            "\t. sci fi\n",
            "\t. movie first\n",
            "\t. take place\n",
            "\t. not mean\n",
            "\t. story not\n",
            "\t. not feel\n",
            "\t. watch movie\n",
            "\t. throughout movie\n",
            "\t. end not\n",
            "\t. watch film\n",
            "\t. movie still\n",
            "\t. film not\n",
            "\t. people like\n",
            "\t. go back\n",
            "\t. van damme\n",
            "\t. comedy not\n",
            "\t. end movie\n",
            "\t. though not\n",
            "\t. movie never\n",
            "\t. bad thing\n",
            "\t. however not\n",
            "\t. time movie\n",
            "\t. good not\n",
            "\t. movie one\n",
            "\t. film making\n",
            "\t. film make\n",
            "\t. one not\n",
            "\t. not find\n",
            "\t. tv show\n",
            "\t. entire film\n",
            "\t. want watch\n",
            "\t. not sure\n",
            "\t. one movie\n",
            "\t. rest cast\n",
            "\t. horror flick\n",
            "\t. first two\n",
            "\t. everyone else\n",
            "\t. good guy\n",
            "\t. get see\n",
            "\t. first film\n",
            "\t. probably not\n",
            "\t. like one\n",
            "\t. not mention\n",
            "\t. story line\n",
            "\t. visual effect\n",
            "\t. watched movie\n",
            "\t. not come\n",
            "\t. first half\n",
            "\t. type movie\n",
            "\t. like film\n",
            "\t. movie pretty\n",
            "\t. kind movie\n",
            "\t. movie go\n",
            "\t. film really\n",
            "\t. big fan\n",
            "\t. not go\n",
            "\t. not going\n",
            "\t. good one\n",
            "\t. seen movie\n",
            "\t. also not\n",
            "\t. one one\n",
            "\t. every single\n",
            "\t. part movie\n",
            "\t. serial killer\n",
            "\t. scene not\n",
            "\t. give film\n",
            "\t. first one\n",
            "\t. film made\n",
            "\t. zombie movie\n",
            "\t. give movie\n",
            "\t. movie take\n",
            "\t. not get\n",
            "\t. star trek\n",
            "\t. movie start\n",
            "\t. film one\n",
            "\t. movie seen\n",
            "\t. gon na\n",
            "\t. worth watching\n",
            "\t. one day\n",
            "\t. made movie\n",
            "\t. film film\n",
            "\t. budget movie\n",
            "\t. wan na\n",
            "\t. seen film\n",
            "\t. film maker\n",
            "\t. running time\n",
            "\t. best friend\n",
            "\t. give u\n",
            "\t. time not\n",
            "\t. not know\n",
            "\t. take seriously\n",
            "\t. seem like\n",
            "\t. effect not\n",
            "\t. watching movie\n",
            "\t. great actor\n",
            "\t. feel like\n",
            "\t. review movie\n",
            "\t. box office\n",
            "\t. read book\n",
            "\t. not look\n",
            "\t. movie made\n",
            "\t. best thing\n",
            "\t. writer director\n",
            "\t. action scene\n",
            "\t. tell story\n",
            "\t. not want\n",
            "\t. not quite\n",
            "\t. star war\n",
            "\t. one two\n",
            "\t. year old\n",
            "\t. get better\n",
            "\t. not not\n",
            "\t. action sequence\n",
            "\t. movie really\n",
            "\t. not understand\n",
            "\t. funny not\n",
            "\t. better film\n",
            "\t. good actor\n",
            "\t. quite good\n",
            "\t. science fiction\n",
            "\t. scary movie\n",
            "\t. not take\n",
            "\t. film much\n",
            "\t. come across\n",
            "\t. movie watch\n",
            "\t. last year\n",
            "\t. movie also\n",
            "\t. fall love\n",
            "\t. not bad\n",
            "\t. plot not\n",
            "\t. never really\n",
            "\t. not many\n",
            "\t. high school\n",
            "\t. see not\n",
            "\t. not expect\n",
            "\t. although not\n",
            "\t. two hour\n",
            "\t. whole film\n",
            "\t. really like\n",
            "\t. throughout film\n",
            "\t. much better\n",
            "\t. movie think\n",
            "\t. not seem\n",
            "\t. sex scene\n",
            "\t. go watch\n",
            "\t. movie see\n",
            "\t. plot hole\n",
            "\t. one scene\n",
            "\t. something like\n",
            "\t. still not\n",
            "\t. last minute\n",
            "\t. can not\n",
            "\t. along way\n",
            "\t. make movie\n",
            "\t. movie even\n",
            "\t. one point\n",
            "\t. make laugh\n",
            "\t. film also\n",
            "\t. movie much\n",
            "\t. good film\n",
            "\t. like movie\n",
            "\t. even though\n",
            "\t. one liner\n",
            "\t. film ever\n",
            "\t. yet another\n",
            "\t. production value\n",
            "\t. character not\n",
            "\t. anything else\n",
            "\t. camera work\n",
            "\t. new york\n",
            "\t. pretty much\n",
            "\t. special effect\n",
            "\t. ever made\n",
            "\t. first place\n",
            "\t. not expecting\n",
            "\t. film good\n",
            "\t. real life\n",
            "\t. never get\n",
            "\t. not seen\n",
            "\t. not really\n",
            "\t. little bit\n",
            "\t. horror film\n",
            "\t. not always\n",
            "\t. movie year\n",
            "\t. beginning end\n",
            "\t. not let\n",
            "\t. making movie\n",
            "\t. good acting\n",
            "\t. b movie\n",
            "\t. start finish\n",
            "\t. good story\n",
            "\t. movie well\n",
            "\t. not help\n",
            "\t. think movie\n",
            "\t. low budget\n",
            "\t. better movie\n",
            "\t. actor not\n",
            "\t. felt like\n",
            "\t. whole movie\n",
            "\t. half hour\n",
            "\t. good movie\n",
            "\t. thought movie\n",
            "\t. first time\n",
            "\t. everything else\n",
            "\t. not one\n",
            "\t. get back\n",
            "\t. really really\n",
            "\t. film well\n",
            "\t. thing movie\n",
            "\t. recommend movie\n",
            "\t. horror fan\n",
            "\t. saw movie\n",
            "\t. entire movie\n",
            "\t. must say\n",
            "\t. not scary\n",
            "\t. long time\n",
            "\t. love story\n",
            "\t. supporting cast\n",
            "\t. comic book\n",
            "\t. one better\n",
            "\t. seemed like\n",
            "\t. something else\n",
            "\t. pretty good\n",
            "\t. big screen\n",
            "\t. last night\n",
            "\t. well made\n",
            "\t. people not\n",
            "\t. not believe\n",
            "\t. like watching\n",
            "\t. see film\n",
            "\t. lot people\n",
            "\t. not anything\n",
            "\t. minute movie\n",
            "\t. seems like\n",
            "\t. not care\n",
            "\t. not much\n",
            "\t. acting not\n",
            "\t. bad good\n",
            "\t. simply not\n",
            "\t. laugh loud\n",
            "\t. movie good\n",
            "\t. really not\n",
            "\t. work well\n",
            "\t. many people\n",
            "\t. sound like\n",
            "\t. nothing else\n",
            "\t. action film\n",
            "\t. romantic comedy\n",
            "\t. good thing\n",
            "\t. movie definitely\n",
            "\t. acting good\n",
            "\t. looked like\n",
            "\t. please not\n",
            "\t. enjoy movie\n",
            "\t. fun watch\n",
            "\t. good idea\n",
            "\t. movie lot\n",
            "\t. action movie\n",
            "\t. not bother\n",
            "\t. not best\n",
            "\t. good job\n",
            "\t. whole thing\n",
            "\t. even better\n",
            "\t. first minute\n",
            "\t. not like\n",
            "\t. see movie\n",
            "\t. one favorite\n",
            "\t. lot fun\n",
            "\t. movie ever\n",
            "\t. good time\n",
            "\t. great film\n",
            "\t. worth watch\n",
            "\t. not watch\n",
            "\t. not enough\n",
            "\t. really liked\n",
            "\t. film great\n",
            "\t. make sense\n",
            "\t. bad film\n",
            "\t. not work\n",
            "\t. not wait\n",
            "\t. may not\n",
            "\t. ever seen\n",
            "\t. best film\n",
            "\t. top notch\n",
            "\t. fun movie\n",
            "\t. really good\n",
            "\t. not good\n",
            "\t. not make\n",
            "\t. love movie\n",
            "\t. bad not\n",
            "\t. well written\n",
            "\t. bad bad\n",
            "\t. not disappointed\n",
            "\t. bad review\n",
            "\t. not recommend\n",
            "\t. negative review\n",
            "\t. movie bad\n",
            "\t. edge seat\n",
            "\t. worst film\n",
            "\t. enjoyed movie\n",
            "\t. pleasantly surprised\n",
            "\t. movie great\n",
            "\t. even worse\n",
            "\t. highly recommend\n",
            "\t. well done\n",
            "\t. not funny\n",
            "\t. acting bad\n",
            "\t. go see\n",
            "\t. great movie\n",
            "\t. must see\n",
            "\t. look like\n",
            "\t. great job\n",
            "\t. really bad\n",
            "\t. best movie\n",
            "\t. really enjoyed\n",
            "\t. not worth\n",
            "\t. bad movie\n",
            "\t. bad acting\n",
            "\t. one worst\n",
            "\t. one best\n",
            "\t. not waste\n",
            "\t. worst movie\n",
            "\t. not even\n",
            "\t. waste time\n",
            "\t# Trigrams :\n",
            "\t. movie ever made\n",
            "\t. movie ever seen\n",
            "\t. not waste time\n",
            "\t. worst movie ever\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "import numpy as np\n",
        "N = 2000\n",
        "Number = 1\n",
        "featureselection = PrettyTable([\"Unigram\", \"Bigram\",\"Trigram\"])\n",
        "for category in train['Label'].unique():\n",
        "    features_chi2 = chi2(X_train_df, train['Label'] == category)\n",
        "    indices = np.argsort(features_chi2[0])\n",
        "    feature_names = np.array(tfidf.get_feature_names_out())[indices]\n",
        "    unigrams = [x for x in feature_names if len(x.split(' ')) == 1]\n",
        "    bigrams = [x for x in feature_names if len(x.split(' ')) == 2]\n",
        "    trigrams = [x for x in feature_names if len(x.split(' ')) == 3]\n",
        "    print(\"%s. %s :\" % (Number,category))\n",
        "    print(\"\\t# Unigrams :\\n\\t. %s\" %('\\n\\t. '.join(unigrams[-N:])))\n",
        "    print(\"\\t# Bigrams :\\n\\t. %s\" %('\\n\\t. '.join(bigrams[-N:])))\n",
        "    print(\"\\t# Trigrams :\\n\\t. %s\" %('\\n\\t. '.join(trigrams[-N:])))\n",
        "    Number += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVJFO6KbVW_I"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taQnHJ3AVYIB"
      },
      "outputs": [],
      "source": [
        "lr_model = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNVsVQyIVaIA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0huTMiAa6a9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AufQmhMCA5f2"
      },
      "source": [
        "## Hyperparameter Tunning for Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "MFsOgVPVW6X1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2irqxfiA4al",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "710843ae-e8cd-43fb-f7a8-d40abef33148"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model_1 = LogisticRegression()\n",
        "model_1.fit(X_train_df, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb93jzf8VcBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32711d5-1575-4824-fb6d-d51c813abe61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score on training dateset for Logistic Regression: 0.8958452380952381\n",
            "AUC Score on training dateset for Logistic Regression: 0.89583243384938\n",
            "F1 Score on training dataset for Logistic Regression: 0.8958431466230218\n",
            "Precision Score on testing dateset for Logistic Regression: 0.8853888888888889\n",
            "AUC Score on testing dateset for Logistic Regression: 0.885406007388238\n",
            "F1 Score on testing dataset for Logistic Regression: 0.8853908950079604\n"
          ]
        }
      ],
      "source": [
        "print(\"Precision Score on training dateset for Logistic Regression: %s\" % precision_score(y_train,model_1.predict(X_train_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for Logistic Regression: %s\" % roc_auc_score(y_train,model_1.predict(X_train_df),multi_class='ovo',average='macro'))\n",
        "f1_score_train_1 = f1_score(y_train, model_1.predict(X_train_df),average='weighted')\n",
        "print('F1 Score on training dataset for Logistic Regression: %s' % f1_score_train_1)\n",
        "\n",
        "print(\"Precision Score on testing dateset for Logistic Regression: %s\" % precision_score(y_test,model_1.predict(X_test_df),average='micro'))\n",
        "print(\"AUC Score on testing dateset for Logistic Regression: %s\" % roc_auc_score(y_test, model_1.predict(X_test_df),multi_class='ovo',average='macro'))\n",
        "f1_score_test_1 = f1_score(y_test, model_1.predict(X_test_df),average='weighted')\n",
        "print('F1 Score on testing dataset for Logistic Regression: %s' % f1_score_test_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Classifier"
      ],
      "metadata": {
        "id": "l5oFnhG_aCxg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D819DlJhVgOy"
      },
      "outputs": [],
      "source": [
        "model_2 = Pipeline(\n",
        "    steps=[('classifier', DecisionTreeClassifier())]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(X_train_df, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "TxTFDjA2YR-j",
        "outputId": "048e48b8-7c35-4c48-9e3d-c5a2509b5811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('classifier', DecisionTreeClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision Score on training dateset for DecisionTree Classifier: %s\" % precision_score(y_train,model_2.predict(X_train_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for DecisionTree Classifier %s\" % roc_auc_score(y_train,model_2.predict(X_train_df),multi_class='ovo',average='macro'))\n",
        "f1_score_train_2 = f1_score(y_train, model_2.predict(X_train_df),average='weighted')\n",
        "print('F1 Score on training dataset for DecisionTree Classifier: %s' % f1_score_train_2)\n",
        "\n",
        "print(\"Precision Score on testing dateset for DecisionTree Classifier: %s\" % precision_score(y_test,model_2.predict(X_test_df),average='micro'))\n",
        "print(\"AUC Score on testing dateset for DecisionTree Classifier: %s\" % roc_auc_score(y_test, model_2.predict(X_test_df),multi_class='ovo',average='macro'))\n",
        "f1_score_test_2 = f1_score(y_test, model_2.predict(X_test_df),average='weighted')\n",
        "print('F1 Score on testing dataset for DecisionTree Classifier: %s' % f1_score_test_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5uWMf76YYIj",
        "outputId": "ecdb4633-7bf9-465c-e7a9-b791ea64156e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score on training dateset for DecisionTree Classifier: 0.9999523809523809\n",
            "AUC Score on training dateset for DecisionTree Classifier 0.9999525616698293\n",
            "F1 Score on training dataset for DecisionTree Classifier: 0.9999523809609115\n",
            "Precision Score on testing dateset for DecisionTree Classifier: 0.7138888888888889\n",
            "AUC Score on testing dateset for DecisionTree Classifier: 0.7139008514252979\n",
            "F1 Score on testing dataset for DecisionTree Classifier: 0.7138944522995792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVWdyrlmbn23"
      },
      "outputs": [],
      "source": [
        "model_3 = Pipeline(\n",
        "    steps=[('classifier', DecisionTreeClassifier(max_depth=9))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model_3.fit(X_train_df, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "ONBic3wRayS0",
        "outputId": "1c3b6fd5-2ac4-46d6-b949-915c7d0771f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 56.4 s, sys: 436 ms, total: 56.8 s\n",
            "Wall time: 1min 1s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('classifier', DecisionTreeClassifier(max_depth=9))])"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, DecisionTreeClassifier(max_depth=9))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, DecisionTreeClassifier(max_depth=9))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=9)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision Score on training dateset for DecisionTree Classifier: %s\" % precision_score(y_train,model_3.predict(X_train_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for DecisionTree Classifier %s\" % roc_auc_score(y_train,model_3.predict(X_train_df),multi_class='ovo',average='macro'))\n",
        "f1_score_train_3 = f1_score(y_train, model_3.predict(X_train_df),average='weighted')\n",
        "print('F1 Score on training dataset for DecisionTree Classifier: %s' % f1_score_train_3)\n",
        "\n",
        "print(\"Precision Score on testing dateset for DecisionTree Classifier: %s\" % precision_score(y_test,model_3.predict(X_test_df),average='micro'))\n",
        "print(\"AUC Score on testing dateset for DecisionTree Classifier: %s\" % roc_auc_score(y_test, model_3.predict(X_test_df),multi_class='ovo',average='macro'))\n",
        "f1_score_test_3 = f1_score(y_test, model_3.predict(X_test_df),average='weighted')\n",
        "print('F1 Score on testing dataset for DecisionTree Classifier: %s' % f1_score_test_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff0OBgSKbCnR",
        "outputId": "fae3c8c7-e94c-4529-d069-aad27f16a04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score on training dateset for DecisionTree Classifier: 0.7376547619047619\n",
            "AUC Score on training dateset for DecisionTree Classifier 0.7372197918518546\n",
            "F1 Score on training dataset for DecisionTree Classifier: 0.734132967815767\n",
            "Precision Score on testing dateset for DecisionTree Classifier: 0.71875\n",
            "AUC Score on testing dateset for DecisionTree Classifier: 0.7197369915647656\n",
            "F1 Score on testing dataset for DecisionTree Classifier: 0.7153719254355063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest Classifier"
      ],
      "metadata": {
        "id": "dmV9yz-R3yK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE9MOWSrcp8W"
      },
      "outputs": [],
      "source": [
        "model_4 = Pipeline(\n",
        "    steps =[\n",
        "        ('classifier', RandomForestClassifier())]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.fit(X_train_df, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "GNlVikyT7Ntd",
        "outputId": "5e275ba9-e834-43e6-bbcb-d48a973e70ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('classifier', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision Score on training dateset for Random Forest Classifier: %s\" % precision_score(y_train,model_4.predict(X_train_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for Random Forest Classifier: %s\" % roc_auc_score(y_train,model_4.predict(X_train_df),multi_class='ovo',average='macro'))\n",
        "f1_score_train_4 = f1_score(y_train, model_4.predict(X_train_df),average='weighted')\n",
        "print('F1 Score on training dataset for Random Forest Classifier: %s' % f1_score_train_4)\n",
        "\n",
        "print(\"Precision Score on testing dateset for Random Forest Classifier: %s\" % precision_score(y_test,model_4.predict(X_test_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for Random Forest Classifier: %s\" % roc_auc_score(y_test, model_4.predict(X_test_df),multi_class='ovo',average='macro'))\n",
        "f1_score_test_4 = f1_score(y_test, model_4.predict(X_test_df),average='weighted')\n",
        "print('F1 Score on training dataset for Random Forest Classifier: %s' % f1_score_test_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjoghrpr9FjF",
        "outputId": "f3f51710-e4c1-4129-ca66-61162a0d58d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score on training dateset for Random Forest Classifier: 0.9999523809523809\n",
            "AUC Score on training dateset for Random Forest Classifier: 0.999952470965565\n",
            "F1 Score on training dataset for Random Forest Classifier: 0.999952380956673\n",
            "Precision Score on testing dateset for Random Forest Classifier: 0.8444166666666667\n",
            "AUC Score on training dateset for Random Forest Classifier: 0.8444169662788171\n",
            "F1 Score on training dataset for Random Forest Classifier: 0.8444183137090522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ada Boost Algorithm"
      ],
      "metadata": {
        "id": "6dHQ31_-c-qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = Pipeline(\n",
        "    steps=[\n",
        "        (\"classifier\", AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4),\n",
        "    n_estimators=50,\n",
        "    learning_rate=0.8)),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "SL8U36vJ9FgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.fit(X_train_df, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "m89vxjhW-2Wa",
        "outputId": "2aa3644d-141c-44fc-ce71-c6af8e422fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('classifier',\n",
              "                 AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4),\n",
              "                                    learning_rate=0.8))])"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n",
              "                 AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4),\n",
              "                                    learning_rate=0.8))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;,\n",
              "                 AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4),\n",
              "                                    learning_rate=0.8))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=4),\n",
              "                   learning_rate=0.8)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision Score on training dateset for AdaBoostClassifier: %s\" % precision_score(y_train,model_5.predict(X_train_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for AdaBoostClassifier: %s\" % roc_auc_score(y_train,model_5.predict(X_train_df),multi_class='ovo',average='macro'))\n",
        "f1_score_train_5 = f1_score(y_train, model_5.predict(X_train_df),average='weighted')\n",
        "print('F1 Score on training dataset for AdaBoostClassifier: %s' % f1_score_train_5)\n",
        "\n",
        "print(\"Precision Score on testing dateset for AdaBoostClassifier: %s\" % precision_score(y_test,model_5.predict(X_test_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for AdaBoostClassifier: %s\" % roc_auc_score(y_test, model_5.predict(X_test_df),multi_class='ovo',average='macro'))\n",
        "f1_score_test_5 = f1_score(y_test, model_5.predict(X_test_df),average='weighted')\n",
        "print('F1 Score on training dataset for AdaBoostClassifier: %s' % f1_score_test_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuvv66Ms-2As",
        "outputId": "73c254de-cd69-48ad-ca15-87e8d508e478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score on training dateset for AdaBoostClassifier: 0.8719285714285714\n",
            "AUC Score on training dateset for AdaBoostClassifier: 0.8719022226172897\n",
            "F1 Score on training dataset for AdaBoostClassifier: 0.8719201413539808\n",
            "Precision Score on testing dateset for AdaBoostClassifier: 0.8436111111111111\n",
            "AUC Score on training dateset for AdaBoostClassifier: 0.8436669070148751\n",
            "F1 Score on training dataset for AdaBoostClassifier: 0.8436125765351109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "j5K4aFjcu0M-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "ehUeNqwF9Fdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparametertuning(classifier, param_grid, metric, verbose_value, cv):\n",
        "  model = GridSearchCV(\n",
        "      estimator=classifier,\n",
        "      param_grid=param_grid,\n",
        "      scoring=metric,\n",
        "      verbose=verbose_value,\n",
        "      cv=cv)\n",
        "  model.fit(X_train_df, y_train)\n",
        "  print('Best Score %s' % {model.best_score_})\n",
        "  print('Best hyperParameter Set:')\n",
        "  best_parameters = model.best_estimator_.get_params()\n",
        "  for param_name in sorted(param_grid.keys()):\n",
        "    print(f'\\{param_name}: {best_parameters[param_name]}')\n",
        "  return model, best_parameters"
      ],
      "metadata": {
        "id": "f_b0hvcZvDxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HyperParameter tuning with logistic regression"
      ],
      "metadata": {
        "id": "0gWiQE7PrLj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_gd = {'penalty':['l2','l1'],\n",
        "            'C':[0.01, 0.1, 1.0, 10.0],\n",
        "            'tol':[0.0001,0.001,0.01],\n",
        "            'max_iter':[100,200]}\n",
        "model_7, best_param = hyperparametertuning(LogisticRegression(),param_gd, 'accuracy',10, 5)"
      ],
      "metadata": {
        "id": "On11WAQgvDsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b680272-db74-4656-8f50-3669a3473a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "[CV 1/5; 1/48] START C=0.01, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 1/5; 1/48] END C=0.01, max_iter=100, penalty=l2, tol=0.0001;, score=0.855 total time=  10.0s\n",
            "[CV 2/5; 1/48] START C=0.01, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 2/5; 1/48] END C=0.01, max_iter=100, penalty=l2, tol=0.0001;, score=0.853 total time=   7.6s\n",
            "[CV 3/5; 1/48] START C=0.01, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 3/5; 1/48] END C=0.01, max_iter=100, penalty=l2, tol=0.0001;, score=0.856 total time=   5.6s\n",
            "[CV 4/5; 1/48] START C=0.01, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 4/5; 1/48] END C=0.01, max_iter=100, penalty=l2, tol=0.0001;, score=0.854 total time=   4.8s\n",
            "[CV 5/5; 1/48] START C=0.01, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 5/5; 1/48] END C=0.01, max_iter=100, penalty=l2, tol=0.0001;, score=0.853 total time=   6.7s\n",
            "[CV 1/5; 2/48] START C=0.01, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 1/5; 2/48] END C=0.01, max_iter=100, penalty=l2, tol=0.001;, score=0.855 total time=   9.5s\n",
            "[CV 2/5; 2/48] START C=0.01, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 2/5; 2/48] END C=0.01, max_iter=100, penalty=l2, tol=0.001;, score=0.853 total time=   6.9s\n",
            "[CV 3/5; 2/48] START C=0.01, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 3/5; 2/48] END C=0.01, max_iter=100, penalty=l2, tol=0.001;, score=0.856 total time=   5.4s\n",
            "[CV 4/5; 2/48] START C=0.01, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 4/5; 2/48] END C=0.01, max_iter=100, penalty=l2, tol=0.001;, score=0.854 total time=   4.3s\n",
            "[CV 5/5; 2/48] START C=0.01, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 5/5; 2/48] END C=0.01, max_iter=100, penalty=l2, tol=0.001;, score=0.853 total time=   5.5s\n",
            "[CV 1/5; 3/48] START C=0.01, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 1/5; 3/48] END C=0.01, max_iter=100, penalty=l2, tol=0.01;, score=0.855 total time=   8.0s\n",
            "[CV 2/5; 3/48] START C=0.01, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 2/5; 3/48] END C=0.01, max_iter=100, penalty=l2, tol=0.01;, score=0.853 total time=   7.6s\n",
            "[CV 3/5; 3/48] START C=0.01, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 3/5; 3/48] END C=0.01, max_iter=100, penalty=l2, tol=0.01;, score=0.856 total time=   4.8s\n",
            "[CV 4/5; 3/48] START C=0.01, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 4/5; 3/48] END C=0.01, max_iter=100, penalty=l2, tol=0.01;, score=0.854 total time=   6.5s\n",
            "[CV 5/5; 3/48] START C=0.01, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 5/5; 3/48] END C=0.01, max_iter=100, penalty=l2, tol=0.01;, score=0.853 total time=   4.3s\n",
            "[CV 1/5; 4/48] START C=0.01, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 1/5; 4/48] END C=0.01, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 2/5; 4/48] START C=0.01, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 2/5; 4/48] END C=0.01, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 3/5; 4/48] START C=0.01, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 3/5; 4/48] END C=0.01, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 4/5; 4/48] START C=0.01, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 4/5; 4/48] END C=0.01, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 5/5; 4/48] START C=0.01, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 5/5; 4/48] END C=0.01, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 1/5; 5/48] START C=0.01, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 1/5; 5/48] END C=0.01, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 2/5; 5/48] START C=0.01, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 2/5; 5/48] END C=0.01, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 3/5; 5/48] START C=0.01, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 3/5; 5/48] END C=0.01, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 4/5; 5/48] START C=0.01, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 4/5; 5/48] END C=0.01, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 5/5; 5/48] START C=0.01, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 5/5; 5/48] END C=0.01, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.9s\n",
            "[CV 1/5; 6/48] START C=0.01, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 1/5; 6/48] END C=0.01, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 2/5; 6/48] START C=0.01, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 2/5; 6/48] END C=0.01, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   1.0s\n",
            "[CV 3/5; 6/48] START C=0.01, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 3/5; 6/48] END C=0.01, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.9s\n",
            "[CV 4/5; 6/48] START C=0.01, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 4/5; 6/48] END C=0.01, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.9s\n",
            "[CV 5/5; 6/48] START C=0.01, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 5/5; 6/48] END C=0.01, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 1/5; 7/48] START C=0.01, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 1/5; 7/48] END C=0.01, max_iter=200, penalty=l2, tol=0.0001;, score=0.855 total time=   9.7s\n",
            "[CV 2/5; 7/48] START C=0.01, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 2/5; 7/48] END C=0.01, max_iter=200, penalty=l2, tol=0.0001;, score=0.853 total time=   6.3s\n",
            "[CV 3/5; 7/48] START C=0.01, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 3/5; 7/48] END C=0.01, max_iter=200, penalty=l2, tol=0.0001;, score=0.856 total time=   5.4s\n",
            "[CV 4/5; 7/48] START C=0.01, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 4/5; 7/48] END C=0.01, max_iter=200, penalty=l2, tol=0.0001;, score=0.854 total time=   5.2s\n",
            "[CV 5/5; 7/48] START C=0.01, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 5/5; 7/48] END C=0.01, max_iter=200, penalty=l2, tol=0.0001;, score=0.853 total time=   4.8s\n",
            "[CV 1/5; 8/48] START C=0.01, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 1/5; 8/48] END C=0.01, max_iter=200, penalty=l2, tol=0.001;, score=0.855 total time=   8.9s\n",
            "[CV 2/5; 8/48] START C=0.01, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 2/5; 8/48] END C=0.01, max_iter=200, penalty=l2, tol=0.001;, score=0.853 total time=   6.7s\n",
            "[CV 3/5; 8/48] START C=0.01, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 3/5; 8/48] END C=0.01, max_iter=200, penalty=l2, tol=0.001;, score=0.856 total time=   5.1s\n",
            "[CV 4/5; 8/48] START C=0.01, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 4/5; 8/48] END C=0.01, max_iter=200, penalty=l2, tol=0.001;, score=0.854 total time=   5.2s\n",
            "[CV 5/5; 8/48] START C=0.01, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 5/5; 8/48] END C=0.01, max_iter=200, penalty=l2, tol=0.001;, score=0.853 total time=   4.2s\n",
            "[CV 1/5; 9/48] START C=0.01, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 1/5; 9/48] END C=0.01, max_iter=200, penalty=l2, tol=0.01;, score=0.855 total time=  10.4s\n",
            "[CV 2/5; 9/48] START C=0.01, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 2/5; 9/48] END C=0.01, max_iter=200, penalty=l2, tol=0.01;, score=0.853 total time=   5.8s\n",
            "[CV 3/5; 9/48] START C=0.01, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 3/5; 9/48] END C=0.01, max_iter=200, penalty=l2, tol=0.01;, score=0.856 total time=   6.3s\n",
            "[CV 4/5; 9/48] START C=0.01, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 4/5; 9/48] END C=0.01, max_iter=200, penalty=l2, tol=0.01;, score=0.854 total time=   4.2s\n",
            "[CV 5/5; 9/48] START C=0.01, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 5/5; 9/48] END C=0.01, max_iter=200, penalty=l2, tol=0.01;, score=0.853 total time=   4.9s\n",
            "[CV 1/5; 10/48] START C=0.01, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 1/5; 10/48] END C=0.01, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 2/5; 10/48] START C=0.01, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 2/5; 10/48] END C=0.01, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 3/5; 10/48] START C=0.01, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 3/5; 10/48] END C=0.01, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 4/5; 10/48] START C=0.01, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 4/5; 10/48] END C=0.01, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 5/5; 10/48] START C=0.01, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 5/5; 10/48] END C=0.01, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 1/5; 11/48] START C=0.01, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 1/5; 11/48] END C=0.01, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 2/5; 11/48] START C=0.01, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 2/5; 11/48] END C=0.01, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 3/5; 11/48] START C=0.01, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 3/5; 11/48] END C=0.01, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 4/5; 11/48] START C=0.01, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 4/5; 11/48] END C=0.01, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 5/5; 11/48] START C=0.01, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 5/5; 11/48] END C=0.01, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 1/5; 12/48] START C=0.01, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 1/5; 12/48] END C=0.01, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 2/5; 12/48] START C=0.01, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 2/5; 12/48] END C=0.01, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 3/5; 12/48] START C=0.01, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 3/5; 12/48] END C=0.01, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 4/5; 12/48] START C=0.01, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 4/5; 12/48] END C=0.01, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 5/5; 12/48] START C=0.01, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 5/5; 12/48] END C=0.01, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 1/5; 13/48] START C=0.1, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 1/5; 13/48] END C=0.1, max_iter=100, penalty=l2, tol=0.0001;, score=0.877 total time=  11.2s\n",
            "[CV 2/5; 13/48] START C=0.1, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 2/5; 13/48] END C=0.1, max_iter=100, penalty=l2, tol=0.0001;, score=0.876 total time=  10.9s\n",
            "[CV 3/5; 13/48] START C=0.1, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 3/5; 13/48] END C=0.1, max_iter=100, penalty=l2, tol=0.0001;, score=0.876 total time=   8.5s\n",
            "[CV 4/5; 13/48] START C=0.1, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 4/5; 13/48] END C=0.1, max_iter=100, penalty=l2, tol=0.0001;, score=0.878 total time=  11.7s\n",
            "[CV 5/5; 13/48] START C=0.1, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 5/5; 13/48] END C=0.1, max_iter=100, penalty=l2, tol=0.0001;, score=0.877 total time=   9.2s\n",
            "[CV 1/5; 14/48] START C=0.1, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 1/5; 14/48] END C=0.1, max_iter=100, penalty=l2, tol=0.001;, score=0.877 total time=  13.6s\n",
            "[CV 2/5; 14/48] START C=0.1, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 2/5; 14/48] END C=0.1, max_iter=100, penalty=l2, tol=0.001;, score=0.876 total time=   9.2s\n",
            "[CV 3/5; 14/48] START C=0.1, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 3/5; 14/48] END C=0.1, max_iter=100, penalty=l2, tol=0.001;, score=0.876 total time=  11.1s\n",
            "[CV 4/5; 14/48] START C=0.1, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 4/5; 14/48] END C=0.1, max_iter=100, penalty=l2, tol=0.001;, score=0.878 total time=  10.3s\n",
            "[CV 5/5; 14/48] START C=0.1, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 5/5; 14/48] END C=0.1, max_iter=100, penalty=l2, tol=0.001;, score=0.877 total time=   9.9s\n",
            "[CV 1/5; 15/48] START C=0.1, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 1/5; 15/48] END C=0.1, max_iter=100, penalty=l2, tol=0.01;, score=0.877 total time=  10.7s\n",
            "[CV 2/5; 15/48] START C=0.1, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 2/5; 15/48] END C=0.1, max_iter=100, penalty=l2, tol=0.01;, score=0.876 total time=  11.0s\n",
            "[CV 3/5; 15/48] START C=0.1, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 3/5; 15/48] END C=0.1, max_iter=100, penalty=l2, tol=0.01;, score=0.876 total time=   9.6s\n",
            "[CV 4/5; 15/48] START C=0.1, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 4/5; 15/48] END C=0.1, max_iter=100, penalty=l2, tol=0.01;, score=0.878 total time=  10.7s\n",
            "[CV 5/5; 15/48] START C=0.1, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 5/5; 15/48] END C=0.1, max_iter=100, penalty=l2, tol=0.01;, score=0.877 total time=   9.0s\n",
            "[CV 1/5; 16/48] START C=0.1, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 1/5; 16/48] END C=0.1, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 2/5; 16/48] START C=0.1, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 2/5; 16/48] END C=0.1, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 3/5; 16/48] START C=0.1, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 3/5; 16/48] END C=0.1, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 4/5; 16/48] START C=0.1, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 4/5; 16/48] END C=0.1, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 5/5; 16/48] START C=0.1, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 5/5; 16/48] END C=0.1, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 1/5; 17/48] START C=0.1, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 1/5; 17/48] END C=0.1, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.9s\n",
            "[CV 2/5; 17/48] START C=0.1, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 2/5; 17/48] END C=0.1, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.9s\n",
            "[CV 3/5; 17/48] START C=0.1, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 3/5; 17/48] END C=0.1, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.9s\n",
            "[CV 4/5; 17/48] START C=0.1, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 4/5; 17/48] END C=0.1, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.9s\n",
            "[CV 5/5; 17/48] START C=0.1, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 5/5; 17/48] END C=0.1, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 1/5; 18/48] START C=0.1, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 1/5; 18/48] END C=0.1, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 2/5; 18/48] START C=0.1, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 2/5; 18/48] END C=0.1, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 3/5; 18/48] START C=0.1, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 3/5; 18/48] END C=0.1, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 4/5; 18/48] START C=0.1, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 4/5; 18/48] END C=0.1, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 5/5; 18/48] START C=0.1, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 5/5; 18/48] END C=0.1, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 1/5; 19/48] START C=0.1, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 1/5; 19/48] END C=0.1, max_iter=200, penalty=l2, tol=0.0001;, score=0.877 total time=  12.6s\n",
            "[CV 2/5; 19/48] START C=0.1, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 2/5; 19/48] END C=0.1, max_iter=200, penalty=l2, tol=0.0001;, score=0.876 total time=   9.1s\n",
            "[CV 3/5; 19/48] START C=0.1, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 3/5; 19/48] END C=0.1, max_iter=200, penalty=l2, tol=0.0001;, score=0.876 total time=  10.4s\n",
            "[CV 4/5; 19/48] START C=0.1, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 4/5; 19/48] END C=0.1, max_iter=200, penalty=l2, tol=0.0001;, score=0.878 total time=  10.2s\n",
            "[CV 5/5; 19/48] START C=0.1, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 5/5; 19/48] END C=0.1, max_iter=200, penalty=l2, tol=0.0001;, score=0.877 total time=  10.3s\n",
            "[CV 1/5; 20/48] START C=0.1, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 1/5; 20/48] END C=0.1, max_iter=200, penalty=l2, tol=0.001;, score=0.877 total time=  10.5s\n",
            "[CV 2/5; 20/48] START C=0.1, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 2/5; 20/48] END C=0.1, max_iter=200, penalty=l2, tol=0.001;, score=0.876 total time=  12.1s\n",
            "[CV 3/5; 20/48] START C=0.1, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 3/5; 20/48] END C=0.1, max_iter=200, penalty=l2, tol=0.001;, score=0.876 total time=   9.8s\n",
            "[CV 4/5; 20/48] START C=0.1, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 4/5; 20/48] END C=0.1, max_iter=200, penalty=l2, tol=0.001;, score=0.878 total time=  11.7s\n",
            "[CV 5/5; 20/48] START C=0.1, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 5/5; 20/48] END C=0.1, max_iter=200, penalty=l2, tol=0.001;, score=0.877 total time=   8.5s\n",
            "[CV 1/5; 21/48] START C=0.1, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 1/5; 21/48] END C=0.1, max_iter=200, penalty=l2, tol=0.01;, score=0.877 total time=  12.8s\n",
            "[CV 2/5; 21/48] START C=0.1, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 2/5; 21/48] END C=0.1, max_iter=200, penalty=l2, tol=0.01;, score=0.876 total time=   9.7s\n",
            "[CV 3/5; 21/48] START C=0.1, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 3/5; 21/48] END C=0.1, max_iter=200, penalty=l2, tol=0.01;, score=0.876 total time=  10.0s\n",
            "[CV 4/5; 21/48] START C=0.1, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 4/5; 21/48] END C=0.1, max_iter=200, penalty=l2, tol=0.01;, score=0.878 total time=   9.9s\n",
            "[CV 5/5; 21/48] START C=0.1, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 5/5; 21/48] END C=0.1, max_iter=200, penalty=l2, tol=0.01;, score=0.877 total time=  10.5s\n",
            "[CV 1/5; 22/48] START C=0.1, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 1/5; 22/48] END C=0.1, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 2/5; 22/48] START C=0.1, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 2/5; 22/48] END C=0.1, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 3/5; 22/48] START C=0.1, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 3/5; 22/48] END C=0.1, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 4/5; 22/48] START C=0.1, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 4/5; 22/48] END C=0.1, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 5/5; 22/48] START C=0.1, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 5/5; 22/48] END C=0.1, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 1/5; 23/48] START C=0.1, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 1/5; 23/48] END C=0.1, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 2/5; 23/48] START C=0.1, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 2/5; 23/48] END C=0.1, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 3/5; 23/48] START C=0.1, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 3/5; 23/48] END C=0.1, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 4/5; 23/48] START C=0.1, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 4/5; 23/48] END C=0.1, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 5/5; 23/48] START C=0.1, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 5/5; 23/48] END C=0.1, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 1/5; 24/48] START C=0.1, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 1/5; 24/48] END C=0.1, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 2/5; 24/48] START C=0.1, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 2/5; 24/48] END C=0.1, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 3/5; 24/48] START C=0.1, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 3/5; 24/48] END C=0.1, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 4/5; 24/48] START C=0.1, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 4/5; 24/48] END C=0.1, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 5/5; 24/48] START C=0.1, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 5/5; 24/48] END C=0.1, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 1/5; 25/48] START C=1.0, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 1/5; 25/48] END C=1.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.882 total time=  24.3s\n",
            "[CV 2/5; 25/48] START C=1.0, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 2/5; 25/48] END C=1.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.886 total time=  22.4s\n",
            "[CV 3/5; 25/48] START C=1.0, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 3/5; 25/48] END C=1.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.884 total time=  22.0s\n",
            "[CV 4/5; 25/48] START C=1.0, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 4/5; 25/48] END C=1.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.887 total time=  26.1s\n",
            "[CV 5/5; 25/48] START C=1.0, max_iter=100, penalty=l2, tol=0.0001...............\n",
            "[CV 5/5; 25/48] END C=1.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.886 total time=  20.8s\n",
            "[CV 1/5; 26/48] START C=1.0, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 1/5; 26/48] END C=1.0, max_iter=100, penalty=l2, tol=0.001;, score=0.882 total time=  29.2s\n",
            "[CV 2/5; 26/48] START C=1.0, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 2/5; 26/48] END C=1.0, max_iter=100, penalty=l2, tol=0.001;, score=0.886 total time=  19.3s\n",
            "[CV 3/5; 26/48] START C=1.0, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 3/5; 26/48] END C=1.0, max_iter=100, penalty=l2, tol=0.001;, score=0.884 total time=  26.3s\n",
            "[CV 4/5; 26/48] START C=1.0, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 4/5; 26/48] END C=1.0, max_iter=100, penalty=l2, tol=0.001;, score=0.887 total time=  20.9s\n",
            "[CV 5/5; 26/48] START C=1.0, max_iter=100, penalty=l2, tol=0.001................\n",
            "[CV 5/5; 26/48] END C=1.0, max_iter=100, penalty=l2, tol=0.001;, score=0.886 total time=  22.7s\n",
            "[CV 1/5; 27/48] START C=1.0, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 1/5; 27/48] END C=1.0, max_iter=100, penalty=l2, tol=0.01;, score=0.882 total time=  25.9s\n",
            "[CV 2/5; 27/48] START C=1.0, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 2/5; 27/48] END C=1.0, max_iter=100, penalty=l2, tol=0.01;, score=0.886 total time=  24.2s\n",
            "[CV 3/5; 27/48] START C=1.0, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 3/5; 27/48] END C=1.0, max_iter=100, penalty=l2, tol=0.01;, score=0.884 total time=  22.4s\n",
            "[CV 4/5; 27/48] START C=1.0, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 4/5; 27/48] END C=1.0, max_iter=100, penalty=l2, tol=0.01;, score=0.887 total time=  24.4s\n",
            "[CV 5/5; 27/48] START C=1.0, max_iter=100, penalty=l2, tol=0.01.................\n",
            "[CV 5/5; 27/48] END C=1.0, max_iter=100, penalty=l2, tol=0.01;, score=0.886 total time=  20.0s\n",
            "[CV 1/5; 28/48] START C=1.0, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 1/5; 28/48] END C=1.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 2/5; 28/48] START C=1.0, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 2/5; 28/48] END C=1.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 3/5; 28/48] START C=1.0, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 3/5; 28/48] END C=1.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 4/5; 28/48] START C=1.0, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 4/5; 28/48] END C=1.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 5/5; 28/48] START C=1.0, max_iter=100, penalty=l1, tol=0.0001...............\n",
            "[CV 5/5; 28/48] END C=1.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 1/5; 29/48] START C=1.0, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 1/5; 29/48] END C=1.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 2/5; 29/48] START C=1.0, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 2/5; 29/48] END C=1.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 3/5; 29/48] START C=1.0, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 3/5; 29/48] END C=1.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 4/5; 29/48] START C=1.0, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 4/5; 29/48] END C=1.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 5/5; 29/48] START C=1.0, max_iter=100, penalty=l1, tol=0.001................\n",
            "[CV 5/5; 29/48] END C=1.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 1/5; 30/48] START C=1.0, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 1/5; 30/48] END C=1.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 2/5; 30/48] START C=1.0, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 2/5; 30/48] END C=1.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 3/5; 30/48] START C=1.0, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 3/5; 30/48] END C=1.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 4/5; 30/48] START C=1.0, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 4/5; 30/48] END C=1.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 5/5; 30/48] START C=1.0, max_iter=100, penalty=l1, tol=0.01.................\n",
            "[CV 5/5; 30/48] END C=1.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 1/5; 31/48] START C=1.0, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 1/5; 31/48] END C=1.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.882 total time=  29.0s\n",
            "[CV 2/5; 31/48] START C=1.0, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 2/5; 31/48] END C=1.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.886 total time=  19.0s\n",
            "[CV 3/5; 31/48] START C=1.0, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 3/5; 31/48] END C=1.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.884 total time=  27.1s\n",
            "[CV 4/5; 31/48] START C=1.0, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 4/5; 31/48] END C=1.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.887 total time=  23.4s\n",
            "[CV 5/5; 31/48] START C=1.0, max_iter=200, penalty=l2, tol=0.0001...............\n",
            "[CV 5/5; 31/48] END C=1.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.886 total time=  22.3s\n",
            "[CV 1/5; 32/48] START C=1.0, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 1/5; 32/48] END C=1.0, max_iter=200, penalty=l2, tol=0.001;, score=0.882 total time=  25.5s\n",
            "[CV 2/5; 32/48] START C=1.0, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 2/5; 32/48] END C=1.0, max_iter=200, penalty=l2, tol=0.001;, score=0.886 total time=  21.9s\n",
            "[CV 3/5; 32/48] START C=1.0, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 3/5; 32/48] END C=1.0, max_iter=200, penalty=l2, tol=0.001;, score=0.884 total time=  22.7s\n",
            "[CV 4/5; 32/48] START C=1.0, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 4/5; 32/48] END C=1.0, max_iter=200, penalty=l2, tol=0.001;, score=0.887 total time=  25.1s\n",
            "[CV 5/5; 32/48] START C=1.0, max_iter=200, penalty=l2, tol=0.001................\n",
            "[CV 5/5; 32/48] END C=1.0, max_iter=200, penalty=l2, tol=0.001;, score=0.886 total time=  18.7s\n",
            "[CV 1/5; 33/48] START C=1.0, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 1/5; 33/48] END C=1.0, max_iter=200, penalty=l2, tol=0.01;, score=0.882 total time=  30.1s\n",
            "[CV 2/5; 33/48] START C=1.0, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 2/5; 33/48] END C=1.0, max_iter=200, penalty=l2, tol=0.01;, score=0.886 total time=  20.3s\n",
            "[CV 3/5; 33/48] START C=1.0, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 3/5; 33/48] END C=1.0, max_iter=200, penalty=l2, tol=0.01;, score=0.884 total time=  25.2s\n",
            "[CV 4/5; 33/48] START C=1.0, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 4/5; 33/48] END C=1.0, max_iter=200, penalty=l2, tol=0.01;, score=0.887 total time=  22.0s\n",
            "[CV 5/5; 33/48] START C=1.0, max_iter=200, penalty=l2, tol=0.01.................\n",
            "[CV 5/5; 33/48] END C=1.0, max_iter=200, penalty=l2, tol=0.01;, score=0.886 total time=  21.5s\n",
            "[CV 1/5; 34/48] START C=1.0, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 1/5; 34/48] END C=1.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 2/5; 34/48] START C=1.0, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 2/5; 34/48] END C=1.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 3/5; 34/48] START C=1.0, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 3/5; 34/48] END C=1.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 4/5; 34/48] START C=1.0, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 4/5; 34/48] END C=1.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 5/5; 34/48] START C=1.0, max_iter=200, penalty=l1, tol=0.0001...............\n",
            "[CV 5/5; 34/48] END C=1.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 1/5; 35/48] START C=1.0, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 1/5; 35/48] END C=1.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 2/5; 35/48] START C=1.0, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 2/5; 35/48] END C=1.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 3/5; 35/48] START C=1.0, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 3/5; 35/48] END C=1.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 4/5; 35/48] START C=1.0, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 4/5; 35/48] END C=1.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 5/5; 35/48] START C=1.0, max_iter=200, penalty=l1, tol=0.001................\n",
            "[CV 5/5; 35/48] END C=1.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 1/5; 36/48] START C=1.0, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 1/5; 36/48] END C=1.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 2/5; 36/48] START C=1.0, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 2/5; 36/48] END C=1.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 3/5; 36/48] START C=1.0, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 3/5; 36/48] END C=1.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 4/5; 36/48] START C=1.0, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 4/5; 36/48] END C=1.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 5/5; 36/48] START C=1.0, max_iter=200, penalty=l1, tol=0.01.................\n",
            "[CV 5/5; 36/48] END C=1.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 1/5; 37/48] START C=10.0, max_iter=100, penalty=l2, tol=0.0001..............\n",
            "[CV 1/5; 37/48] END C=10.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.880 total time=  30.0s\n",
            "[CV 2/5; 37/48] START C=10.0, max_iter=100, penalty=l2, tol=0.0001..............\n",
            "[CV 2/5; 37/48] END C=10.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.885 total time=  35.1s\n",
            "[CV 3/5; 37/48] START C=10.0, max_iter=100, penalty=l2, tol=0.0001..............\n",
            "[CV 3/5; 37/48] END C=10.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.883 total time=  34.0s\n",
            "[CV 4/5; 37/48] START C=10.0, max_iter=100, penalty=l2, tol=0.0001..............\n",
            "[CV 4/5; 37/48] END C=10.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.885 total time=  38.8s\n",
            "[CV 5/5; 37/48] START C=10.0, max_iter=100, penalty=l2, tol=0.0001..............\n",
            "[CV 5/5; 37/48] END C=10.0, max_iter=100, penalty=l2, tol=0.0001;, score=0.886 total time=  30.7s\n",
            "[CV 1/5; 38/48] START C=10.0, max_iter=100, penalty=l2, tol=0.001...............\n",
            "[CV 1/5; 38/48] END C=10.0, max_iter=100, penalty=l2, tol=0.001;, score=0.880 total time=  34.7s\n",
            "[CV 2/5; 38/48] START C=10.0, max_iter=100, penalty=l2, tol=0.001...............\n",
            "[CV 2/5; 38/48] END C=10.0, max_iter=100, penalty=l2, tol=0.001;, score=0.885 total time=  30.3s\n",
            "[CV 3/5; 38/48] START C=10.0, max_iter=100, penalty=l2, tol=0.001...............\n",
            "[CV 3/5; 38/48] END C=10.0, max_iter=100, penalty=l2, tol=0.001;, score=0.883 total time=  37.8s\n",
            "[CV 4/5; 38/48] START C=10.0, max_iter=100, penalty=l2, tol=0.001...............\n",
            "[CV 4/5; 38/48] END C=10.0, max_iter=100, penalty=l2, tol=0.001;, score=0.885 total time=  33.0s\n",
            "[CV 5/5; 38/48] START C=10.0, max_iter=100, penalty=l2, tol=0.001...............\n",
            "[CV 5/5; 38/48] END C=10.0, max_iter=100, penalty=l2, tol=0.001;, score=0.886 total time=  34.8s\n",
            "[CV 1/5; 39/48] START C=10.0, max_iter=100, penalty=l2, tol=0.01................\n",
            "[CV 1/5; 39/48] END C=10.0, max_iter=100, penalty=l2, tol=0.01;, score=0.880 total time=  30.9s\n",
            "[CV 2/5; 39/48] START C=10.0, max_iter=100, penalty=l2, tol=0.01................\n",
            "[CV 2/5; 39/48] END C=10.0, max_iter=100, penalty=l2, tol=0.01;, score=0.885 total time=  34.5s\n",
            "[CV 3/5; 39/48] START C=10.0, max_iter=100, penalty=l2, tol=0.01................\n",
            "[CV 3/5; 39/48] END C=10.0, max_iter=100, penalty=l2, tol=0.01;, score=0.883 total time=  31.4s\n",
            "[CV 4/5; 39/48] START C=10.0, max_iter=100, penalty=l2, tol=0.01................\n",
            "[CV 4/5; 39/48] END C=10.0, max_iter=100, penalty=l2, tol=0.01;, score=0.885 total time=  39.2s\n",
            "[CV 5/5; 39/48] START C=10.0, max_iter=100, penalty=l2, tol=0.01................\n",
            "[CV 5/5; 39/48] END C=10.0, max_iter=100, penalty=l2, tol=0.01;, score=0.886 total time=  30.0s\n",
            "[CV 1/5; 40/48] START C=10.0, max_iter=100, penalty=l1, tol=0.0001..............\n",
            "[CV 1/5; 40/48] END C=10.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 2/5; 40/48] START C=10.0, max_iter=100, penalty=l1, tol=0.0001..............\n",
            "[CV 2/5; 40/48] END C=10.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 3/5; 40/48] START C=10.0, max_iter=100, penalty=l1, tol=0.0001..............\n",
            "[CV 3/5; 40/48] END C=10.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 4/5; 40/48] START C=10.0, max_iter=100, penalty=l1, tol=0.0001..............\n",
            "[CV 4/5; 40/48] END C=10.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 5/5; 40/48] START C=10.0, max_iter=100, penalty=l1, tol=0.0001..............\n",
            "[CV 5/5; 40/48] END C=10.0, max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.8s\n",
            "[CV 1/5; 41/48] START C=10.0, max_iter=100, penalty=l1, tol=0.001...............\n",
            "[CV 1/5; 41/48] END C=10.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 2/5; 41/48] START C=10.0, max_iter=100, penalty=l1, tol=0.001...............\n",
            "[CV 2/5; 41/48] END C=10.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 3/5; 41/48] START C=10.0, max_iter=100, penalty=l1, tol=0.001...............\n",
            "[CV 3/5; 41/48] END C=10.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 4/5; 41/48] START C=10.0, max_iter=100, penalty=l1, tol=0.001...............\n",
            "[CV 4/5; 41/48] END C=10.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 5/5; 41/48] START C=10.0, max_iter=100, penalty=l1, tol=0.001...............\n",
            "[CV 5/5; 41/48] END C=10.0, max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 1/5; 42/48] START C=10.0, max_iter=100, penalty=l1, tol=0.01................\n",
            "[CV 1/5; 42/48] END C=10.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.9s\n",
            "[CV 2/5; 42/48] START C=10.0, max_iter=100, penalty=l1, tol=0.01................\n",
            "[CV 2/5; 42/48] END C=10.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 3/5; 42/48] START C=10.0, max_iter=100, penalty=l1, tol=0.01................\n",
            "[CV 3/5; 42/48] END C=10.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.9s\n",
            "[CV 4/5; 42/48] START C=10.0, max_iter=100, penalty=l1, tol=0.01................\n",
            "[CV 4/5; 42/48] END C=10.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 5/5; 42/48] START C=10.0, max_iter=100, penalty=l1, tol=0.01................\n",
            "[CV 5/5; 42/48] END C=10.0, max_iter=100, penalty=l1, tol=0.01;, score=nan total time=   0.8s\n",
            "[CV 1/5; 43/48] START C=10.0, max_iter=200, penalty=l2, tol=0.0001..............\n",
            "[CV 1/5; 43/48] END C=10.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.880 total time=  55.3s\n",
            "[CV 2/5; 43/48] START C=10.0, max_iter=200, penalty=l2, tol=0.0001..............\n",
            "[CV 2/5; 43/48] END C=10.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.885 total time=  41.7s\n",
            "[CV 3/5; 43/48] START C=10.0, max_iter=200, penalty=l2, tol=0.0001..............\n",
            "[CV 3/5; 43/48] END C=10.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.883 total time= 1.1min\n",
            "[CV 4/5; 43/48] START C=10.0, max_iter=200, penalty=l2, tol=0.0001..............\n",
            "[CV 4/5; 43/48] END C=10.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.885 total time=  43.1s\n",
            "[CV 5/5; 43/48] START C=10.0, max_iter=200, penalty=l2, tol=0.0001..............\n",
            "[CV 5/5; 43/48] END C=10.0, max_iter=200, penalty=l2, tol=0.0001;, score=0.886 total time=  58.6s\n",
            "[CV 1/5; 44/48] START C=10.0, max_iter=200, penalty=l2, tol=0.001...............\n",
            "[CV 1/5; 44/48] END C=10.0, max_iter=200, penalty=l2, tol=0.001;, score=0.880 total time=  50.9s\n",
            "[CV 2/5; 44/48] START C=10.0, max_iter=200, penalty=l2, tol=0.001...............\n",
            "[CV 2/5; 44/48] END C=10.0, max_iter=200, penalty=l2, tol=0.001;, score=0.885 total time=  48.2s\n",
            "[CV 3/5; 44/48] START C=10.0, max_iter=200, penalty=l2, tol=0.001...............\n",
            "[CV 3/5; 44/48] END C=10.0, max_iter=200, penalty=l2, tol=0.001;, score=0.883 total time=  54.5s\n",
            "[CV 4/5; 44/48] START C=10.0, max_iter=200, penalty=l2, tol=0.001...............\n",
            "[CV 4/5; 44/48] END C=10.0, max_iter=200, penalty=l2, tol=0.001;, score=0.885 total time=  49.0s\n",
            "[CV 5/5; 44/48] START C=10.0, max_iter=200, penalty=l2, tol=0.001...............\n",
            "[CV 5/5; 44/48] END C=10.0, max_iter=200, penalty=l2, tol=0.001;, score=0.886 total time=  53.2s\n",
            "[CV 1/5; 45/48] START C=10.0, max_iter=200, penalty=l2, tol=0.01................\n",
            "[CV 1/5; 45/48] END C=10.0, max_iter=200, penalty=l2, tol=0.01;, score=0.880 total time=  55.4s\n",
            "[CV 2/5; 45/48] START C=10.0, max_iter=200, penalty=l2, tol=0.01................\n",
            "[CV 2/5; 45/48] END C=10.0, max_iter=200, penalty=l2, tol=0.01;, score=0.885 total time=  42.0s\n",
            "[CV 3/5; 45/48] START C=10.0, max_iter=200, penalty=l2, tol=0.01................\n",
            "[CV 3/5; 45/48] END C=10.0, max_iter=200, penalty=l2, tol=0.01;, score=0.883 total time= 1.1min\n",
            "[CV 4/5; 45/48] START C=10.0, max_iter=200, penalty=l2, tol=0.01................\n",
            "[CV 4/5; 45/48] END C=10.0, max_iter=200, penalty=l2, tol=0.01;, score=0.885 total time=  43.0s\n",
            "[CV 5/5; 45/48] START C=10.0, max_iter=200, penalty=l2, tol=0.01................\n",
            "[CV 5/5; 45/48] END C=10.0, max_iter=200, penalty=l2, tol=0.01;, score=0.886 total time=  58.2s\n",
            "[CV 1/5; 46/48] START C=10.0, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 1/5; 46/48] END C=10.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 2/5; 46/48] START C=10.0, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 2/5; 46/48] END C=10.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 3/5; 46/48] START C=10.0, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 3/5; 46/48] END C=10.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 4/5; 46/48] START C=10.0, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 4/5; 46/48] END C=10.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 5/5; 46/48] START C=10.0, max_iter=200, penalty=l1, tol=0.0001..............\n",
            "[CV 5/5; 46/48] END C=10.0, max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.7s\n",
            "[CV 1/5; 47/48] START C=10.0, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 1/5; 47/48] END C=10.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 2/5; 47/48] START C=10.0, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 2/5; 47/48] END C=10.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 3/5; 47/48] START C=10.0, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 3/5; 47/48] END C=10.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 4/5; 47/48] START C=10.0, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 4/5; 47/48] END C=10.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.8s\n",
            "[CV 5/5; 47/48] START C=10.0, max_iter=200, penalty=l1, tol=0.001...............\n",
            "[CV 5/5; 47/48] END C=10.0, max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.7s\n",
            "[CV 1/5; 48/48] START C=10.0, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 1/5; 48/48] END C=10.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 2/5; 48/48] START C=10.0, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 2/5; 48/48] END C=10.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 3/5; 48/48] START C=10.0, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 3/5; 48/48] END C=10.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 4/5; 48/48] START C=10.0, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 4/5; 48/48] END C=10.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "[CV 5/5; 48/48] START C=10.0, max_iter=200, penalty=l1, tol=0.01................\n",
            "[CV 5/5; 48/48] END C=10.0, max_iter=200, penalty=l1, tol=0.01;, score=nan total time=   0.7s\n",
            "Best Score {0.8849642857142858}\n",
            "Best hyperParameter Set:\n",
            "\\C: 1.0\n",
            "\\max_iter: 100\n",
            "\\penalty: l2\n",
            "\\tol: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"Precision Score on training dateset for Finetuned Logsitic Regression Classifier: %s\" % precision_score(y_train,model_7.predict(X_train_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for Finetuned Logsitic Regression Classifier: %s\" % roc_auc_score(y_train,model_7.predict_proba(X_train_df)[:,1],multi_class='ovo',average='macro'))\n",
        "f1_score_train_7 =f1_score(y_train, model_7.predict(X_train_df),average=\"weighted\")\n",
        "print(\"F1 Score training dateset for Finetuned Logsitic Regression Classifier: %s\" % f1_score_train_7)\n",
        "print(\"Precision Score on test for Finetuned Logsitic Regression Classifier: %s\" % precision_score(y_test,model_7.predict(X_test_df),average='micro'))\n",
        "print(\"AUC Score on test for Finetuned Logsitic Regression Classifier: %s\" % roc_auc_score(y_test,model_7.predict_proba(X_test_df)[:,1],multi_class='ovo',average='macro'))\n",
        "f1_score_7 =f1_score(y_test,model_7.predict(X_test_df),average=\"weighted\")\n",
        "print(\"F1 Score for Finetuned Logsitic Regression Classifier: %s\" % f1_score_7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE8ZR2IevDoi",
        "outputId": "2a56ed19-c7cc-4ff0-d423-2a8734b701fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score on training dateset for Finetuned Logsitic Regression Classifier: 0.8958452380952381\n",
            "AUC Score on training dateset for Finetuned Logsitic Regression Classifier: 0.9609615454169856\n",
            "F1 Score training dateset for Finetuned Logsitic Regression Classifier: 0.8958431466230218\n",
            "Precision Score on test for Finetuned Logsitic Regression Classifier: 0.8853888888888889\n",
            "AUC Score on test for Finetuned Logsitic Regression Classifier: 0.9534461796981488\n",
            "F1 Score for Finetuned Logsitic Regression Classifier: 0.8853908950079604\n",
            "CPU times: user 6.37 s, sys: 595 ms, total: 6.97 s\n",
            "Wall time: 5.93 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tuning with random forest classifier"
      ],
      "metadata": {
        "id": "meIiXl8C_WWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators':[100, 200],\n",
        "    'max_depth':[9, 11, 13],\n",
        "    'criterion':['gini','entropy'],\n",
        "    'min_samples_split':[3,6,9],\n",
        "    'min_samples_leaf':[3,5],\n",
        "    'max_features':['sqrt','log2']\n",
        "}\n",
        "model_8, best_param_8 = hyperparametertuning(RandomForestClassifier(),param_grid, 'accuracy',10, 3)"
      ],
      "metadata": {
        "id": "fk9uJJcAvDmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29c5921-5085-47bb-cca6-6d50240c3e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
            "[CV 1/3; 1/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 1/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.812 total time=  48.3s\n",
            "[CV 2/3; 1/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 1/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.813 total time=  33.6s\n",
            "[CV 3/3; 1/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 1/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.804 total time=  35.1s\n",
            "[CV 1/3; 2/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 2/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.815 total time= 1.1min\n",
            "[CV 2/3; 2/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 2/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.814 total time= 1.1min\n",
            "[CV 3/3; 2/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 2/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.811 total time= 1.1min\n",
            "[CV 1/3; 3/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 3/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.812 total time=  33.2s\n",
            "[CV 2/3; 3/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 3/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.816 total time=  34.2s\n",
            "[CV 3/3; 3/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 3/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.808 total time=  33.2s\n",
            "[CV 1/3; 4/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 4/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.813 total time= 1.1min\n",
            "[CV 2/3; 4/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 4/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.815 total time= 1.1min\n",
            "[CV 3/3; 4/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 4/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.815 total time= 1.1min\n",
            "[CV 1/3; 5/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 5/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.810 total time=  36.3s\n",
            "[CV 2/3; 5/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 5/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.810 total time=  33.3s\n",
            "[CV 3/3; 5/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 5/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.808 total time=  34.2s\n",
            "[CV 1/3; 6/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 6/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.816 total time= 1.1min\n",
            "[CV 2/3; 6/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 6/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.812 total time= 1.1min\n",
            "[CV 3/3; 6/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 6/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.810 total time= 1.1min\n",
            "[CV 1/3; 7/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 7/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.805 total time=  33.4s\n",
            "[CV 2/3; 7/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 7/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.815 total time=  34.9s\n",
            "[CV 3/3; 7/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 7/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.809 total time=  35.3s\n",
            "[CV 1/3; 8/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 8/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.817 total time= 1.1min\n",
            "[CV 2/3; 8/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 8/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.814 total time= 1.1min\n",
            "[CV 3/3; 8/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 8/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.812 total time= 1.1min\n",
            "[CV 1/3; 9/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 9/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.811 total time=  33.8s\n",
            "[CV 2/3; 9/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 9/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.815 total time=  34.1s\n",
            "[CV 3/3; 9/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 9/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.807 total time=  33.4s\n",
            "[CV 1/3; 10/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 10/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.813 total time= 1.1min\n",
            "[CV 2/3; 10/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 10/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.813 total time= 1.1min\n",
            "[CV 3/3; 10/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 10/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.810 total time= 1.1min\n",
            "[CV 1/3; 11/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 11/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.807 total time=  35.2s\n",
            "[CV 2/3; 11/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 11/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.810 total time=  34.8s\n",
            "[CV 3/3; 11/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 11/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.810 total time=  33.5s\n",
            "[CV 1/3; 12/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 12/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.813 total time= 1.1min\n",
            "[CV 2/3; 12/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 12/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.816 total time= 1.1min\n",
            "[CV 3/3; 12/144] START criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 12/144] END criterion=gini, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.808 total time= 1.1min\n",
            "[CV 1/3; 13/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 13/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.835 total time=  10.8s\n",
            "[CV 2/3; 13/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 13/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.830 total time=  10.2s\n",
            "[CV 3/3; 13/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 13/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.831 total time=   9.7s\n",
            "[CV 1/3; 14/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 14/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.843 total time=  19.0s\n",
            "[CV 2/3; 14/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 14/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.842 total time=  18.7s\n",
            "[CV 3/3; 14/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 14/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.845 total time=  21.4s\n",
            "[CV 1/3; 15/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 15/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.833 total time=  10.3s\n",
            "[CV 2/3; 15/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 15/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.832 total time=   9.9s\n",
            "[CV 3/3; 15/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 15/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.827 total time=  10.4s\n",
            "[CV 1/3; 16/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 16/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.838 total time=  19.1s\n",
            "[CV 2/3; 16/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 16/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.845 total time=  19.2s\n",
            "[CV 3/3; 16/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 16/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.833 total time=  18.4s\n",
            "[CV 1/3; 17/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 17/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.834 total time=  10.3s\n",
            "[CV 2/3; 17/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 17/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.830 total time=  10.3s\n",
            "[CV 3/3; 17/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 17/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.824 total time=  10.3s\n",
            "[CV 1/3; 18/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 18/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.847 total time=  18.8s\n",
            "[CV 2/3; 18/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 18/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.837 total time=  19.3s\n",
            "[CV 3/3; 18/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 18/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.837 total time=  20.3s\n",
            "[CV 1/3; 19/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 19/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.837 total time=  11.5s\n",
            "[CV 2/3; 19/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 19/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.834 total time=  10.0s\n",
            "[CV 3/3; 19/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 19/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.830 total time=  10.0s\n",
            "[CV 1/3; 20/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 20/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.838 total time=  19.7s\n",
            "[CV 2/3; 20/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 20/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.845 total time=  18.7s\n",
            "[CV 3/3; 20/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 20/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.840 total time=  19.4s\n",
            "[CV 1/3; 21/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 21/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.837 total time=   9.6s\n",
            "[CV 2/3; 21/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 21/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.837 total time=  10.3s\n",
            "[CV 3/3; 21/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 21/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.836 total time=  10.3s\n",
            "[CV 1/3; 22/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 22/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.843 total time=  18.7s\n",
            "[CV 2/3; 22/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 22/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.846 total time=  19.5s\n",
            "[CV 3/3; 22/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 22/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.844 total time=  19.7s\n",
            "[CV 1/3; 23/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 23/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.834 total time=  11.4s\n",
            "[CV 2/3; 23/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 23/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.834 total time=  10.5s\n",
            "[CV 3/3; 23/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 23/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.832 total time=   9.9s\n",
            "[CV 1/3; 24/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 24/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.841 total time=  18.9s\n",
            "[CV 2/3; 24/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 24/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.847 total time=  18.6s\n",
            "[CV 3/3; 24/144] START criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 24/144] END criterion=gini, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.841 total time=  19.6s\n",
            "[CV 1/3; 25/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 25/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.817 total time=  39.9s\n",
            "[CV 2/3; 25/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 25/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.816 total time=  40.3s\n",
            "[CV 3/3; 25/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 25/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.812 total time=  41.7s\n",
            "[CV 1/3; 26/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 26/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.818 total time= 1.3min\n",
            "[CV 2/3; 26/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 26/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.816 total time= 1.3min\n",
            "[CV 3/3; 26/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 26/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.817 total time= 1.3min\n",
            "[CV 1/3; 27/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 27/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.818 total time=  40.1s\n",
            "[CV 2/3; 27/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 27/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.818 total time=  40.4s\n",
            "[CV 3/3; 27/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 27/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.812 total time=  42.7s\n",
            "[CV 1/3; 28/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 28/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.815 total time= 1.3min\n",
            "[CV 2/3; 28/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 28/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.818 total time= 1.3min\n",
            "[CV 3/3; 28/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 28/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.814 total time= 1.3min\n",
            "[CV 1/3; 29/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 29/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.816 total time=  40.3s\n",
            "[CV 2/3; 29/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 29/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.814 total time=  40.1s\n",
            "[CV 3/3; 29/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 29/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.813 total time=  43.0s\n",
            "[CV 1/3; 30/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 30/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.818 total time= 1.4min\n",
            "[CV 2/3; 30/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 30/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.821 total time= 1.4min\n",
            "[CV 3/3; 30/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 30/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.817 total time= 1.3min\n",
            "[CV 1/3; 31/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 31/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.815 total time=  39.7s\n",
            "[CV 2/3; 31/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 31/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.815 total time=  40.0s\n",
            "[CV 3/3; 31/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 31/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.811 total time=  42.0s\n",
            "[CV 1/3; 32/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 32/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.818 total time= 1.3min\n",
            "[CV 2/3; 32/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 32/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.817 total time= 1.3min\n",
            "[CV 3/3; 32/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 32/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.814 total time= 1.3min\n",
            "[CV 1/3; 33/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 33/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.811 total time=  40.0s\n",
            "[CV 2/3; 33/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 33/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.818 total time=  39.8s\n",
            "[CV 3/3; 33/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 33/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.815 total time=  42.2s\n",
            "[CV 1/3; 34/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 34/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.817 total time= 1.3min\n",
            "[CV 2/3; 34/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 34/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.816 total time= 1.3min\n",
            "[CV 3/3; 34/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 34/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.812 total time= 1.3min\n",
            "[CV 1/3; 35/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 35/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.813 total time=  40.2s\n",
            "[CV 2/3; 35/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 35/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.816 total time=  40.1s\n",
            "[CV 3/3; 35/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 35/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.814 total time=  42.0s\n",
            "[CV 1/3; 36/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 36/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.818 total time= 1.3min\n",
            "[CV 2/3; 36/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 36/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.818 total time= 1.3min\n",
            "[CV 3/3; 36/144] START criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 36/144] END criterion=gini, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.815 total time= 1.3min\n",
            "[CV 1/3; 37/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 37/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.842 total time=  11.9s\n",
            "[CV 2/3; 37/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 37/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.835 total time=  11.9s\n",
            "[CV 3/3; 37/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 37/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.841 total time=  12.0s\n",
            "[CV 1/3; 38/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 38/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.845 total time=  22.4s\n",
            "[CV 2/3; 38/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 38/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.844 total time=  22.0s\n",
            "[CV 3/3; 38/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 38/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.846 total time=  22.8s\n",
            "[CV 1/3; 39/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 39/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.843 total time=  12.6s\n",
            "[CV 2/3; 39/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 39/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.838 total time=  13.1s\n",
            "[CV 3/3; 39/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 39/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.835 total time=  11.7s\n",
            "[CV 1/3; 40/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 40/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.845 total time=  22.0s\n",
            "[CV 2/3; 40/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 40/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.844 total time=  22.7s\n",
            "[CV 3/3; 40/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 40/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.844 total time=  22.5s\n",
            "[CV 1/3; 41/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 41/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.839 total time=  11.2s\n",
            "[CV 2/3; 41/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 41/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.839 total time=  11.5s\n",
            "[CV 3/3; 41/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 41/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.838 total time=  11.8s\n",
            "[CV 1/3; 42/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 42/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.846 total time=  22.5s\n",
            "[CV 2/3; 42/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 42/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.846 total time=  22.7s\n",
            "[CV 3/3; 42/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 42/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.842 total time=  23.6s\n",
            "[CV 1/3; 43/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 43/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.838 total time=  11.7s\n",
            "[CV 2/3; 43/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 43/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.839 total time=  11.8s\n",
            "[CV 3/3; 43/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 43/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.835 total time=  11.8s\n",
            "[CV 1/3; 44/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 44/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.845 total time=  21.8s\n",
            "[CV 2/3; 44/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 44/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.843 total time=  22.1s\n",
            "[CV 3/3; 44/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 44/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.839 total time=  22.5s\n",
            "[CV 1/3; 45/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 45/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.835 total time=  11.7s\n",
            "[CV 2/3; 45/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 45/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.833 total time=  12.1s\n",
            "[CV 3/3; 45/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 45/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.835 total time=  11.6s\n",
            "[CV 1/3; 46/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 46/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.847 total time=  23.3s\n",
            "[CV 2/3; 46/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 46/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.842 total time=  23.9s\n",
            "[CV 3/3; 46/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 46/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.843 total time=  23.2s\n",
            "[CV 1/3; 47/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 47/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.839 total time=  11.9s\n",
            "[CV 2/3; 47/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 47/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.838 total time=  11.4s\n",
            "[CV 3/3; 47/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 47/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.841 total time=  11.8s\n",
            "[CV 1/3; 48/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 48/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.847 total time=  22.7s\n",
            "[CV 2/3; 48/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 48/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.844 total time=  22.9s\n",
            "[CV 3/3; 48/144] START criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 48/144] END criterion=gini, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.839 total time=  22.0s\n",
            "[CV 1/3; 49/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 49/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.817 total time=  47.8s\n",
            "[CV 2/3; 49/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 49/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.818 total time=  46.7s\n",
            "[CV 3/3; 49/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 49/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.817 total time=  45.9s\n",
            "[CV 1/3; 50/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 50/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.819 total time= 1.5min\n",
            "[CV 2/3; 50/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 50/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.819 total time= 1.5min\n",
            "[CV 3/3; 50/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 50/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.819 total time= 1.5min\n",
            "[CV 1/3; 51/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 51/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.818 total time=  47.5s\n",
            "[CV 2/3; 51/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 51/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.818 total time=  45.1s\n",
            "[CV 3/3; 51/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 51/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.813 total time=  45.9s\n",
            "[CV 1/3; 52/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 52/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.822 total time= 1.5min\n",
            "[CV 2/3; 52/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 52/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.821 total time= 1.5min\n",
            "[CV 3/3; 52/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 52/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.817 total time= 1.5min\n",
            "[CV 1/3; 53/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 53/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.816 total time=  45.3s\n",
            "[CV 2/3; 53/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 53/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.814 total time=  45.7s\n",
            "[CV 3/3; 53/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 53/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.815 total time=  45.7s\n",
            "[CV 1/3; 54/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 54/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.821 total time= 1.5min\n",
            "[CV 2/3; 54/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 54/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.822 total time= 1.5min\n",
            "[CV 3/3; 54/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 54/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.818 total time= 1.5min\n",
            "[CV 1/3; 55/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 55/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.818 total time=  45.7s\n",
            "[CV 2/3; 55/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 55/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.818 total time=  45.1s\n",
            "[CV 3/3; 55/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 55/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.815 total time=  48.2s\n",
            "[CV 1/3; 56/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 56/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.822 total time= 1.5min\n",
            "[CV 2/3; 56/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 56/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.821 total time= 1.5min\n",
            "[CV 3/3; 56/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 56/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.821 total time= 1.5min\n",
            "[CV 1/3; 57/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 57/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.818 total time=  44.9s\n",
            "[CV 2/3; 57/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 57/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.819 total time=  48.2s\n",
            "[CV 3/3; 57/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 57/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.814 total time=  44.8s\n",
            "[CV 1/3; 58/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 58/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.820 total time= 1.5min\n",
            "[CV 2/3; 58/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 58/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.822 total time= 1.5min\n",
            "[CV 3/3; 58/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 58/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.817 total time= 1.5min\n",
            "[CV 1/3; 59/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 59/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.817 total time=  47.3s\n",
            "[CV 2/3; 59/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 59/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.815 total time=  45.4s\n",
            "[CV 3/3; 59/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 59/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.816 total time=  46.2s\n",
            "[CV 1/3; 60/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 60/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.821 total time= 1.5min\n",
            "[CV 2/3; 60/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 60/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.820 total time= 1.5min\n",
            "[CV 3/3; 60/144] START criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 60/144] END criterion=gini, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.819 total time= 1.5min\n",
            "[CV 1/3; 61/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 61/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.842 total time=  14.4s\n",
            "[CV 2/3; 61/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 61/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.839 total time=  13.4s\n",
            "[CV 3/3; 61/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 61/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.839 total time=  13.3s\n",
            "[CV 1/3; 62/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 62/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.851 total time=  25.6s\n",
            "[CV 2/3; 62/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 62/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.851 total time=  25.3s\n",
            "[CV 3/3; 62/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 62/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.843 total time=  25.2s\n",
            "[CV 1/3; 63/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 63/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.839 total time=  13.1s\n",
            "[CV 2/3; 63/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 63/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.838 total time=  13.2s\n",
            "[CV 3/3; 63/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 63/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.839 total time=  13.3s\n",
            "[CV 1/3; 64/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 64/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.847 total time=  26.7s\n",
            "[CV 2/3; 64/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 64/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.845 total time=  26.6s\n",
            "[CV 3/3; 64/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 64/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.845 total time=  25.7s\n",
            "[CV 1/3; 65/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 65/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.837 total time=  13.3s\n",
            "[CV 2/3; 65/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 65/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.841 total time=  13.4s\n",
            "[CV 3/3; 65/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 65/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.835 total time=  13.5s\n",
            "[CV 1/3; 66/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 66/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.847 total time=  25.6s\n",
            "[CV 2/3; 66/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 66/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.849 total time=  25.6s\n",
            "[CV 3/3; 66/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 66/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.847 total time=  25.5s\n",
            "[CV 1/3; 67/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 67/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.842 total time=  14.2s\n",
            "[CV 2/3; 67/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 67/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.840 total time=  13.1s\n",
            "[CV 3/3; 67/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 67/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.842 total time=  14.1s\n",
            "[CV 1/3; 68/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 68/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.849 total time=  25.3s\n",
            "[CV 2/3; 68/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 68/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.847 total time=  25.2s\n",
            "[CV 3/3; 68/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 68/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.844 total time=  25.5s\n",
            "[CV 1/3; 69/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 69/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.838 total time=  13.1s\n",
            "[CV 2/3; 69/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 69/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.844 total time=  13.2s\n",
            "[CV 3/3; 69/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 69/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.833 total time=  12.9s\n",
            "[CV 1/3; 70/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 70/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.844 total time=  25.1s\n",
            "[CV 2/3; 70/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 70/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.849 total time=  26.9s\n",
            "[CV 3/3; 70/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 70/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.844 total time=  26.3s\n",
            "[CV 1/3; 71/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 71/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.840 total time=  13.2s\n",
            "[CV 2/3; 71/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 71/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.842 total time=  13.2s\n",
            "[CV 3/3; 71/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 71/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.834 total time=  13.2s\n",
            "[CV 1/3; 72/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 72/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.850 total time=  25.3s\n",
            "[CV 2/3; 72/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 72/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.847 total time=  25.4s\n",
            "[CV 3/3; 72/144] START criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 72/144] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.850 total time=  25.3s\n",
            "[CV 1/3; 73/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 73/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.815 total time=  36.2s\n",
            "[CV 2/3; 73/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 73/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.811 total time=  37.9s\n",
            "[CV 3/3; 73/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 73/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.803 total time=  36.8s\n",
            "[CV 1/3; 74/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 74/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.813 total time= 1.2min\n",
            "[CV 2/3; 74/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 74/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.813 total time= 1.2min\n",
            "[CV 3/3; 74/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 74/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.810 total time= 1.2min\n",
            "[CV 1/3; 75/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 75/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.811 total time=  36.6s\n",
            "[CV 2/3; 75/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 75/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.809 total time=  35.6s\n",
            "[CV 3/3; 75/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 75/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.797 total time=  37.6s\n",
            "[CV 1/3; 76/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 76/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.812 total time= 1.2min\n",
            "[CV 2/3; 76/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 76/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.809 total time= 1.2min\n",
            "[CV 3/3; 76/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 76/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.807 total time= 1.2min\n",
            "[CV 1/3; 77/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 77/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.812 total time=  36.4s\n",
            "[CV 2/3; 77/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 77/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.809 total time=  35.9s\n",
            "[CV 3/3; 77/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 77/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.806 total time=  36.0s\n",
            "[CV 1/3; 78/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 78/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.811 total time= 1.2min\n",
            "[CV 2/3; 78/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 78/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.811 total time= 1.2min\n",
            "[CV 3/3; 78/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 78/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.805 total time= 1.2min\n",
            "[CV 1/3; 79/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 79/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.812 total time=  38.2s\n",
            "[CV 2/3; 79/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 79/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.807 total time=  36.0s\n",
            "[CV 3/3; 79/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 79/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.806 total time=  35.4s\n",
            "[CV 1/3; 80/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 80/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.812 total time= 1.2min\n",
            "[CV 2/3; 80/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 80/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.817 total time= 1.2min\n",
            "[CV 3/3; 80/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 80/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.811 total time= 1.2min\n",
            "[CV 1/3; 81/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 81/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.808 total time=  36.4s\n",
            "[CV 2/3; 81/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 81/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.808 total time=  35.3s\n",
            "[CV 3/3; 81/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 81/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.809 total time=  37.6s\n",
            "[CV 1/3; 82/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 82/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.812 total time= 1.2min\n",
            "[CV 2/3; 82/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 82/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.810 total time= 1.2min\n",
            "[CV 3/3; 82/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 82/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.810 total time= 1.2min\n",
            "[CV 1/3; 83/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 83/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.805 total time=  35.8s\n",
            "[CV 2/3; 83/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 83/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.811 total time=  35.0s\n",
            "[CV 3/3; 83/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 83/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.801 total time=  35.5s\n",
            "[CV 1/3; 84/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 84/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.810 total time= 1.2min\n",
            "[CV 2/3; 84/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 84/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.808 total time= 1.2min\n",
            "[CV 3/3; 84/144] START criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 84/144] END criterion=entropy, max_depth=9, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.812 total time= 1.2min\n",
            "[CV 1/3; 85/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 85/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.830 total time=  10.5s\n",
            "[CV 2/3; 85/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 85/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.836 total time=  11.1s\n",
            "[CV 3/3; 85/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 85/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.832 total time=  10.7s\n",
            "[CV 1/3; 86/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 86/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.847 total time=  21.8s\n",
            "[CV 2/3; 86/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 86/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.841 total time=  19.7s\n",
            "[CV 3/3; 86/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 86/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.837 total time=  21.0s\n",
            "[CV 1/3; 87/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 87/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.832 total time=  11.1s\n",
            "[CV 2/3; 87/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 87/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.833 total time=  10.0s\n",
            "[CV 3/3; 87/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 87/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.829 total time=  10.8s\n",
            "[CV 1/3; 88/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 88/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.846 total time=  20.7s\n",
            "[CV 2/3; 88/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 88/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.842 total time=  19.7s\n",
            "[CV 3/3; 88/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 88/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.840 total time=  20.7s\n",
            "[CV 1/3; 89/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 89/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.829 total time=  10.7s\n",
            "[CV 2/3; 89/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 89/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.832 total time=  10.6s\n",
            "[CV 3/3; 89/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 89/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.824 total time=  11.7s\n",
            "[CV 1/3; 90/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 90/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.841 total time=  20.9s\n",
            "[CV 2/3; 90/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 90/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.842 total time=  20.0s\n",
            "[CV 3/3; 90/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 90/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.840 total time=  21.0s\n",
            "[CV 1/3; 91/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 91/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.834 total time=  10.9s\n",
            "[CV 2/3; 91/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 91/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.840 total time=  10.3s\n",
            "[CV 3/3; 91/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 91/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.830 total time=  11.2s\n",
            "[CV 1/3; 92/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 92/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.844 total time=  20.9s\n",
            "[CV 2/3; 92/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 92/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.841 total time=  19.6s\n",
            "[CV 3/3; 92/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 92/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.840 total time=  20.9s\n",
            "[CV 1/3; 93/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 93/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.833 total time=  10.8s\n",
            "[CV 2/3; 93/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 93/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.834 total time=  10.1s\n",
            "[CV 3/3; 93/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 93/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.829 total time=  11.9s\n",
            "[CV 1/3; 94/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 94/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.840 total time=  20.9s\n",
            "[CV 2/3; 94/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 94/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.842 total time=  19.7s\n",
            "[CV 3/3; 94/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 94/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.834 total time=  20.7s\n",
            "[CV 1/3; 95/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 95/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.833 total time=  10.9s\n",
            "[CV 2/3; 95/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 95/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.834 total time=  10.0s\n",
            "[CV 3/3; 95/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 95/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.832 total time=  10.9s\n",
            "[CV 1/3; 96/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 96/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.843 total time=  21.0s\n",
            "[CV 2/3; 96/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 96/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.841 total time=  20.0s\n",
            "[CV 3/3; 96/144] START criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 96/144] END criterion=entropy, max_depth=9, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.840 total time=  20.7s\n",
            "[CV 1/3; 97/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 97/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.815 total time=  44.0s\n",
            "[CV 2/3; 97/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 97/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.817 total time=  42.8s\n",
            "[CV 3/3; 97/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 97/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.816 total time=  43.8s\n",
            "[CV 1/3; 98/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 98/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.818 total time= 1.4min\n",
            "[CV 2/3; 98/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 98/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.815 total time= 1.4min\n",
            "[CV 3/3; 98/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 98/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.815 total time= 1.4min\n",
            "[CV 1/3; 99/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 99/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.816 total time=  44.0s\n",
            "[CV 2/3; 99/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 99/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.813 total time=  42.9s\n",
            "[CV 3/3; 99/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 99/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.811 total time=  42.9s\n",
            "[CV 1/3; 100/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 100/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.816 total time= 1.4min\n",
            "[CV 2/3; 100/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 100/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.817 total time= 1.4min\n",
            "[CV 3/3; 100/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 100/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.813 total time= 1.4min\n",
            "[CV 1/3; 101/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 101/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.814 total time=  43.1s\n",
            "[CV 2/3; 101/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 101/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.813 total time=  44.3s\n",
            "[CV 3/3; 101/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 101/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.812 total time=  43.5s\n",
            "[CV 1/3; 102/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 102/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.817 total time= 1.4min\n",
            "[CV 2/3; 102/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 102/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.818 total time= 1.4min\n",
            "[CV 3/3; 102/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 102/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.814 total time= 1.4min\n",
            "[CV 1/3; 103/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 103/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.808 total time=  43.2s\n",
            "[CV 2/3; 103/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 103/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.812 total time=  43.9s\n",
            "[CV 3/3; 103/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 103/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.810 total time=  42.9s\n",
            "[CV 1/3; 104/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 104/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.814 total time= 1.4min\n",
            "[CV 2/3; 104/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 104/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.813 total time= 1.4min\n",
            "[CV 3/3; 104/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 104/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.813 total time= 1.4min\n",
            "[CV 1/3; 105/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 105/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.815 total time=  43.6s\n",
            "[CV 2/3; 105/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 105/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.813 total time=  44.1s\n",
            "[CV 3/3; 105/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 105/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.810 total time=  43.2s\n",
            "[CV 1/3; 106/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 106/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.814 total time= 1.4min\n",
            "[CV 2/3; 106/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 106/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.816 total time= 1.4min\n",
            "[CV 3/3; 106/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 106/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.812 total time= 1.4min\n",
            "[CV 1/3; 107/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 107/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.815 total time=  43.2s\n",
            "[CV 2/3; 107/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 107/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.815 total time=  43.8s\n",
            "[CV 3/3; 107/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 107/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.810 total time=  43.4s\n",
            "[CV 1/3; 108/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 108/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.817 total time= 1.4min\n",
            "[CV 2/3; 108/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 108/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.816 total time= 1.4min\n",
            "[CV 3/3; 108/144] START criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 108/144] END criterion=entropy, max_depth=11, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.814 total time= 1.4min\n",
            "[CV 1/3; 109/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 109/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.836 total time=  12.6s\n",
            "[CV 2/3; 109/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 109/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.833 total time=  12.9s\n",
            "[CV 3/3; 109/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 109/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.837 total time=  12.8s\n",
            "[CV 1/3; 110/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 110/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.847 total time=  24.3s\n",
            "[CV 2/3; 110/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 110/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.845 total time=  23.3s\n",
            "[CV 3/3; 110/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 110/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.839 total time=  24.2s\n",
            "[CV 1/3; 111/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 111/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.834 total time=  12.7s\n",
            "[CV 2/3; 111/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 111/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.841 total time=  12.7s\n",
            "[CV 3/3; 111/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 111/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.838 total time=  12.8s\n",
            "[CV 1/3; 112/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 112/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.846 total time=  24.4s\n",
            "[CV 2/3; 112/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 112/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.841 total time=  24.2s\n",
            "[CV 3/3; 112/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 112/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.846 total time=  23.8s\n",
            "[CV 1/3; 113/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 113/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.841 total time=  12.3s\n",
            "[CV 2/3; 113/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 113/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.837 total time=  12.5s\n",
            "[CV 3/3; 113/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 113/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.831 total time=  12.7s\n",
            "[CV 1/3; 114/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 114/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.849 total time=  24.3s\n",
            "[CV 2/3; 114/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 114/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.843 total time=  24.4s\n",
            "[CV 3/3; 114/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 114/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.838 total time=  24.4s\n",
            "[CV 1/3; 115/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 115/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.837 total time=  12.6s\n",
            "[CV 2/3; 115/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 115/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.830 total time=  12.7s\n",
            "[CV 3/3; 115/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 115/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.834 total time=  12.5s\n",
            "[CV 1/3; 116/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 116/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.847 total time=  23.6s\n",
            "[CV 2/3; 116/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 116/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.841 total time=  24.3s\n",
            "[CV 3/3; 116/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 116/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.841 total time=  24.3s\n",
            "[CV 1/3; 117/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 117/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.837 total time=  12.6s\n",
            "[CV 2/3; 117/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 117/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.835 total time=  12.7s\n",
            "[CV 3/3; 117/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 117/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.833 total time=  12.6s\n",
            "[CV 1/3; 118/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 118/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.845 total time=  24.2s\n",
            "[CV 2/3; 118/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 118/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.845 total time=  23.9s\n",
            "[CV 3/3; 118/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 118/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.843 total time=  24.0s\n",
            "[CV 1/3; 119/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 119/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.842 total time=  12.7s\n",
            "[CV 2/3; 119/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 119/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.839 total time=  12.7s\n",
            "[CV 3/3; 119/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 119/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.834 total time=  12.6s\n",
            "[CV 1/3; 120/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 120/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.842 total time=  24.2s\n",
            "[CV 2/3; 120/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 120/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.846 total time=  24.2s\n",
            "[CV 3/3; 120/144] START criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 120/144] END criterion=entropy, max_depth=11, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.837 total time=  24.0s\n",
            "[CV 1/3; 121/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 121/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.816 total time=  49.5s\n",
            "[CV 2/3; 121/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 121/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.818 total time=  50.2s\n",
            "[CV 3/3; 121/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 121/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.814 total time=  50.0s\n",
            "[CV 1/3; 122/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 122/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.820 total time= 1.6min\n",
            "[CV 2/3; 122/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 122/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.821 total time= 1.6min\n",
            "[CV 3/3; 122/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 122/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.814 total time= 1.6min\n",
            "[CV 1/3; 123/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 123/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.819 total time=  49.0s\n",
            "[CV 2/3; 123/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 123/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.817 total time=  49.8s\n",
            "[CV 3/3; 123/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 123/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.815 total time=  50.0s\n",
            "[CV 1/3; 124/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 124/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.816 total time= 1.6min\n",
            "[CV 2/3; 124/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 124/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.820 total time= 1.6min\n",
            "[CV 3/3; 124/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 124/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.815 total time= 1.6min\n",
            "[CV 1/3; 125/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 125/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.812 total time=  48.6s\n",
            "[CV 2/3; 125/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 125/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.816 total time=  49.9s\n",
            "[CV 3/3; 125/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 125/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.811 total time=  49.6s\n",
            "[CV 1/3; 126/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 126/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.820 total time= 1.6min\n",
            "[CV 2/3; 126/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 126/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.817 total time= 1.6min\n",
            "[CV 3/3; 126/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 126/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.814 total time= 1.6min\n",
            "[CV 1/3; 127/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 127/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.818 total time=  48.7s\n",
            "[CV 2/3; 127/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 127/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.815 total time=  49.4s\n",
            "[CV 3/3; 127/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 127/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.818 total time=  49.5s\n",
            "[CV 1/3; 128/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 128/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.819 total time= 1.6min\n",
            "[CV 2/3; 128/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 128/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.819 total time= 1.6min\n",
            "[CV 3/3; 128/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 128/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.817 total time= 1.6min\n",
            "[CV 1/3; 129/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 129/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.820 total time=  48.8s\n",
            "[CV 2/3; 129/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 129/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.816 total time=  49.7s\n",
            "[CV 3/3; 129/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 129/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.815 total time=  49.9s\n",
            "[CV 1/3; 130/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 130/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.819 total time= 1.6min\n",
            "[CV 2/3; 130/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 130/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.820 total time= 1.6min\n",
            "[CV 3/3; 130/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 130/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.815 total time= 1.6min\n",
            "[CV 1/3; 131/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 131/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.814 total time=  49.6s\n",
            "[CV 2/3; 131/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 131/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.819 total time=  49.8s\n",
            "[CV 3/3; 131/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 131/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.811 total time=  48.4s\n",
            "[CV 1/3; 132/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 132/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.814 total time= 1.6min\n",
            "[CV 2/3; 132/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 132/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.818 total time= 1.6min\n",
            "[CV 3/3; 132/144] START criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 132/144] END criterion=entropy, max_depth=13, max_features=sqrt, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.814 total time= 1.6min\n",
            "[CV 1/3; 133/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 133/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.839 total time=  14.5s\n",
            "[CV 2/3; 133/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 133/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.840 total time=  14.5s\n",
            "[CV 3/3; 133/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 133/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.838 total time=  14.5s\n",
            "[CV 1/3; 134/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 134/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.852 total time=  27.4s\n",
            "[CV 2/3; 134/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 134/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.849 total time=  27.3s\n",
            "[CV 3/3; 134/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 134/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=200;, score=0.847 total time=  27.3s\n",
            "[CV 1/3; 135/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 135/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.838 total time=  14.4s\n",
            "[CV 2/3; 135/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 135/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.840 total time=  14.2s\n",
            "[CV 3/3; 135/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 135/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=0.835 total time=  14.4s\n",
            "[CV 1/3; 136/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 136/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.849 total time=  27.8s\n",
            "[CV 2/3; 136/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 136/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.851 total time=  27.4s\n",
            "[CV 3/3; 136/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 136/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=200;, score=0.842 total time=  27.2s\n",
            "[CV 1/3; 137/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 137/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.842 total time=  14.2s\n",
            "[CV 2/3; 137/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 137/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.837 total time=  14.2s\n",
            "[CV 3/3; 137/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 137/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=100;, score=0.835 total time=  14.2s\n",
            "[CV 1/3; 138/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 138/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.844 total time=  27.2s\n",
            "[CV 2/3; 138/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 138/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.844 total time=  27.6s\n",
            "[CV 3/3; 138/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 138/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=200;, score=0.847 total time=  27.3s\n",
            "[CV 1/3; 139/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 1/3; 139/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.842 total time=  14.1s\n",
            "[CV 2/3; 139/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 2/3; 139/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.840 total time=  14.2s\n",
            "[CV 3/3; 139/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100\n",
            "[CV 3/3; 139/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=0.834 total time=  14.1s\n",
            "[CV 1/3; 140/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 1/3; 140/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.848 total time=  27.1s\n",
            "[CV 2/3; 140/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 2/3; 140/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.848 total time=  26.9s\n",
            "[CV 3/3; 140/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200\n",
            "[CV 3/3; 140/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=200;, score=0.845 total time=  27.1s\n",
            "[CV 1/3; 141/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 1/3; 141/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.843 total time=  14.2s\n",
            "[CV 2/3; 141/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 2/3; 141/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.839 total time=  14.1s\n",
            "[CV 3/3; 141/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100\n",
            "[CV 3/3; 141/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=100;, score=0.841 total time=  14.2s\n",
            "[CV 1/3; 142/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 1/3; 142/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.849 total time=  27.2s\n",
            "[CV 2/3; 142/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 2/3; 142/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.847 total time=  27.2s\n",
            "[CV 3/3; 142/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200\n",
            "[CV 3/3; 142/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=200;, score=0.845 total time=  27.3s\n",
            "[CV 1/3; 143/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 1/3; 143/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.840 total time=  14.3s\n",
            "[CV 2/3; 143/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 2/3; 143/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.837 total time=  14.2s\n",
            "[CV 3/3; 143/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100\n",
            "[CV 3/3; 143/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=100;, score=0.841 total time=  14.2s\n",
            "[CV 1/3; 144/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 1/3; 144/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.849 total time=  27.3s\n",
            "[CV 2/3; 144/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 2/3; 144/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.843 total time=  27.0s\n",
            "[CV 3/3; 144/144] START criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200\n",
            "[CV 3/3; 144/144] END criterion=entropy, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=9, n_estimators=200;, score=0.849 total time=  27.2s\n",
            "Best Score {0.8491785714285714}\n",
            "Best hyperParameter Set:\n",
            "\\criterion: entropy\n",
            "\\max_depth: 13\n",
            "\\max_features: log2\n",
            "\\min_samples_leaf: 3\n",
            "\\min_samples_split: 3\n",
            "\\n_estimators: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"Precision Score on training dateset for Finetuned Random Forest Classifier: %s\" % precision_score(y_train,model_8.predict(X_train_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for Finetuned Random Forest Classifier: %s\" % roc_auc_score(y_train,model_8.predict_proba(X_train_df)[:,1],multi_class='ovo',average='macro'))\n",
        "f1_score_train_8 =f1_score(y_train,model_8.predict(X_train_df),average=\"weighted\")\n",
        "print(\"F1 Score training dateset for Finetuned Random Forest Classifier: %s\" % f1_score_train_8)\n",
        "print(\"Precision Score on test for Finetuned Random Forest Classifier: %s\" % precision_score(y_test,model_8.predict(X_test_df),average='micro'))\n",
        "print(\"AUC Score on test for Finetuned Random Forest Classifier: %s\" % roc_auc_score(y_test,model_8.predict_proba(X_test_df)[:,1],multi_class='ovo',average='macro'))\n",
        "f1_score_8 =f1_score(y_test,model_8.predict(X_test_df),average=\"weighted\")\n",
        "print(\"F1 Score for Finetuned Random Forest Classifier: %s\" % f1_score_8)\n"
      ],
      "metadata": {
        "id": "QcxvnrRmvDjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d3e49bb-7fee-4ffe-9117-7549bd0dc106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score on training dateset for Finetuned Random Forest Classifier: 0.8705833333333334\n",
            "AUC Score on training dateset for Finetuned Random Forest Classifier: 0.9437963986325424\n",
            "F1 Score training dateset for Finetuned Random Forest Classifier: 0.8704930921939557\n",
            "Precision Score on test for Finetuned Random Forest Classifier: 0.8465833333333334\n",
            "AUC Score on test for Finetuned Random Forest Classifier: 0.9233651717543115\n",
            "F1 Score for Finetuned Random Forest Classifier: 0.8465195818256632\n",
            "CPU times: user 23.6 s, sys: 901 ms, total: 24.5 s\n",
            "Wall time: 24.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Precision Score on training dateset for Finetuned Random Forest Classifier: %s\" % precision_score(y_train,model_8.predict(X_train_df),average='micro'))\n",
        "print(\"AUC Score on training dateset for Finetuned Random Forest Classifier: %s\" % roc_auc_score(y_train,model_8.predict_proba(X_train_df)[:,1],multi_class='ovo',average='macro'))\n",
        "f1_score_train_8 =f1_score(y_train,model_8.predict(X_train_df),average=\"weighted\")\n",
        "print(\"F1 Score training dateset for Finetuned Random Forest Classifier: %s\" % f1_score_train_8)\n",
        "print(\"Precision Score on test for Finetuned Random Forest Classifier: %s\" % precision_score(y_test,model_8.predict(X_test_df),average='micro'))\n",
        "print(\"AUC Score on test for Finetuned Random Forest Classifier: %s\" % roc_auc_score(y_test,model_8.predict_proba(X_test_df)[:,1],multi_class='ovo',average='macro'))\n",
        "f1_score_8 =f1_score(y_test,model_8.predict(X_test_df),average=\"weighted\")\n",
        "print(\"F1 Score for Finetuned Random Forest Classifier: %s\" % f1_score_8)"
      ],
      "metadata": {
        "id": "ziXujDTGvDfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192fb0ef-baf0-41b9-b7ce-da82812e423b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score on training dateset for Finetuned Random Forest Classifier: 0.8705833333333334\n",
            "AUC Score on training dateset for Finetuned Random Forest Classifier: 0.9437963986325424\n",
            "F1 Score training dateset for Finetuned Random Forest Classifier: 0.8704930921939557\n",
            "Precision Score on test for Finetuned Random Forest Classifier: 0.8465833333333334\n",
            "AUC Score on test for Finetuned Random Forest Classifier: 0.9233651717543115\n",
            "F1 Score for Finetuned Random Forest Classifier: 0.8465195818256632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we focus on calculation of f1 score of each model"
      ],
      "metadata": {
        "id": "u-9W_EvEXauc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_test_1 = 0.8853908950079604\n",
        "f1_score_test_2 = 0.7138944522995792\n",
        "f1_score_test_3 = 0.7153719254355063\n",
        "f1_score_test_4 = 0.8444183137090522\n",
        "f1_score_test_5 = 0.8436125765351109\n",
        "f1_score_7 = 0.8853908950079604\n",
        "f1_score_8 = 0.8465195818256632"
      ],
      "metadata": {
        "id": "IryjZ35nXaCC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- f1_score_test_1 and f1_score_7 is higher among all model so, our model is logistic regression"
      ],
      "metadata": {
        "id": "PUmH6xXXZy0w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v3A43dykZxo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mn1P0uLcYhh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PERH777z9ST7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}