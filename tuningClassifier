# ---------------------------- CATBOOST CLASSIFIER -------------------------------------------

# def objective(trial):
#     params = {
#         "iterations": trial.suggest_int("iterations", 50, 500),
#         "depth": trial.suggest_int("depth", 2, 10),
#         "learning_rate": trial.suggest_loguniform("learning_rate", 0.01, 0.3),
#         "l2_leaf_reg": trial.suggest_float("l2_leaf_reg", 1e-8, 10.0),
#         "border_count": trial.suggest_int("border_count", 32, 255),
#         "bagging_temperature": trial.suggest_float("bagging_temperature", 0.0, 1.0),
#         "random_strength": trial.suggest_float("random_strength", 1e-8, 10.0),
#         # "od_wait": trial.suggest_int("od_wait", 10, 50),
#         # "task_type": "GPU",
#     }
    
#     clf = CatBoostClassifier(**params, verbose=0)
    
#     score = cross_val_score(clf, X_train, y_train, cv=5, scoring="accuracy", n_jobs=-1).mean()
#     return score


# # Run the optimization
# study = optuna.create_study(direction="maximize")
# study.optimize(objective, n_trials=1000, show_progress_bar=True)

# # Best hyperparameters
# print("Best Hyperparameters:", study.best_params)

# best_params = study.best_params
# best_clf = CatBoostClassifier(**best_params, verbose=0)
# best_clf.fit(X_train, y_train)

# y_pred = best_clf.predict_proba(X_test)[:, 1]
# accuracy = roc_auc_score(y_test, y_pred)
# print("Test Accuracy:", accuracy)


#-------------------------- LGBM CLASSIFIER ----------------------------------------------------------------------------

# def objective(trial):
#     params = {
#         "n_estimators": trial.suggest_int("n_estimators", 50, 500),
#         "max_depth": trial.suggest_int("max_depth", 2, 20),
#         "learning_rate": trial.suggest_loguniform("learning_rate", 0.01, 0.3),
#         "num_leaves": trial.suggest_int("num_leaves", 2, 256),
#         "subsample": trial.suggest_float("subsample", 0.5, 1.0),
#         "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
#         "reg_alpha": trial.suggest_float("reg_alpha", 1e-8, 10.0),
#         "reg_lambda": trial.suggest_float("reg_lambda", 1e-8, 10.0),
#         "min_child_samples": trial.suggest_int("min_child_samples", 1, 100),
#         "verbose":-1
#     }
    
#     clf = LGBMClassifier(**params)
    
#     score = cross_val_score(clf, X_train, y_train, cv=5, scoring="roc_auc", n_jobs=-1, verbose=0).mean()
#     return score

# study = optuna.create_study(direction="maximize")
# study.optimize(objective, n_trials=1000, show_progress_bar=True)

# print("Best Hyperparameters:", study.best_params)

# best_params = study.best_params
# best_clf = LGBMClassifier(**best_params)
# best_clf.fit(X_train, y_train)

# y_pred = best_clf.predict_proba(X_test)[:, 1]
# accuracy = roc_auc_score(y_test, y_pred)
# print("Test Accuracy:", accuracy)

# -----------------------------------   XGB CLASSIFIER -------------------------------------------
# def objective(trial):
#     params = {
#         "n_estimators": trial.suggest_int("n_estimators", 50, 800),
#         "max_depth": trial.suggest_int("max_depth", 2, 20),
#         "learning_rate": trial.suggest_loguniform("learning_rate", 0.01, 0.3),
#         "subsample": trial.suggest_float("subsample", 0.5, 1.0),
#         "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
#         "gamma": trial.suggest_float("gamma", 0, 5),
#         "min_child_weight": trial.suggest_int("min_child_weight", 1, 10),
#         "lambda": trial.suggest_float("lambda", 1e-8, 10.0),
#         "alpha": trial.suggest_float("alpha", 1e-8, 10.0),
#         # "tree_method":"gpu_hist",
#         # "devices":'0'
#     }
    
#     clf = XGBClassifier(**params, use_label_encoder=False, eval_metric="logloss")
    
#     score = cross_val_score(clf, X_train, y_train, cv=5, scoring="roc_auc", n_jobs=-1).mean()
#     return score

# study = optuna.create_study(direction="maximize")
# study.optimize(objective, n_trials=1000, show_progress_bar=True)

# print("Best Hyperparameters:", study.best_params)

# best_params = study.best_params
# best_clf = XGBClassifier(**best_params, use_label_encoder=False, eval_metric="logloss")
# best_clf.fit(X_train, y_train)

# y_pred = best_clf.predict_proba(X_test)[:, 1]
# accuracy = roc_auc_score(y_test, y_pred)
# print("Test Accuracy:", accuracy)

# ------------------------------------------- Random Forest Calssifier ------------------------------------------------

# def objective(trial):
#     n_estimators = trial.suggest_int("n_estimators", 50, 500)
#     max_depth = trial.suggest_int("max_depth", 2, 20)
#     min_samples_split = trial.suggest_int("min_samples_split", 2, 20)
#     min_samples_leaf = trial.suggest_int("min_samples_leaf", 1, 20)
#     max_features = trial.suggest_float("max_features", 0.1, 1.0)
    
#     clf = RandomForestClassifier(
#         n_estimators=n_estimators,
#         max_depth=max_depth,
#         min_samples_split=min_samples_split,
#         min_samples_leaf=min_samples_leaf,
#         max_features=max_features,
#         random_state=42,
#         n_jobs=-1
#     )
    
#     score = cross_val_score(clf, X_train, y_train, cv=5, scoring="accuracy", n_jobs=-1).mean()
#     return score

# study = optuna.create_study(direction="maximize")
# study.optimize(objective, n_trials=500, show_progress_bar=True)

# print("Best Hyperparameters:", study.best_params)

# best_params = study.best_params
# best_clf = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)
# best_clf.fit(X_train, y_train)

# y_pred = best_clf.predict_proba(X_test)[:, 1]
# accuracy = roc_auc_score(y_test, y_pred)
# print("Test Accuracy:", accuracy)

# --------------------------------------- Stacking Classifier ---------------------------------------------------------------------

# FOLDS = 10
# kf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)

# oof_preds = np.zeros((len(X), 4)) 
# stack_test_preds = np.zeros((len(test_df), 4))

# # Cross-validation loop
# for i, (train_idx, val_idx) in enumerate(kf.split(X, y)):
#     print(f'------------------ Fold {i+1} ----------------------')
    
#     X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

#     cat_model = CatBoostClassifier(**cat_params)
#     cat_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)
#     oof_preds[val_idx, 0] = cat_model.predict_proba(X_val)[:, 1]
#     stack_test_preds[:, 0] += cat_model.predict_proba(test_df)[:, 1] / FOLDS  

#     lgb_model = LGBMClassifier(**lgb_params)
#     lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)])
#     oof_preds[val_idx, 1] = lgb_model.predict_proba(X_val)[:, 1]
#     stack_test_preds[:, 1] += lgb_model.predict_proba(test_df)[:, 1] / FOLDS  
    
#     xgb_model = XGBClassifier(**xgb_params)
#     xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0, early_stopping_rounds=50)
#     oof_preds[val_idx, 2] = xgb_model.predict_proba(X_val)[:, 1]
#     stack_test_preds[:, 2] += xgb_model.predict_proba(test_df)[:, 1] / FOLDS 

#     rf_model = RandomForestClassifier(**rf_params)
#     rf_model.fit(X_train, y_train)
#     oof_preds[val_idx, 3] = rf_model.predict_proba(X_val)[:, 1]
#     stack_test_preds[:, 3]+=rf_model.predict_proba(test_df)[:, 1]/FOLDS


# meta_model = LogisticRegression()
# meta_model.fit(oof_preds, y)
# final_preds = meta_model.predict_proba(stack_test_preds)[:, 1]

# print("Stacking ensemble predictions complete!")


# Train the meta model
# meta_model = LogisticRegression()
# meta_model.fit(oof_preds, y)

# # Use the stacked test predictions for final prediction
# final_preds = meta_model.predict_proba(stack_test_preds)[:, 1]

# print("Stacking ensemble predictions complete!")

# # Corrected line: Use stack_test_preds instead of test_df
# pred_test = meta_model.predict_proba(stack_test_preds)[:, 1]  

# sub['rainfall'] = pred_test
# sub.to_csv('submission.csv', index=False)

# ---------------------------------------------- Simple Neural Network ---------------------------------------------------------------------------------------------------------

# import tensorflow as tf
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Dense, Dropout
# import optuna

# def all_optimizers(trial):
#     optimizers = {
#         "SGD": tf.keras.optimizers.SGD(
#             learning_rate=trial.suggest_loguniform("sgd_lr", 1e-4, 1e-1),
#             momentum=trial.suggest_float("sgd_momentum", 0.0, 1.0),
#             nesterov=True
#         ),
#         "RMSprop": tf.keras.optimizers.RMSprop(
#             learning_rate=trial.suggest_loguniform("rms_lr", 1e-5, 1e-2)
#         ),
#         "Nadam": tf.keras.optimizers.Nadam(
#             learning_rate=trial.suggest_loguniform("nadam_lr", 1e-5, 1e-2),
#             beta_1=trial.suggest_float("nadam_beta_1", 0.8, 0.99),
#             beta_2=trial.suggest_float("nadam_beta_2", 0.9, 1.0)
#         ),
#         "Adam": tf.keras.optimizers.Adam(
#             learning_rate=trial.suggest_loguniform("adam_lr", 1e-5, 1e-2)
#         ),
#         "AdamW": tf.keras.optimizers.AdamW(
#             learning_rate=trial.suggest_loguniform("adamw_lr", 1e-5, 1e-2),
#             weight_decay=trial.suggest_loguniform("adamw_weight_decay", 1e-6, 1e-2)
#         )
#     }
#     optimizer_name = trial.suggest_categorical("optimizer", list(optimizers.keys()))
#     return optimizers[optimizer_name]

# def create_ann(trial, num_classes, input_dim):
#     ann = Sequential()
    
#     # First hidden layer
#     units1 = trial.suggest_int("units1", 16, 256, step=16)
#     ann.add(Dense(units1, input_dim=input_dim, kernel_initializer='he_uniform', 
#                   activation=trial.suggest_categorical("activation1", ["relu", "tanh"])))
#     ann.add(Dropout(trial.suggest_float("dropout1", 0.0, 0.5)))
    
#     # Second hidden layer
#     units2 = trial.suggest_int("units2", 4, 128, step=4)
#     ann.add(Dense(units2, kernel_initializer='he_uniform', 
#                   activation=trial.suggest_categorical("activation2", ["relu", "tanh"])))
#     ann.add(Dropout(trial.suggest_float("dropout2", 0.0, 0.5)))

#     # Output layer
#     ann.add(Dense(num_classes, kernel_initializer='he_uniform', activation="softmax"))

#     optimizer = all_optimizers(trial)

#     ann.compile(loss="binary_crossentropy", optimizer=optimizer, metrics=["accuracy"])
#     return ann

# def objective(trial):
#     num_classes = 2  # Adjust based on your dataset
#     input_dim = X_train.shape[1]  # Assuming X_train is defined

#     model = create_ann(trial, num_classes, input_dim)
    
#     history = model.fit(
#         X_train, y_train,
#         epochs=trial.suggest_int("epochs", 10, 100),
#         batch_size=trial.suggest_int("batch_size", 16, 128, step=16),
#         validation_data=(X_val, y_val),
#         verbose=0
#     )
    
#     return max(history.history["val_accuracy"])

# study = optuna.create_study(direction="maximize")
# study.optimize(objective, n_trials=50)

# print("Best parameters:", study.best_params)







